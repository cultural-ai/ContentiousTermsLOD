{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import rdflib\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading results EN\n",
    "with open('aat_query_results_en.json','r') as jf:\n",
    "    aat_query_results_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading results NL\n",
    "with open('aat_query_results_nl.json','r') as jf:\n",
    "    aat_query_results_nl = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms to get lemmas\n",
    "with open('/LODlit/query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. N entities by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "n_entities_en = {}\n",
    "for term, results in aat_query_results_en.items():\n",
    "    n_entities_en[term] = len(set([hit['aat_uri'] for hit in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "n_entities_nl = {}\n",
    "for term, results in aat_query_results_nl.items():\n",
    "    n_entities_nl[term] = len(set([hit['aat_uri'] for hit in results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the results in csv\n",
    "with open('n_entities_by_term.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','term','lang','n_entities']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for query_term, e in n_entities_en.items():\n",
    "        # getting a lemma of the query term\n",
    "        for l, wordforms in query_terms['en'].items():\n",
    "            if query_term in wordforms:\n",
    "                lemma = l\n",
    "        row = [lemma,query_term,'en',e]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    for query_term, e in n_entities_nl.items():\n",
    "        # getting a lemma of the query term\n",
    "        for l, wordforms in query_terms['nl'].items():\n",
    "            if query_term in wordforms:\n",
    "                lemma = l\n",
    "        row = [lemma,query_term,'nl',e]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N entities by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('n_entities_by_term.csv')\n",
    "# lemmas are not unique in 2 lang, making seaprate dfs by lang\n",
    "en_df = df.loc[df['lang'] == 'en']\n",
    "nl_df = df.loc[df['lang'] == 'nl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('n_entities_by_lemma.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','lang','n_entities']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in en_df.groupby('lemma'):\n",
    "        \n",
    "        row = [group[0],'en',sum(group[1]['n_entities'])]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    for group in nl_df.groupby('lemma'):\n",
    "        \n",
    "        row = [group[0],'nl',sum(group[1]['n_entities'])]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. N hits (ocurences) of where terms are found by query term\n",
    "â€“ prefLabel, altLabel, scopeNote, prefLabel_comment, altLabel_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "\n",
    "aat_where_terms_found_en = {}\n",
    "\n",
    "for term, results in aat_query_results_en.items():\n",
    "    pref = 0\n",
    "    alt = 0\n",
    "    scopeNote = 0\n",
    "    pref_comment = 0\n",
    "    alt_comment = 0\n",
    "    for hit in results:\n",
    "        if hit['found_in'] == 'prefLabel':\n",
    "            pref += 1\n",
    "        if hit['found_in'] == 'altLabel':\n",
    "            alt += 1\n",
    "        if hit['found_in'] == 'scopeNote':\n",
    "            scopeNote += 1\n",
    "        if hit['found_in'] == 'prefLabel_comment':\n",
    "            pref_comment += 1\n",
    "        if hit['found_in'] == 'altLabel_comment':\n",
    "            alt_comment += 1\n",
    "            \n",
    "    aat_where_terms_found_en[term] = [pref,alt,scopeNote,pref_comment,alt_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "\n",
    "aat_where_terms_found_nl = {}\n",
    "\n",
    "for term, results in aat_query_results_nl.items():\n",
    "    pref = 0\n",
    "    alt = 0\n",
    "    scopeNote = 0\n",
    "    pref_comment = 0\n",
    "    alt_comment = 0\n",
    "    for hit in results:\n",
    "        if hit['found_in'] == 'prefLabel':\n",
    "            pref += 1\n",
    "        if hit['found_in'] == 'altLabel':\n",
    "            alt += 1\n",
    "        if hit['found_in'] == 'scopeNote':\n",
    "            scopeNote += 1\n",
    "        if hit['found_in'] == 'prefLabel_comment':\n",
    "            pref_comment += 1\n",
    "        if hit['found_in'] == 'altLabel_comment':\n",
    "            alt_comment += 1\n",
    "            \n",
    "    aat_where_terms_found_nl[term] = [pref,alt,scopeNote,pref_comment,alt_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting a csv of where terms are found\n",
    "\n",
    "with open('n_hits_by_term.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','term','lang','aat_prefLabel','aat_altLabel','aat_scopeNote',\\\n",
    "              'aat_prefLabel_comment','aat_altLabel_comment','total']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for term, stats in aat_where_terms_found_en.items():\n",
    "        for l, wordforms in query_terms['en'].items():\n",
    "            if term in wordforms:\n",
    "                lemma = l\n",
    "        row = [lemma, term, 'en', stats[0], stats[1], stats[2], stats[3], stats[4], sum(stats)]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    for term, stats in aat_where_terms_found_nl.items():\n",
    "        for l, wordforms in query_terms['nl'].items():\n",
    "            if term in wordforms:\n",
    "                lemma = l\n",
    "        row = [lemma, term, 'nl', stats[0], stats[1], stats[2], stats[3], stats[4], sum(stats)]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. N hits (ocurences) by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('n_hits_by_term.csv')\n",
    "# lemmas are not unique in 2 lang, making separate dfs by lang\n",
    "en_df = df.loc[df['lang'] == 'en']\n",
    "nl_df = df.loc[df['lang'] == 'nl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting a csv with stats by lemma\n",
    "\n",
    "with open('n_hits_by_lemma.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','lang','aat_prefLabel','aat_altLabel','aat_scopeNote',\\\n",
    "              'aat_prefLabel_comment','aat_altLabel_comment','total_lemma']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in en_df.groupby('lemma'):\n",
    "        \n",
    "        row = [group[0],'en',sum(group[1]['aat_prefLabel']),sum(group[1]['aat_altLabel']),\\\n",
    "               sum(group[1]['aat_scopeNote']),sum(group[1]['aat_prefLabel_comment']),\\\n",
    "               sum(group[1]['aat_altLabel_comment']),sum(group[1]['total'])]\n",
    "        \n",
    "        writer.writerow(row)\n",
    "        \n",
    "    for group in nl_df.groupby('lemma'):\n",
    "        \n",
    "        row = [group[0],'nl',sum(group[1]['aat_prefLabel']),sum(group[1]['aat_altLabel']),\\\n",
    "               sum(group[1]['aat_scopeNote']),sum(group[1]['aat_prefLabel_comment']),\\\n",
    "               sum(group[1]['aat_altLabel_comment']),sum(group[1]['total'])]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting general number of literals in subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These numbers are put in Table 1\n",
    "# We used subgraphs in the N3 format (compressed on GitHub in /AAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_subgraph_en = Graph()\n",
    "aat_subgraph_en.parse(\"AAT/aat_subgraph_en.n3\", format=\"n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_subgraph_nl = Graph()\n",
    "aat_subgraph_nl.parse(\"AAT/aat_subgraph_nl.n3\", format=\"n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefLabel_lit = \"\"\"\n",
    "SELECT (COUNT(*) AS ?count)\n",
    "\n",
    "WHERE {\n",
    "?concept skosxl:prefLabel / skosxl:literalForm ?lit_form .\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altLabel_lit = \"\"\"\n",
    "SELECT (COUNT(*) AS ?count)\n",
    "\n",
    "WHERE {\n",
    "?concept skosxl:altLabel / skosxl:literalForm ?lit_form .\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefLabel_comment = \"\"\"\n",
    "SELECT (COUNT(*) AS ?count)\n",
    "\n",
    "WHERE {\n",
    "?concept skosxl:prefLabel / rdfs:comment ?lit_form .\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altLabel_comment = \"\"\"\n",
    "SELECT (COUNT(*) AS ?count)\n",
    "\n",
    "WHERE {\n",
    "?concept skosxl:altLabel / rdfs:comment ?lit_form .\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_note = \"\"\"\n",
    "SELECT (COUNT(*) AS ?count)\n",
    "\n",
    "WHERE {\n",
    "?concept skos:scopeNote / rdf:value ?lit_form .\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_subgraph_nl.query(altLabel_lit).bindings[0][\"count\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
