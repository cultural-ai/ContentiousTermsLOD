{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. For each resource, divide lemmas into quartiles based on N of entities they have\n",
    "### 2. In each quartile, randomly draw 10 entities excluding related match entities; take only unique entities (40 in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms with lemmas\n",
    "with open('/Users/anesterov/reps/LODlit/query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_lemma_quartiles(lang:str, path_to_n_hits_by_lemma:str) -> dict:\n",
    "    '''\n",
    "    Grouping lemmas in quartiles according to N of entities they have in resources\n",
    "    lang: str, 'en' or 'nl' (relevant only for wikidata and aat)\n",
    "    path_to_n_hits_by_lemma: str, a path to a csv file with N of hits by lemma (for example, '/LODlit/Wikidata/n_hits_by_lemma.csv')\n",
    "    Returns dict {'q1':['lemma']}\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    resource_hits = pd.read_csv(path_to_n_hits_by_lemma)\n",
    "    \n",
    "    if 'lang' in resource_hits.columns:\n",
    "        resource_hits_by_lang = resource_hits.loc[resource_hits['lang'] == lang]\n",
    "    # for PWN and ODWN\n",
    "    else:\n",
    "        resource_hits_by_lang = resource_hits\n",
    "    \n",
    "    # getting quantiles values\n",
    "    q_values = list(resource_hits_by_lang[\"total_lemma\"].quantile([0,0.25,0.5,0.75,1]))\n",
    "    \n",
    "    # getting list of lemmas by quartiles\n",
    "    # quartile 1\n",
    "    results['q1'] = [row[1]['lemma'] for row in resource_hits_by_lang.iterrows() if int(q_values[0]) <= row[1]['total_lemma'] <= int(q_values[1])]\n",
    "    # quartile 2\n",
    "    results['q2'] = [row[1]['lemma'] for row in resource_hits_by_lang.iterrows() if int(q_values[1]) <= row[1]['total_lemma'] <= int(q_values[2])]\n",
    "    # quartile 3\n",
    "    results['q3'] = [row[1]['lemma'] for row in resource_hits_by_lang.iterrows() if int(q_values[2]) <= row[1]['total_lemma'] <= int(q_values[3])]\n",
    "    # quartile 4\n",
    "    results['q4'] = [row[1]['lemma'] for row in resource_hits_by_lang.iterrows() if int(q_values[3]) <= row[1]['total_lemma'] <= int(q_values[4])]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# def _get_subset_by_resource()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_n_hits = '/Users/anesterov/reps/LODlit/Wikidata/n_hits_by_lemma.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_en_quartiles = _get_lemma_quartiles('en',path_to_n_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_en_top10 = pd.read_csv('/Users/anesterov/reps/LODlit/annotation_sheet_wikidata_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, generate a file with Top-10 grouped by lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change path later; the file on GitHub is zipped\n",
    "wd_en_cs = pd.read_csv('/Users/anesterov/LODlit_local/wd/apr6/wikidata_en_cs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping NaN values if there are no search results and cs_rm per\n",
    "wd_en_cs.dropna(subset=['hit_id', 'cs_rm'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entities with no CS score\n",
    "wd_en_cs.drop(wd_en_cs[wd_en_cs['cs_rm'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the lemmas column\n",
    "lemmas = []\n",
    "for row in wd_en_cs.iterrows():\n",
    "    for lemma, wordforms in query_terms['en'].items():\n",
    "        if row[1]['term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_en_cs.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "wd_en_cs.drop_duplicates(subset=[\"lemma\",\"hit_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and get Top-10 by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_by_lemma = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in wd_en_cs.groupby(\"lemma\"):\n",
    "    top_10_by_lemma = top_10_by_lemma.append(group[1].sort_values(by=\"cs_rm\", ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>term</th>\n",
       "      <th>hit_id</th>\n",
       "      <th>bow</th>\n",
       "      <th>cs_rm</th>\n",
       "      <th>cs_wm</th>\n",
       "      <th>cs_rm_wm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87351</th>\n",
       "      <td>aboriginal</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>Q103817</td>\n",
       "      <td>['culture', 'aboriginal', 'minority', 'descend...</td>\n",
       "      <td>0.947705</td>\n",
       "      <td>0.820495</td>\n",
       "      <td>0.945303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87882</th>\n",
       "      <td>aboriginal</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>Q96200400</td>\n",
       "      <td>['statement', 'state', 'territorial', 'buildin...</td>\n",
       "      <td>0.937666</td>\n",
       "      <td>0.814829</td>\n",
       "      <td>0.938606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88901</th>\n",
       "      <td>aboriginal</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>Q7980672</td>\n",
       "      <td>['language', 'area', 'event', 'recognised', 'p...</td>\n",
       "      <td>0.929123</td>\n",
       "      <td>0.814358</td>\n",
       "      <td>0.929588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87611</th>\n",
       "      <td>aboriginal</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>Q28942344</td>\n",
       "      <td>['aboriginal', 'people', 'community', 'indigen...</td>\n",
       "      <td>0.921723</td>\n",
       "      <td>0.842450</td>\n",
       "      <td>0.924107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88372</th>\n",
       "      <td>aboriginal</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>Q8039318</td>\n",
       "      <td>['victoria', 'corporation', 'strait', 'council...</td>\n",
       "      <td>0.920416</td>\n",
       "      <td>0.821256</td>\n",
       "      <td>0.919088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42897</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>Q8125662</td>\n",
       "      <td>['movement', 'white', 'category', 'people', 'w...</td>\n",
       "      <td>0.893367</td>\n",
       "      <td>0.817041</td>\n",
       "      <td>0.882048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40087</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>Q106677040</td>\n",
       "      <td>['white', 'category', 'people', 'ethnoracial',...</td>\n",
       "      <td>0.892952</td>\n",
       "      <td>0.873420</td>\n",
       "      <td>0.900122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39323</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>Q2072081</td>\n",
       "      <td>['state', 'person', 'white', 'people', 'color'...</td>\n",
       "      <td>0.886583</td>\n",
       "      <td>0.859105</td>\n",
       "      <td>0.894965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40228</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>Q2560112</td>\n",
       "      <td>['separatism', 'movement', 'supremacy', 'white...</td>\n",
       "      <td>0.882116</td>\n",
       "      <td>0.798548</td>\n",
       "      <td>0.872482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39399</th>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>Q278929</td>\n",
       "      <td>['movement', 'nationalism', 'pan', 'white', 'd...</td>\n",
       "      <td>0.879718</td>\n",
       "      <td>0.823224</td>\n",
       "      <td>0.879991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lemma        term      hit_id  \\\n",
       "87351  aboriginal  aboriginal     Q103817   \n",
       "87882  aboriginal  aboriginal   Q96200400   \n",
       "88901  aboriginal  aboriginal    Q7980672   \n",
       "87611  aboriginal  aboriginal   Q28942344   \n",
       "88372  aboriginal  aboriginal    Q8039318   \n",
       "...           ...         ...         ...   \n",
       "42897       white       white    Q8125662   \n",
       "40087       white       white  Q106677040   \n",
       "39323       white       white    Q2072081   \n",
       "40228       white       white    Q2560112   \n",
       "39399       white       white     Q278929   \n",
       "\n",
       "                                                     bow     cs_rm     cs_wm  \\\n",
       "87351  ['culture', 'aboriginal', 'minority', 'descend...  0.947705  0.820495   \n",
       "87882  ['statement', 'state', 'territorial', 'buildin...  0.937666  0.814829   \n",
       "88901  ['language', 'area', 'event', 'recognised', 'p...  0.929123  0.814358   \n",
       "87611  ['aboriginal', 'people', 'community', 'indigen...  0.921723  0.842450   \n",
       "88372  ['victoria', 'corporation', 'strait', 'council...  0.920416  0.821256   \n",
       "...                                                  ...       ...       ...   \n",
       "42897  ['movement', 'white', 'category', 'people', 'w...  0.893367  0.817041   \n",
       "40087  ['white', 'category', 'people', 'ethnoracial',...  0.892952  0.873420   \n",
       "39323  ['state', 'person', 'white', 'people', 'color'...  0.886583  0.859105   \n",
       "40228  ['separatism', 'movement', 'supremacy', 'white...  0.882116  0.798548   \n",
       "39399  ['movement', 'nationalism', 'pan', 'white', 'd...  0.879718  0.823224   \n",
       "\n",
       "       cs_rm_wm  \n",
       "87351  0.945303  \n",
       "87882  0.938606  \n",
       "88901  0.929588  \n",
       "87611  0.924107  \n",
       "88372  0.919088  \n",
       "...         ...  \n",
       "42897  0.882048  \n",
       "40087  0.900122  \n",
       "39323  0.894965  \n",
       "40228  0.872482  \n",
       "39399  0.879991  \n",
       "\n",
       "[681 rows x 7 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_by_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wd_en_quartiles['q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_entities = []\n",
    "q2_entities = []\n",
    "q3_entities = []\n",
    "q4_entities = []\n",
    "\n",
    "for group in top_10_by_lemma.groupby('lemma'):\n",
    "    if group[0] in wd_en_quartiles['q1']:\n",
    "        q1_entities.extend(group[1]['hit_id'].to_list())\n",
    "        \n",
    "    if group[0] in wd_en_quartiles['q2']:\n",
    "        q2_entities.extend(group[1]['hit_id'].to_list())\n",
    "        \n",
    "    if group[0] in wd_en_quartiles['q3']:\n",
    "        q3_entities.extend(group[1]['hit_id'].to_list())\n",
    "        \n",
    "    if group[0] in wd_en_quartiles['q4']:\n",
    "        q4_entities.extend(group[1]['hit_id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q4_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random entities from each quartile\n",
    "random_subset = []\n",
    "\n",
    "random_subset.extend(random.choices(q1_entities, k=10))\n",
    "random_subset.extend(random.choices(q2_entities, k=10))\n",
    "random_subset.extend(random.choices(q3_entities, k=10))\n",
    "random_subset.extend(random.choices(q4_entities, k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(random_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_annotated = pd.read_csv('/Users/anesterov/reps/LODlit/Wikidata/annotated/wd_en_rm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_subset = pd.DataFrame()\n",
    "\n",
    "for row in wd_annotated.iterrows():\n",
    "    if row[1]['entity_id'] in random_subset:\n",
    "        annotated_subset = annotated_subset.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lemmas\n",
    "lemmas = []\n",
    "for row in annotated_subset.iterrows():\n",
    "    for lemma, wordforms in query_terms['en'].items():\n",
    "        if row[1]['term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_subset.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_subset.drop_duplicates(subset=[\"entity_id\",\"lemma\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_subset.to_csv('/Users/anesterov/reps/LODlit/Wikidata/annotated/subset_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_id in random_subset:\n",
    "    if e_id not in wd_annotated[\"entity_id\"].to_list():\n",
    "        print(e_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
