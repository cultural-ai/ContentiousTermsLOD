{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing related matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/wordsmatter/related_matches/rm.json','r') as jf:\n",
    "    rms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related matches from ODWN are in a separate file\n",
    "with open('/Users/anesterov/reps/LODlit/bg/related_matches_odwn.json','r') as jf:\n",
    "    rms_odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms with lemmas\n",
    "with open('/Users/anesterov/reps/LODlit/query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_term(query_term:str, lang:str) -> str:\n",
    "    '''\n",
    "    Getting a lemma of a query term\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns str, 'not found' if lemma was not found\n",
    "    '''\n",
    "    \n",
    "    return_lemma = 'not found'\n",
    "    \n",
    "    # importing query terms with lemmas\n",
    "    # change path to GitHub\n",
    "    \n",
    "    with open('/Users/anesterov/reps/LODlit/query_terms.json','r') as jf:\n",
    "        query_terms = json.load(jf)\n",
    "        \n",
    "    for lemma, qt in query_terms[lang].items():\n",
    "        if query_term in qt:\n",
    "            return_lemma = lemma\n",
    "            \n",
    "    return return_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many query terms are associated with related matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing bg info\n",
    "with open('/Users/anesterov/reps/LODlit/bg/background_info_bows.json','r') as jf:\n",
    "    bg_info = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN \n",
    "no_rm = []\n",
    "for query_term, bows in bg_info[\"en\"].items():\n",
    "    if bows.get(\"wm\") != None and len(bows) == 1:\n",
    "        no_rm.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baboo',\n",
       " 'bush negro',\n",
       " 'full blood',\n",
       " 'half-blood',\n",
       " 'low-income countries',\n",
       " 'roots'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([get_lemma_by_term(term,'en') for term in no_rm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL \n",
    "no_rm_nl = []\n",
    "for query_term, bows in bg_info[\"nl\"].items():\n",
    "    if bows.get(\"wm\") != None and len(bows) == 1:\n",
    "        no_rm_nl.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_rm_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exotisch', 'oriÃ«ntaals', 'roots', 'traditioneel', 'volbloed'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([get_lemma_by_term(term,'nl') for term in no_rm_nl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing search results and generating a subset with related matches for every resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rm_subset(resource_data:dict, rm_data:dict, resource:str, lang:str) -> dict:\n",
    "    '''\n",
    "    Retrieves info about entities that are related matches\n",
    "    resource_data: dict, search results in a resource\n",
    "    rm_data: dict, info about related matches ('rm.json')\n",
    "    resource: str, 'wikidata', 'aat', 'pwn', 'odwn'\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns dict \n",
    "    '''\n",
    "    results = {}\n",
    "\n",
    "    for query_term, value in resource_data.items():\n",
    "        \n",
    "        hits_by_query_term = []\n",
    "    \n",
    "        for rm_info in rm_data.values():\n",
    "            \n",
    "            if rm_info['lang'] == lang and query_term in rm_info['query_terms']:\n",
    "                for hit in value:\n",
    "                    \n",
    "                    # checking resource\n",
    "                    \n",
    "                    if resource == 'wikidata':\n",
    "                        \n",
    "                        if hit.get('QID') == rm_info['related_matches']['wikidata'][0]:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    if resource == 'aat':\n",
    "                        \n",
    "                        if hit.get('aat_uri') == rm_info['related_matches']['aat'][0]:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    if resource == 'pwn':\n",
    "                        \n",
    "                        if hit.get('synset_id') in rm_info['related_matches']['pwn']:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    # ODWN is handled separately\n",
    "                            \n",
    "        results[query_term] = hits_by_query_term\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/LODlit_local/wd/jan31/results_clean_en.json','r') as jf:\n",
    "    wd_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_wd_en = generate_rm_subset(wd_en,rms,\"wikidata\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_wd_en.json', 'w') as jf:\n",
    "    json.dump(rm_wd_en, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/LODlit_local/wd/jan31/results_clean_nl.json','r') as jf:\n",
    "    wd_nl = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_wd_nl = generate_rm_subset(wd_nl,rms,\"wikidata\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_wd_nl.json', 'w') as jf:\n",
    "    json.dump(rm_wd_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAT EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/AAT/aat_query_results_en.json','r') as jf:\n",
    "    aat_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_aat_en = generate_rm_subset(aat_en,rms,\"aat\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_aat_en.json', 'w') as jf:\n",
    "    json.dump(rm_aat_en, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAT NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/AAT/aat_query_results_nl.json','r') as jf:\n",
    "    aat_nl = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_aat_nl = generate_rm_subset(aat_nl,rms,\"aat\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_aat_nl.json', 'w') as jf:\n",
    "    json.dump(rm_aat_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/PWN/pwn31_query_results.json','r') as jf:\n",
    "    pwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_pwn = generate_rm_subset(pwn,rms,\"pwn\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_pwn.json', 'w') as jf:\n",
    "    json.dump(rm_pwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/ODWN/odwn_query_results.json','r') as jf:\n",
    "    odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_odwn = {}\n",
    "\n",
    "for query_term, value in odwn.items():\n",
    "    \n",
    "    hits_by_query_term = []\n",
    "    \n",
    "    for rm_info in rms_odwn.values():\n",
    "        if query_term in rm_info['query_terms']:\n",
    "            \n",
    "            for hit in value:\n",
    "                # all related matches in ODWN have LE_id\n",
    "                if hit.get('le_id') in rm_info['odwn_le']:\n",
    "                    hits_by_query_term.append(hit)\n",
    "                    \n",
    "    rm_odwn[query_term] = hits_by_query_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/anesterov/reps/LODlit/rm/rm_odwn.json', 'w') as jf:\n",
    "    json.dump(rm_odwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N unique related matches per resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata EN: 58\n"
     ]
    }
   ],
   "source": [
    "quids = []\n",
    "\n",
    "for rm_info in rm_wd_en.values():\n",
    "    quids.extend([hit['QID'] for hit in rm_info])\n",
    "    \n",
    "print(\"Wikidata EN:\",len(set(quids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata NL: 63\n"
     ]
    }
   ],
   "source": [
    "quids = []\n",
    "\n",
    "for rm_info in rm_wd_nl.values():\n",
    "    quids.extend([hit['QID'] for hit in rm_info])\n",
    "    \n",
    "print(\"Wikidata NL:\",len(set(quids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAT EN: 37\n"
     ]
    }
   ],
   "source": [
    "aat_uris = []\n",
    "\n",
    "for rm_info in rm_aat_en.values():\n",
    "    aat_uris.extend([hit['aat_uri'] for hit in rm_info])\n",
    "    \n",
    "print(\"AAT EN:\",len(set(aat_uris)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAT NL: 27\n"
     ]
    }
   ],
   "source": [
    "aat_uris = []\n",
    "\n",
    "for rm_info in rm_aat_nl.values():\n",
    "    aat_uris.extend([hit['aat_uri'] for hit in rm_info])\n",
    "    \n",
    "print(\"AAT NL:\",len(set(aat_uris)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PWN: 81\n"
     ]
    }
   ],
   "source": [
    "pwn_synsets = []\n",
    "\n",
    "for rm_info in rm_pwn.values():\n",
    "    pwn_synsets.extend([hit['synset_id'] for hit in rm_info])\n",
    "    \n",
    "print(\"PWN:\",len(set(pwn_synsets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODWN: 65\n"
     ]
    }
   ],
   "source": [
    "odwn_le = []\n",
    "\n",
    "for rm_info in rm_odwn.values():\n",
    "    odwn_le.extend([hit['le_id'] for hit in rm_info])\n",
    "    \n",
    "print(\"ODWN:\",len(set(odwn_le)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview by properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from statistics import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurences = []\n",
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences.append(hit[\"found_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'prefLabel': 44, 'aliases': 67, 'description': 4})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hits = 0\n",
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    total_hits += len(rm_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descent\n",
      "homosexual\n",
      "indo\n",
      "primitive\n"
     ]
    }
   ],
   "source": [
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    for hit in rm_info:\n",
    "        if hit[\"found_in\"] == 'description':\n",
    "            print(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL wikidata\n",
    "all_occurences_nl = []\n",
    "for query_term, rm_info in rm_wd_nl.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_nl.append(hit[\"found_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'prefLabel': 51, 'aliases': 53})"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_occurences_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'prefLabel': 23, 'altLabel': 60, 'scopeNote': 10})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EN AAT\n",
    "all_occurences_aat_en = []\n",
    "for query_term, rm_info in rm_aat_en.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_aat_en.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_aat_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_occurences_aat_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'prefLabel': 25, 'scopeNote': 6, 'altLabel': 11})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NL AAT\n",
    "all_occurences_aat_nl = []\n",
    "for query_term, rm_info in rm_aat_nl.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_aat_nl.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_aat_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_occurences_aat_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'lemmata': 90, 'definition': 11, 'examples': 36})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PWN\n",
    "all_occurences_pwn = []\n",
    "for query_term, rm_info in rm_pwn.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_pwn.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_pwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_occurences_pwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'le': 66, 'sense_examples': 38, 'sense_definition': 2})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ODWN\n",
    "all_occurences_odwn = []\n",
    "for query_term, rm_info in rm_odwn.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_odwn.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_odwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_occurences_odwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Counter(all_occurences_odwn).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an overview for all resources\n",
    "# EN\n",
    "with open('rm_stats_en.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"query_term\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"pwn_le\",\"pwn_def\",\"pwn_examples\",\"pwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for query_term in rm_wd_en.keys():\n",
    "        \n",
    "        # wikidata\n",
    "        wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_en[query_term]])\n",
    "        wd_pref = wd_hits.get('prefLabel')\n",
    "        wd_aliases = wd_hits.get('aliases')\n",
    "        wd_descr = wd_hits.get('description')\n",
    "        wd_total = sum(Counter(wd_hits).values())\n",
    "        \n",
    "        # aat\n",
    "        aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_en[query_term]])\n",
    "        aat_pref = aat_hits.get('prefLabel')\n",
    "        aat_alt = aat_hits.get('altLabel')\n",
    "        aat_scopeNote = aat_hits.get('scopeNote')\n",
    "        aat_total = sum(Counter(aat_hits).values())\n",
    "        \n",
    "        # pwn\n",
    "        pwn_hits = Counter([hit[\"found_in\"] for hit in rm_pwn[query_term]])\n",
    "        pwn_le = pwn_hits.get('lemmata')\n",
    "        pwn_def = pwn_hits.get('definition')\n",
    "        pwn_examples = pwn_hits.get('examples')\n",
    "        pwn_total = sum(Counter(pwn_hits).values())\n",
    "        \n",
    "        total_hits = wd_total + aat_total + pwn_total\n",
    "        \n",
    "        data = [query_term,\"en\",wd_pref,wd_aliases,wd_descr,wd_total,aat_pref,aat_alt,aat_scopeNote,aat_total,\\\n",
    "               pwn_le,pwn_def,pwn_examples,pwn_total,total_hits]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which terms and lemmas have no hits\n",
    "# EN\n",
    "\n",
    "no_hits = []\n",
    "\n",
    "for query_term in rm_wd_en.keys():\n",
    "        \n",
    "    # wikidata\n",
    "    wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_en[query_term]])\n",
    "    wd_pref = wd_hits.get('prefLabel')\n",
    "    wd_aliases = wd_hits.get('aliases')\n",
    "    wd_descr = wd_hits.get('description')\n",
    "    wd_total = sum(Counter(wd_hits).values())\n",
    "\n",
    "    # aat\n",
    "    aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_en[query_term]])\n",
    "    aat_pref = aat_hits.get('prefLabel')\n",
    "    aat_alt = aat_hits.get('altLabel')\n",
    "    aat_scopeNote = aat_hits.get('scopeNote')\n",
    "    aat_total = sum(Counter(aat_hits).values())\n",
    "\n",
    "    # pwn\n",
    "    pwn_hits = Counter([hit[\"found_in\"] for hit in rm_pwn[query_term]])\n",
    "    pwn_le = pwn_hits.get('lemmata')\n",
    "    pwn_def = pwn_hits.get('definition')\n",
    "    pwn_examples = pwn_hits.get('examples')\n",
    "    pwn_total = sum(Counter(pwn_hits).values())\n",
    "\n",
    "    total_hits = wd_total + aat_total + pwn_total\n",
    "\n",
    "    if total_hits == 0:\n",
    "        no_hits.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low-income countries\n",
      "baboo\n",
      "bush negro\n",
      "roots\n",
      "half-blood\n",
      "full blood\n"
     ]
    }
   ],
   "source": [
    "for lemma, wordforms in query_terms['en'].items():\n",
    "    k = 0\n",
    "    for w in wordforms:\n",
    "        if w in no_hits:\n",
    "            k += 1\n",
    "            \n",
    "    if k == len(wordforms):\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "with open('rm_stats_nl.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"query_term\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"odwn_le\",\"odwn_sense_examples\",\"odwn_sense_definition\",\"odwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for query_term in rm_wd_nl.keys():\n",
    "        \n",
    "        # wikidata\n",
    "        wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_nl[query_term]])\n",
    "        wd_pref = wd_hits.get('prefLabel')\n",
    "        wd_aliases = wd_hits.get('aliases')\n",
    "        wd_descr = wd_hits.get('description')\n",
    "        wd_total = sum(Counter(wd_hits).values())\n",
    "        \n",
    "        # aat\n",
    "        aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_nl[query_term]])\n",
    "        aat_pref = aat_hits.get('prefLabel')\n",
    "        aat_alt = aat_hits.get('altLabel')\n",
    "        aat_scopeNote = aat_hits.get('scopeNote')\n",
    "        aat_total = sum(Counter(aat_hits).values())\n",
    "        \n",
    "        # pwn\n",
    "        odwn_hits = Counter([hit[\"found_in\"] for hit in rm_odwn[query_term]])\n",
    "        odwn_le = odwn_hits.get('le')\n",
    "        odwn_sense_ex = odwn_hits.get('sense_examples')\n",
    "        odwn_sense_def = odwn_hits.get('sense_definition')\n",
    "        odwn_total = sum(Counter(odwn_hits).values())\n",
    "        \n",
    "        total_hits = wd_total + aat_total + odwn_total\n",
    "        \n",
    "        data = [query_term,\"nl\",wd_pref,wd_aliases,wd_descr,wd_total,aat_pref,aat_alt,aat_scopeNote,aat_total,\\\n",
    "               odwn_le,odwn_sense_ex,odwn_sense_def,odwn_total,total_hits]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which terms and lemmas have no hits\n",
    "# NL\n",
    "no_hits = []\n",
    "\n",
    "for query_term in rm_wd_nl.keys():\n",
    "        \n",
    "    # wikidata\n",
    "    wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_nl[query_term]])\n",
    "    wd_pref = wd_hits.get('prefLabel')\n",
    "    wd_aliases = wd_hits.get('aliases')\n",
    "    wd_descr = wd_hits.get('description')\n",
    "    wd_total = sum(Counter(wd_hits).values())\n",
    "\n",
    "    # aat\n",
    "    aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_nl[query_term]])\n",
    "    aat_pref = aat_hits.get('prefLabel')\n",
    "    aat_alt = aat_hits.get('altLabel')\n",
    "    aat_scopeNote = aat_hits.get('scopeNote')\n",
    "    aat_total = sum(Counter(aat_hits).values())\n",
    "\n",
    "    # pwn\n",
    "    odwn_hits = Counter([hit[\"found_in\"] for hit in rm_odwn[query_term]])\n",
    "    odwn_le = odwn_hits.get('le')\n",
    "    odwn_sense_ex = odwn_hits.get('sense_examples')\n",
    "    odwn_sense_def = odwn_hits.get('sense_definition')\n",
    "    odwn_total = sum(Counter(odwn_hits).values())\n",
    "\n",
    "    total_hits = wd_total + aat_total + odwn_total\n",
    "    \n",
    "    if total_hits == 0:\n",
    "        no_hits.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exotisch\n",
      "oriÃ«ntaals\n",
      "traditioneel\n",
      "roots\n",
      "volbloed\n"
     ]
    }
   ],
   "source": [
    "for lemma, wordforms in query_terms['nl'].items():\n",
    "    k = 0\n",
    "    for w in wordforms:\n",
    "        if w in no_hits:\n",
    "            k += 1\n",
    "            \n",
    "    if k == len(wordforms):\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview by lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en = pd.read_csv('/Users/anesterov/reps/LODlit/rm/rm_stats_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_term</th>\n",
       "      <th>lang</th>\n",
       "      <th>wd_pref</th>\n",
       "      <th>wd_aliases</th>\n",
       "      <th>wd_descr</th>\n",
       "      <th>wd_total</th>\n",
       "      <th>aat_pref</th>\n",
       "      <th>aat_alt</th>\n",
       "      <th>aat_scopeNote</th>\n",
       "      <th>aat_total</th>\n",
       "      <th>pwn_le</th>\n",
       "      <th>pwn_def</th>\n",
       "      <th>pwn_examples</th>\n",
       "      <th>pwn_total</th>\n",
       "      <th>total_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batavias</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batavia</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>southern rhodesia</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>madras</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low-income country</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>full blood</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>metis</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>mÃ©tis</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>tribes</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>tribe</td>\n",
       "      <td>en</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             query_term lang  wd_pref  wd_aliases  wd_descr  wd_total  \\\n",
       "0              batavias   en      0.0         0.0       0.0         0   \n",
       "1               batavia   en      1.0         0.0       0.0         1   \n",
       "2     southern rhodesia   en      1.0         0.0       0.0         1   \n",
       "3                madras   en      0.0         1.0       0.0         1   \n",
       "4    low-income country   en      0.0         0.0       0.0         0   \n",
       "..                  ...  ...      ...         ...       ...       ...   \n",
       "149          full blood   en      0.0         0.0       0.0         0   \n",
       "150               metis   en      0.0         1.0       0.0         1   \n",
       "151               mÃ©tis   en      1.0         0.0       0.0         1   \n",
       "152              tribes   en      0.0         0.0       0.0         0   \n",
       "153               tribe   en      1.0         1.0       0.0         2   \n",
       "\n",
       "     aat_pref  aat_alt  aat_scopeNote  aat_total  pwn_le  pwn_def  \\\n",
       "0         0.0      0.0            0.0          0     0.0      0.0   \n",
       "1         0.0      0.0            0.0          0     0.0      0.0   \n",
       "2         0.0      0.0            0.0          0     0.0      0.0   \n",
       "3         0.0      0.0            0.0          0     1.0      1.0   \n",
       "4         0.0      0.0            0.0          0     0.0      0.0   \n",
       "..        ...      ...            ...        ...     ...      ...   \n",
       "149       0.0      0.0            0.0          0     0.0      0.0   \n",
       "150       1.0      0.0            1.0          2     0.0      0.0   \n",
       "151       0.0      1.0            0.0          1     0.0      0.0   \n",
       "152       1.0      0.0            0.0          1     0.0      0.0   \n",
       "153       0.0      1.0            0.0          1     3.0      0.0   \n",
       "\n",
       "     pwn_examples  pwn_total  total_hits  \n",
       "0             0.0          0           0  \n",
       "1             0.0          0           1  \n",
       "2             0.0          0           1  \n",
       "3             0.0          2           3  \n",
       "4             0.0          0           0  \n",
       "..            ...        ...         ...  \n",
       "149           0.0          0           0  \n",
       "150           0.0          0           3  \n",
       "151           0.0          0           2  \n",
       "152           0.0          0           1  \n",
       "153           0.0          3           6  \n",
       "\n",
       "[154 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas column for each query term EN\n",
    "lemmas = []\n",
    "for row in stats_en.iterrows():\n",
    "    for lemma, wordforms in query_terms['en'].items():\n",
    "        if row[1]['query_term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas EN\n",
    "\n",
    "with open('rm_stats_by_lemma_en.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"pwn_le\",\"pwn_def\",\"pwn_examples\",\"pwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    for lemma_group in stats_en.groupby(\"lemma\"):\n",
    "        data = [lemma_group[0],\"en\",sum(lemma_group[1]['wd_pref']),sum(lemma_group[1]['wd_aliases']),\\\n",
    "              sum(lemma_group[1]['wd_descr']),sum(lemma_group[1]['wd_total']),\\\n",
    "              sum(lemma_group[1]['aat_pref']),sum(lemma_group[1]['aat_alt']),\\\n",
    "              sum(lemma_group[1]['aat_scopeNote']),sum(lemma_group[1]['aat_total']),\\\n",
    "              sum(lemma_group[1]['pwn_le']),sum(lemma_group[1]['pwn_def']),\\\n",
    "              sum(lemma_group[1]['pwn_examples']),sum(lemma_group[1]['pwn_total']),\\\n",
    "              sum(lemma_group[1]['total_hits'])]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl = pd.read_csv('/Users/anesterov/reps/LODlit/rm/rm_stats_nl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas column for each query term EN\n",
    "lemmas = []\n",
    "for row in stats_nl.iterrows():\n",
    "    for lemma, wordforms in query_terms['nl'].items():\n",
    "        if row[1]['query_term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>query_term</th>\n",
       "      <th>lang</th>\n",
       "      <th>wd_pref</th>\n",
       "      <th>wd_aliases</th>\n",
       "      <th>wd_descr</th>\n",
       "      <th>wd_total</th>\n",
       "      <th>aat_pref</th>\n",
       "      <th>aat_alt</th>\n",
       "      <th>aat_scopeNote</th>\n",
       "      <th>aat_total</th>\n",
       "      <th>odwn_le</th>\n",
       "      <th>odwn_sense_examples</th>\n",
       "      <th>odwn_sense_definition</th>\n",
       "      <th>odwn_total</th>\n",
       "      <th>total_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politionele actie</td>\n",
       "      <td>politionele acties</td>\n",
       "      <td>nl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politionele actie</td>\n",
       "      <td>politionele actie</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>birma</td>\n",
       "      <td>birma</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exotisch</td>\n",
       "      <td>exotische</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exotisch</td>\n",
       "      <td>exotischere</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>inheems</td>\n",
       "      <td>inheemst</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>inheems</td>\n",
       "      <td>inheemser</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>inheems</td>\n",
       "      <td>inheems</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>trans</td>\n",
       "      <td>transen</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>trans</td>\n",
       "      <td>trans</td>\n",
       "      <td>nl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows Ã 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lemma          query_term lang  wd_pref  wd_aliases  \\\n",
       "0    politionele actie  politionele acties   nl      1.0         0.0   \n",
       "1    politionele actie   politionele actie   nl      0.0         0.0   \n",
       "2                birma               birma   nl      0.0         1.0   \n",
       "3             exotisch           exotische   nl      0.0         0.0   \n",
       "4             exotisch         exotischere   nl      0.0         0.0   \n",
       "..                 ...                 ...  ...      ...         ...   \n",
       "237            inheems            inheemst   nl      0.0         0.0   \n",
       "238            inheems           inheemser   nl      0.0         0.0   \n",
       "239            inheems             inheems   nl      0.0         1.0   \n",
       "240              trans             transen   nl      0.0         0.0   \n",
       "241              trans               trans   nl      0.0         0.0   \n",
       "\n",
       "     wd_descr  wd_total  aat_pref  aat_alt  aat_scopeNote  aat_total  odwn_le  \\\n",
       "0         0.0         1       0.0      0.0            0.0          0      0.0   \n",
       "1         0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "2         0.0         1       0.0      0.0            0.0          0      1.0   \n",
       "3         0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "4         0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "..        ...       ...       ...      ...            ...        ...      ...   \n",
       "237       0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "238       0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "239       0.0         1       0.0      0.0            0.0          0      0.0   \n",
       "240       0.0         0       0.0      0.0            0.0          0      0.0   \n",
       "241       0.0         0       0.0      0.0            0.0          0      1.0   \n",
       "\n",
       "     odwn_sense_examples  odwn_sense_definition  odwn_total  total_hits  \n",
       "0                    0.0                    0.0           0           1  \n",
       "1                    0.0                    0.0           0           0  \n",
       "2                    0.0                    0.0           1           2  \n",
       "3                    0.0                    0.0           0           0  \n",
       "4                    0.0                    0.0           0           0  \n",
       "..                   ...                    ...         ...         ...  \n",
       "237                  0.0                    0.0           0           0  \n",
       "238                  0.0                    0.0           0           0  \n",
       "239                  0.0                    0.0           0           1  \n",
       "240                  0.0                    0.0           0           0  \n",
       "241                  0.0                    0.0           1           1  \n",
       "\n",
       "[242 rows x 16 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas NL\n",
    "\n",
    "with open('rm_stats_by_lemma_nl.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"odwn_le\",\"odwn_sense_examples\",\"odwn_sense_definition\",\"odwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    for lemma_group in stats_nl.groupby(\"lemma\"):\n",
    "        data = [lemma_group[0],\"nl\",sum(lemma_group[1]['wd_pref']),sum(lemma_group[1]['wd_aliases']),\\\n",
    "              sum(lemma_group[1]['wd_descr']),sum(lemma_group[1]['wd_total']),\\\n",
    "              sum(lemma_group[1]['aat_pref']),sum(lemma_group[1]['aat_alt']),\\\n",
    "              sum(lemma_group[1]['aat_scopeNote']),sum(lemma_group[1]['aat_total']),\\\n",
    "              sum(lemma_group[1]['odwn_le']),sum(lemma_group[1]['odwn_sense_examples']),\\\n",
    "              sum(lemma_group[1]['odwn_sense_definition']),sum(lemma_group[1]['odwn_total']),\\\n",
    "              sum(lemma_group[1]['total_hits'])]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a csv with related matches\n",
    "# group by lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rm_entities_all.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"resource\",\"entity_id\"]\n",
    "    writer.writerow(header)\n",
    "        \n",
    "    # EN wikidata\n",
    "    for query_term, rms in rm_wd_en.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"wikidata\",rm['QID']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # NL wikidata\n",
    "    for query_term, rms in rm_wd_nl.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'nl'),'nl',\"wikidata\",rm['QID']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # EN AAT\n",
    "    for query_term, rms in rm_aat_en.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"aat\",rm['aat_uri']]\n",
    "            writer.writerow(data)\n",
    "    \n",
    "    # NL AAT\n",
    "    for query_term, rms in rm_aat_nl.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'nl'),'nl',\"aat\",rm['aat_uri']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # PWN\n",
    "    for query_term, rms in rm_pwn.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"pwn\",rm['synset_id']] \n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # ODWN\n",
    "    for query_term, rms in rm_odwn.items():\n",
    "        for rm in rms:\n",
    "            if rm['synset_id'] == '':\n",
    "                data = [get_lemma_by_term(query_term,'nl'),'nl',\"odwn\",rm['sense_id']]\n",
    "                writer.writerow(data)\n",
    "            else:\n",
    "                data = [get_lemma_by_term(query_term,'nl'),'nl',\"odwn\",rm['synset_id']]\n",
    "                writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = pd.read_csv(\"/Users/anesterov/reps/LODlit/rm/rm_entities_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities.to_csv(\"/Users/anesterov/reps/LODlit/rm/rm_entities_unique.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_entities = pd.read_csv(\"/Users/anesterov/reps/LODlit/rm/rm_entities_unique.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_wd = rm_entities[rm_entities[\"resource\"] == \"wikidata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_aat = rm_entities[rm_entities[\"resource\"] == \"aat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-7554033aa74d>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  entities_aat_nl = rm_entities[rm_entities[\"resource\"] == \"aat\"][rm_entities[\"lang\"] == \"nl\"]\n"
     ]
    }
   ],
   "source": [
    "entities_aat_nl = rm_entities[rm_entities[\"resource\"] == \"aat\"][rm_entities[\"lang\"] == \"nl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(entities_aat_nl[\"entity_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(entities_wd[\"entity_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(entities_aat[\"entity_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
