{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing related matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from Words Matter KG\n",
    "url = 'https://raw.githubusercontent.com/cultural-ai/wordsmatter/main/related_matches/rm.json'\n",
    "r = requests.get(url)\n",
    "rms = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related matches from ODWN are in a separate file\n",
    "with open('LODlit/bg/related_matches_odwn.json','r') as jf:\n",
    "    rms_odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms with lemmas\n",
    "with open('LODlit/query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_term(query_term:str, lang:str) -> str:\n",
    "    '''\n",
    "    Getting a lemma of a query term\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns str, 'not found' if lemma was not found\n",
    "    '''\n",
    "    \n",
    "    return_lemma = 'not found'\n",
    "    \n",
    "    # importing query terms with lemmas\n",
    "    # change path to GitHub\n",
    "    \n",
    "    with open('LODlit/query_terms.json','r') as jf:\n",
    "        query_terms = json.load(jf)\n",
    "        \n",
    "    for lemma, qt in query_terms[lang].items():\n",
    "        if query_term in qt:\n",
    "            return_lemma = lemma\n",
    "            \n",
    "    return return_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many query terms are associated with related matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing bg info\n",
    "with open('LODlit/bg/background_info_bows.json','r') as jf:\n",
    "    bg_info = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN \n",
    "no_rm = []\n",
    "for query_term, bows in bg_info[\"en\"].items():\n",
    "    if bows.get(\"wm\") != None and len(bows) == 1:\n",
    "        no_rm.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([get_lemma_by_term(term,'en') for term in no_rm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL \n",
    "no_rm_nl = []\n",
    "for query_term, bows in bg_info[\"nl\"].items():\n",
    "    if bows.get(\"wm\") != None and len(bows) == 1:\n",
    "        no_rm_nl.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_rm_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([get_lemma_by_term(term,'nl') for term in no_rm_nl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing search results and generating a subset with related matches for every resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rm_subset(resource_data:dict, rm_data:dict, resource:str, lang:str) -> dict:\n",
    "    '''\n",
    "    Retrieves info about entities that are related matches\n",
    "    resource_data: dict, search results in a resource\n",
    "    rm_data: dict, info about related matches ('rm.json')\n",
    "    resource: str, 'wikidata', 'aat', 'pwn', 'odwn'\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns dict \n",
    "    '''\n",
    "    results = {}\n",
    "\n",
    "    for query_term, value in resource_data.items():\n",
    "        \n",
    "        hits_by_query_term = []\n",
    "    \n",
    "        for rm_info in rm_data.values():\n",
    "            \n",
    "            if rm_info['lang'] == lang and query_term in rm_info['query_terms']:\n",
    "                for hit in value:\n",
    "                    \n",
    "                    # checking resource\n",
    "                    \n",
    "                    if resource == 'wikidata':\n",
    "                        \n",
    "                        if hit.get('QID') == rm_info['related_matches']['wikidata'][0]:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    if resource == 'aat':\n",
    "                        \n",
    "                        if hit.get('aat_uri') == rm_info['related_matches']['aat'][0]:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    if resource == 'pwn':\n",
    "                        \n",
    "                        if hit.get('synset_id') in rm_info['related_matches']['pwn']:\n",
    "                            hits_by_query_term.append(hit)\n",
    "                            \n",
    "                    # ODWN is handled separately\n",
    "                            \n",
    "        results[query_term] = hits_by_query_term\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is gzipped on GitHub with the prefix \"gzip_\"\n",
    "with open('results_clean_en.json','r') as jf:\n",
    "    wd_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_wd_en = generate_rm_subset(wd_en,rms,\"wikidata\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_wd_en.json', 'w') as jf:\n",
    "    json.dump(rm_wd_en, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file is gzipped on GitHub with the prefix \"gzip_\"\n",
    "with open('results_clean_nl.json','r') as jf:\n",
    "    wd_nl = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_wd_nl = generate_rm_subset(wd_nl,rms,\"wikidata\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_wd_nl.json', 'w') as jf:\n",
    "    json.dump(rm_wd_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAT EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/AAT/aat_query_results_en.json','r') as jf:\n",
    "    aat_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_aat_en = generate_rm_subset(aat_en,rms,\"aat\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_aat_en.json', 'w') as jf:\n",
    "    json.dump(rm_aat_en, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAT NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/AAT/aat_query_results_nl.json','r') as jf:\n",
    "    aat_nl = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_aat_nl = generate_rm_subset(aat_nl,rms,\"aat\",\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_aat_nl.json', 'w') as jf:\n",
    "    json.dump(rm_aat_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/PWN/pwn31_query_results.json','r') as jf:\n",
    "    pwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_pwn = generate_rm_subset(pwn,rms,\"pwn\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_pwn.json', 'w') as jf:\n",
    "    json.dump(rm_pwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/ODWN/odwn_query_results.json','r') as jf:\n",
    "    odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_odwn = {}\n",
    "\n",
    "for query_term, value in odwn.items():\n",
    "    \n",
    "    hits_by_query_term = []\n",
    "    \n",
    "    for rm_info in rms_odwn.values():\n",
    "        if query_term in rm_info['query_terms']:\n",
    "            \n",
    "            for hit in value:\n",
    "                # all related matches in ODWN have LE_id\n",
    "                if hit.get('le_id') in rm_info['odwn_le']:\n",
    "                    hits_by_query_term.append(hit)\n",
    "                    \n",
    "    rm_odwn[query_term] = hits_by_query_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LODlit/rm/rm_odwn.json', 'w') as jf:\n",
    "    json.dump(rm_odwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N unique related matches per resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quids = []\n",
    "\n",
    "for rm_info in rm_wd_en.values():\n",
    "    quids.extend([hit['QID'] for hit in rm_info])\n",
    "    \n",
    "print(\"Wikidata EN:\",len(set(quids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quids = []\n",
    "\n",
    "for rm_info in rm_wd_nl.values():\n",
    "    quids.extend([hit['QID'] for hit in rm_info])\n",
    "    \n",
    "print(\"Wikidata NL:\",len(set(quids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_uris = []\n",
    "\n",
    "for rm_info in rm_aat_en.values():\n",
    "    aat_uris.extend([hit['aat_uri'] for hit in rm_info])\n",
    "    \n",
    "print(\"AAT EN:\",len(set(aat_uris)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aat_uris = []\n",
    "\n",
    "for rm_info in rm_aat_nl.values():\n",
    "    aat_uris.extend([hit['aat_uri'] for hit in rm_info])\n",
    "    \n",
    "print(\"AAT NL:\",len(set(aat_uris)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwn_synsets = []\n",
    "\n",
    "for rm_info in rm_pwn.values():\n",
    "    pwn_synsets.extend([hit['synset_id'] for hit in rm_info])\n",
    "    \n",
    "print(\"PWN:\",len(set(pwn_synsets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odwn_le = []\n",
    "\n",
    "for rm_info in rm_odwn.values():\n",
    "    odwn_le.extend([hit['le_id'] for hit in rm_info])\n",
    "    \n",
    "print(\"ODWN:\",len(set(odwn_le)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview by properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from statistics import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occurences = []\n",
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences.append(hit[\"found_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hits = 0\n",
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    total_hits += len(rm_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query_term, rm_info in rm_wd_en.items():\n",
    "    for hit in rm_info:\n",
    "        if hit[\"found_in\"] == 'description':\n",
    "            print(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL wikidata\n",
    "all_occurences_nl = []\n",
    "for query_term, rm_info in rm_wd_nl.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_nl.append(hit[\"found_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_occurences_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN AAT\n",
    "all_occurences_aat_en = []\n",
    "for query_term, rm_info in rm_aat_en.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_aat_en.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_aat_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_occurences_aat_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL AAT\n",
    "all_occurences_aat_nl = []\n",
    "for query_term, rm_info in rm_aat_nl.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_aat_nl.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_aat_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_occurences_aat_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWN\n",
    "all_occurences_pwn = []\n",
    "for query_term, rm_info in rm_pwn.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_pwn.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_pwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_occurences_pwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODWN\n",
    "all_occurences_odwn = []\n",
    "for query_term, rm_info in rm_odwn.items():\n",
    "    for hit in rm_info:\n",
    "        all_occurences_odwn.append(hit[\"found_in\"])\n",
    "Counter(all_occurences_odwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_occurences_odwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Counter(all_occurences_odwn).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an overview for all resources\n",
    "# EN\n",
    "with open('rm_stats_en.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"query_term\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"pwn_le\",\"pwn_def\",\"pwn_examples\",\"pwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for query_term in rm_wd_en.keys():\n",
    "        \n",
    "        # wikidata\n",
    "        wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_en[query_term]])\n",
    "        wd_pref = wd_hits.get('prefLabel')\n",
    "        wd_aliases = wd_hits.get('aliases')\n",
    "        wd_descr = wd_hits.get('description')\n",
    "        wd_total = sum(Counter(wd_hits).values())\n",
    "        \n",
    "        # aat\n",
    "        aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_en[query_term]])\n",
    "        aat_pref = aat_hits.get('prefLabel')\n",
    "        aat_alt = aat_hits.get('altLabel')\n",
    "        aat_scopeNote = aat_hits.get('scopeNote')\n",
    "        aat_total = sum(Counter(aat_hits).values())\n",
    "        \n",
    "        # pwn\n",
    "        pwn_hits = Counter([hit[\"found_in\"] for hit in rm_pwn[query_term]])\n",
    "        pwn_le = pwn_hits.get('lemmata')\n",
    "        pwn_def = pwn_hits.get('definition')\n",
    "        pwn_examples = pwn_hits.get('examples')\n",
    "        pwn_total = sum(Counter(pwn_hits).values())\n",
    "        \n",
    "        total_hits = wd_total + aat_total + pwn_total\n",
    "        \n",
    "        data = [query_term,\"en\",wd_pref,wd_aliases,wd_descr,wd_total,aat_pref,aat_alt,aat_scopeNote,aat_total,\\\n",
    "               pwn_le,pwn_def,pwn_examples,pwn_total,total_hits]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which terms and lemmas have no hits\n",
    "# EN\n",
    "\n",
    "no_hits = []\n",
    "\n",
    "for query_term in rm_wd_en.keys():\n",
    "        \n",
    "    # wikidata\n",
    "    wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_en[query_term]])\n",
    "    wd_pref = wd_hits.get('prefLabel')\n",
    "    wd_aliases = wd_hits.get('aliases')\n",
    "    wd_descr = wd_hits.get('description')\n",
    "    wd_total = sum(Counter(wd_hits).values())\n",
    "\n",
    "    # aat\n",
    "    aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_en[query_term]])\n",
    "    aat_pref = aat_hits.get('prefLabel')\n",
    "    aat_alt = aat_hits.get('altLabel')\n",
    "    aat_scopeNote = aat_hits.get('scopeNote')\n",
    "    aat_total = sum(Counter(aat_hits).values())\n",
    "\n",
    "    # pwn\n",
    "    pwn_hits = Counter([hit[\"found_in\"] for hit in rm_pwn[query_term]])\n",
    "    pwn_le = pwn_hits.get('lemmata')\n",
    "    pwn_def = pwn_hits.get('definition')\n",
    "    pwn_examples = pwn_hits.get('examples')\n",
    "    pwn_total = sum(Counter(pwn_hits).values())\n",
    "\n",
    "    total_hits = wd_total + aat_total + pwn_total\n",
    "\n",
    "    if total_hits == 0:\n",
    "        no_hits.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma, wordforms in query_terms['en'].items():\n",
    "    k = 0\n",
    "    for w in wordforms:\n",
    "        if w in no_hits:\n",
    "            k += 1\n",
    "            \n",
    "    if k == len(wordforms):\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "with open('rm_stats_nl.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"query_term\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"odwn_le\",\"odwn_sense_examples\",\"odwn_sense_definition\",\"odwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for query_term in rm_wd_nl.keys():\n",
    "        \n",
    "        # wikidata\n",
    "        wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_nl[query_term]])\n",
    "        wd_pref = wd_hits.get('prefLabel')\n",
    "        wd_aliases = wd_hits.get('aliases')\n",
    "        wd_descr = wd_hits.get('description')\n",
    "        wd_total = sum(Counter(wd_hits).values())\n",
    "        \n",
    "        # aat\n",
    "        aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_nl[query_term]])\n",
    "        aat_pref = aat_hits.get('prefLabel')\n",
    "        aat_alt = aat_hits.get('altLabel')\n",
    "        aat_scopeNote = aat_hits.get('scopeNote')\n",
    "        aat_total = sum(Counter(aat_hits).values())\n",
    "        \n",
    "        # pwn\n",
    "        odwn_hits = Counter([hit[\"found_in\"] for hit in rm_odwn[query_term]])\n",
    "        odwn_le = odwn_hits.get('le')\n",
    "        odwn_sense_ex = odwn_hits.get('sense_examples')\n",
    "        odwn_sense_def = odwn_hits.get('sense_definition')\n",
    "        odwn_total = sum(Counter(odwn_hits).values())\n",
    "        \n",
    "        total_hits = wd_total + aat_total + odwn_total\n",
    "        \n",
    "        data = [query_term,\"nl\",wd_pref,wd_aliases,wd_descr,wd_total,aat_pref,aat_alt,aat_scopeNote,aat_total,\\\n",
    "               odwn_le,odwn_sense_ex,odwn_sense_def,odwn_total,total_hits]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which terms and lemmas have no hits\n",
    "# NL\n",
    "no_hits = []\n",
    "\n",
    "for query_term in rm_wd_nl.keys():\n",
    "        \n",
    "    # wikidata\n",
    "    wd_hits = Counter([hit[\"found_in\"] for hit in rm_wd_nl[query_term]])\n",
    "    wd_pref = wd_hits.get('prefLabel')\n",
    "    wd_aliases = wd_hits.get('aliases')\n",
    "    wd_descr = wd_hits.get('description')\n",
    "    wd_total = sum(Counter(wd_hits).values())\n",
    "\n",
    "    # aat\n",
    "    aat_hits = Counter([hit[\"found_in\"] for hit in rm_aat_nl[query_term]])\n",
    "    aat_pref = aat_hits.get('prefLabel')\n",
    "    aat_alt = aat_hits.get('altLabel')\n",
    "    aat_scopeNote = aat_hits.get('scopeNote')\n",
    "    aat_total = sum(Counter(aat_hits).values())\n",
    "\n",
    "    # pwn\n",
    "    odwn_hits = Counter([hit[\"found_in\"] for hit in rm_odwn[query_term]])\n",
    "    odwn_le = odwn_hits.get('le')\n",
    "    odwn_sense_ex = odwn_hits.get('sense_examples')\n",
    "    odwn_sense_def = odwn_hits.get('sense_definition')\n",
    "    odwn_total = sum(Counter(odwn_hits).values())\n",
    "\n",
    "    total_hits = wd_total + aat_total + odwn_total\n",
    "    \n",
    "    if total_hits == 0:\n",
    "        no_hits.append(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma, wordforms in query_terms['nl'].items():\n",
    "    k = 0\n",
    "    for w in wordforms:\n",
    "        if w in no_hits:\n",
    "            k += 1\n",
    "            \n",
    "    if k == len(wordforms):\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview by lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en = pd.read_csv('LODlit/rm/rm_stats_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas column for each query term EN\n",
    "lemmas = []\n",
    "for row in stats_en.iterrows():\n",
    "    for lemma, wordforms in query_terms['en'].items():\n",
    "        if row[1]['query_term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_en.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas EN\n",
    "\n",
    "with open('rm_stats_by_lemma_en.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"pwn_le\",\"pwn_def\",\"pwn_examples\",\"pwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    for lemma_group in stats_en.groupby(\"lemma\"):\n",
    "        data = [lemma_group[0],\"en\",sum(lemma_group[1]['wd_pref']),sum(lemma_group[1]['wd_aliases']),\\\n",
    "              sum(lemma_group[1]['wd_descr']),sum(lemma_group[1]['wd_total']),\\\n",
    "              sum(lemma_group[1]['aat_pref']),sum(lemma_group[1]['aat_alt']),\\\n",
    "              sum(lemma_group[1]['aat_scopeNote']),sum(lemma_group[1]['aat_total']),\\\n",
    "              sum(lemma_group[1]['pwn_le']),sum(lemma_group[1]['pwn_def']),\\\n",
    "              sum(lemma_group[1]['pwn_examples']),sum(lemma_group[1]['pwn_total']),\\\n",
    "              sum(lemma_group[1]['total_hits'])]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl = pd.read_csv('LODlit/rm/rm_stats_nl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lemmas column for each query term EN\n",
    "lemmas = []\n",
    "for row in stats_nl.iterrows():\n",
    "    for lemma, wordforms in query_terms['nl'].items():\n",
    "        if row[1]['query_term'] in wordforms:\n",
    "            lemmas.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_nl.insert(0,\"lemma\",lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas NL\n",
    "\n",
    "with open('rm_stats_by_lemma_nl.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\",\\\n",
    "              \"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\"aat_total\",\\\n",
    "              \"odwn_le\",\"odwn_sense_examples\",\"odwn_sense_definition\",\"odwn_total\",\"total_hits\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    for lemma_group in stats_nl.groupby(\"lemma\"):\n",
    "        data = [lemma_group[0],\"nl\",sum(lemma_group[1]['wd_pref']),sum(lemma_group[1]['wd_aliases']),\\\n",
    "              sum(lemma_group[1]['wd_descr']),sum(lemma_group[1]['wd_total']),\\\n",
    "              sum(lemma_group[1]['aat_pref']),sum(lemma_group[1]['aat_alt']),\\\n",
    "              sum(lemma_group[1]['aat_scopeNote']),sum(lemma_group[1]['aat_total']),\\\n",
    "              sum(lemma_group[1]['odwn_le']),sum(lemma_group[1]['odwn_sense_examples']),\\\n",
    "              sum(lemma_group[1]['odwn_sense_definition']),sum(lemma_group[1]['odwn_total']),\\\n",
    "              sum(lemma_group[1]['total_hits'])]\n",
    "        \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate a csv with related matches\n",
    "# group by lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rm_entities_all.csv','w') as csv_file:\n",
    "    \n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"lang\",\"resource\",\"entity_id\"]\n",
    "    writer.writerow(header)\n",
    "        \n",
    "    # EN wikidata\n",
    "    for query_term, rms in rm_wd_en.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"wikidata\",rm['QID']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # NL wikidata\n",
    "    for query_term, rms in rm_wd_nl.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'nl'),'nl',\"wikidata\",rm['QID']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # EN AAT\n",
    "    for query_term, rms in rm_aat_en.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"aat\",rm['aat_uri']]\n",
    "            writer.writerow(data)\n",
    "    \n",
    "    # NL AAT\n",
    "    for query_term, rms in rm_aat_nl.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'nl'),'nl',\"aat\",rm['aat_uri']]\n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # PWN\n",
    "    for query_term, rms in rm_pwn.items():\n",
    "        for rm in rms:\n",
    "            data = [get_lemma_by_term(query_term,'en'),'en',\"pwn\",rm['synset_id']] \n",
    "            writer.writerow(data)\n",
    "            \n",
    "    # ODWN\n",
    "    for query_term, rms in rm_odwn.items():\n",
    "        for rm in rms:\n",
    "            if rm['synset_id'] == '':\n",
    "                data = [get_lemma_by_term(query_term,'nl'),'nl',\"odwn\",rm['sense_id']]\n",
    "                writer.writerow(data)\n",
    "            else:\n",
    "                data = [get_lemma_by_term(query_term,'nl'),'nl',\"odwn\",rm['synset_id']]\n",
    "                writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = pd.read_csv(\"LODlit/rm/rm_entities_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities.to_csv(\"LODlit/rm/rm_entities_unique.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
