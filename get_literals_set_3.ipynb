{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting literals of resources from Set 3\n",
    "These resources are taken from the Words Matter knowledge graph and are connected to culturally sensitive terms with the propertty *skos:relatedMatch*; here, these resources are called \"related matches\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generating a file with terms grouped by canonical forms linked to their related resources (related matches) from the Words Matter knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {lemma: {\"query_terms\":[], \"related_matches\":{\"wikidata\":\"\",\"aat\":\"\",pwn:[\"\",\"\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import query term\n",
    "with open('query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading related matches from GitHub\n",
    "path_rm = \"https://github.com/cultural-ai/wordsmatter/raw/main/related_matches/rm.json\"\n",
    "rm = requests.get(path_rm).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_terms_related_matches = {}\n",
    "\n",
    "for lang in query_terms.keys():\n",
    "\n",
    "    dict_per_lang = {}\n",
    "\n",
    "    for lemma, terms in query_terms[lang].items():\n",
    "        \n",
    "        dict_per_lemma = {}\n",
    "        dict_per_lemma[\"query_terms\"] = terms\n",
    "        dict_per_lemma[\"related_matches\"] = {}\n",
    "        dict_per_lemma[\"related_matches\"][\"wikidata\"] = []\n",
    "        dict_per_lemma[\"related_matches\"][\"aat\"] = []\n",
    "\n",
    "        for value in rm.values():\n",
    "            \n",
    "            # check lang\n",
    "            if value[\"lang\"] == lang and lemma in value[\"query_terms\"]:\n",
    "                \n",
    "                if value[\"related_matches\"][\"wikidata\"][0] != \"None\":\n",
    "                    dict_per_lemma[\"related_matches\"][\"wikidata\"].append(value[\"related_matches\"][\"wikidata\"][0])\n",
    "                if value[\"related_matches\"][\"aat\"][0] != \"None\":\n",
    "                    dict_per_lemma[\"related_matches\"][\"aat\"].append(value[\"related_matches\"][\"aat\"][0])\n",
    "               \n",
    "                if lang == \"en\":\n",
    "                    if value[\"related_matches\"][\"pwn\"][0] != \"None\":\n",
    "                        dict_per_lemma[\"related_matches\"][\"pwn\"] = value[\"related_matches\"][\"pwn\"]\n",
    "                    else:\n",
    "                        dict_per_lemma[\"related_matches\"][\"pwn\"] = []\n",
    "                        \n",
    "        dict_per_lang[lemma] = dict_per_lemma\n",
    "        \n",
    "    query_terms_related_matches[lang] = dict_per_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting related matches from ODWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/bg/related_matches_odwn.json','r') as jf:\n",
    "    odwn_rm = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma, info in query_terms_related_matches[\"nl\"].items():\n",
    "    \n",
    "    info[\"related_matches\"][\"odwn\"] = {\"synset_id\":[],\"le_id\":[]}\n",
    "    for value in odwn_rm.values():\n",
    "        if lemma in value[\"query_terms\"]:\n",
    "            if value[\"odwn_synsets\"] != \"\":\n",
    "                info[\"related_matches\"][\"odwn\"][\"synset_id\"].extend(value[\"odwn_synsets\"])\n",
    "            if value[\"odwn_le\"][0] != \"None\":\n",
    "                info[\"related_matches\"][\"odwn\"][\"le_id\"].extend(value[\"odwn_le\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting\n",
    "with open('lemmas_terms_rms.json', 'w') as jf:\n",
    "    json.dump(query_terms_related_matches, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add literals of related resources to the file generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {lemma: {\"query_terms\":[], \"related_matches\":{\"wikidata\":\"\",\"aat\":\"\",pwn:[\"\",\"\"]},\n",
    "#          \"related_matches_lit\":{\"wikidata\":[], \"aat\":[], \"pwn\":[]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query results in each dataset\n",
    "\n",
    "with gzip.open(f\"/Wikidata/gzip_results_clean_en.json\", 'r') as gzip_json:\n",
    "    wd_en = json.loads(gzip_json.read().decode('utf-8'))\n",
    "    \n",
    "with gzip.open(f\"/Wikidata/gzip_results_clean_nl.json\", 'r') as gzip_json:\n",
    "    wd_nl = json.loads(gzip_json.read().decode('utf-8'))\n",
    "    \n",
    "with open('/AAT/aat_query_results_en.json','r') as jf:\n",
    "    aat_en = json.load(jf)\n",
    "    \n",
    "with open('/AAT/aat_query_results_nl.json','r') as jf:\n",
    "    aat_nl = json.load(jf)\n",
    "    \n",
    "with open('/PWN/pwn31_query_results.json','r') as jf:\n",
    "    pwn = json.load(jf)\n",
    "    \n",
    "with open('/ODWN/odwn_query_results.json','r') as jf:\n",
    "    odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaping dicts per lang\n",
    "for lemma, info in query_terms_related_matches[\"en\"].items():\n",
    "    info[\"related_matches_lit\"] = {}\n",
    "    info[\"related_matches_lit\"][\"wikidata\"] = []\n",
    "    info[\"related_matches_lit\"][\"aat\"] = []\n",
    "    info[\"related_matches_lit\"][\"pwn\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma, info in query_terms_related_matches[\"nl\"].items():\n",
    "    info[\"related_matches_lit\"] = {}\n",
    "    info[\"related_matches_lit\"][\"wikidata\"] = []\n",
    "    info[\"related_matches_lit\"][\"aat\"] = []\n",
    "    info[\"related_matches_lit\"][\"odwn\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from Wikidata EN\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"en\"].items():\n",
    "    if len(info[\"related_matches\"][\"wikidata\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if wd_en[term] != []:\n",
    "                for hit in wd_en[term]:\n",
    "                    if info[\"related_matches\"][\"wikidata\"][0] == hit[\"QID\"]:\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].append(hit[\"prefLabel\"])\n",
    "                        if hit[\"aliases\"] != None:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"aliases\"])\n",
    "                        if type(hit[\"description\"]) == str:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].append(hit[\"description\"])\n",
    "                        if type(hit[\"description\"]) == list:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"description\"])\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"instance_of\"])\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"subclass_of\"])\n",
    "                        \n",
    "                        # if hit with RM is found, don't iterate over other hits\n",
    "                        break\n",
    "                        \n",
    "            # if RM for lemma is found, don't iterate over other query terms\n",
    "            if len(info[\"related_matches_lit\"][\"wikidata\"]) > 0:\n",
    "                break\n",
    "    continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from Wikidata NL\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"nl\"].items():\n",
    "    if len(info[\"related_matches\"][\"wikidata\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if wd_nl[term] != []:\n",
    "                for hit in wd_nl[term]:\n",
    "                    if info[\"related_matches\"][\"wikidata\"][0] == hit[\"QID\"]:\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].append(hit[\"prefLabel\"])\n",
    "                        if hit[\"aliases\"] != None:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"aliases\"])\n",
    "                        if type(hit[\"description\"]) == str:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].append(hit[\"description\"])\n",
    "                        if type(hit[\"description\"]) == list:\n",
    "                            info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"description\"])\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"instance_of\"])\n",
    "                        info[\"related_matches_lit\"][\"wikidata\"].extend(hit[\"subclass_of\"])\n",
    "                        \n",
    "                        # if hit with RM is found, don't iterate over other hits\n",
    "                        break\n",
    "                        \n",
    "            # if RM for lemma is found, don't iterate over other query terms\n",
    "            if len(info[\"related_matches_lit\"][\"wikidata\"]) > 0:\n",
    "                break\n",
    "                \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from AAT EN\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"en\"].items():\n",
    "    if len(info[\"related_matches\"][\"aat\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if aat_en[term] != []:\n",
    "                for hit in aat_en[term]:\n",
    "                    if info[\"related_matches\"][\"aat\"][0] == hit[\"aat_uri\"]:\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"prefLabel\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"prefLabel_comment\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].extend(hit[\"altLabel\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].extend(hit[\"altLabel_comment\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"scopeNote\"])\n",
    "\n",
    "                        # if hit with RM is found, don't iterate over other hits\n",
    "                        break\n",
    "                        \n",
    "            # if RM for lemma is found, don't iterate over other query terms\n",
    "            if len(info[\"related_matches_lit\"][\"aat\"]) > 0:\n",
    "                break\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from AAT NL\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"nl\"].items():\n",
    "    if len(info[\"related_matches\"][\"aat\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if aat_nl[term] != []:\n",
    "                for hit in aat_nl[term]:\n",
    "                    if info[\"related_matches\"][\"aat\"][0] == hit[\"aat_uri\"]:\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"prefLabel\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"prefLabel_comment\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].extend(hit[\"altLabel\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].extend(hit[\"altLabel_comment\"])\n",
    "                        info[\"related_matches_lit\"][\"aat\"].append(hit[\"scopeNote\"])\n",
    "\n",
    "                        # if hit with RM is found, don't iterate over other hits\n",
    "                        break\n",
    "                        \n",
    "            # if RM for lemma is found, don't iterate over other query terms\n",
    "            if len(info[\"related_matches_lit\"][\"aat\"]) > 0:\n",
    "                break\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from PWN\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"en\"].items():\n",
    "    if len(info[\"related_matches\"][\"pwn\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if pwn[term] != []:\n",
    "                for hit in pwn[term]:\n",
    "                    for hit_id in info[\"related_matches\"][\"pwn\"]:\n",
    "                        if hit_id == hit[\"synset_id\"]:\n",
    "                            info[\"related_matches_lit\"][\"pwn\"].extend(hit[\"lemmata\"])\n",
    "                            info[\"related_matches_lit\"][\"pwn\"].append(hit[\"definition\"])\n",
    "                            info[\"related_matches_lit\"][\"pwn\"].extend(hit[\"examples\"])\n",
    "                        \n",
    "            # if RM for lemma is found, don't iterate over other query terms\n",
    "            if len(info[\"related_matches_lit\"][\"pwn\"]) > 0:\n",
    "                info[\"related_matches_lit\"][\"pwn\"] = list(set(info[\"related_matches_lit\"][\"pwn\"]))\n",
    "                \n",
    "                break\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding literals from ODWN\n",
    "\n",
    "for lemma, info in query_terms_related_matches[\"nl\"].items():\n",
    "    if len(info[\"related_matches\"][\"odwn\"][\"synset_id\"]) > 0 or \\\n",
    "    len(info[\"related_matches\"][\"odwn\"][\"le_id\"]) > 0:\n",
    "        \n",
    "        for term in info[\"query_terms\"]:\n",
    "            if odwn[term] != []:\n",
    "                for hit in odwn[term]:\n",
    "\n",
    "                    if hit[\"synset_id\"] != \"\" and hit[\"synset_id\"] in info[\"related_matches\"][\"odwn\"][\"synset_id\"]:\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].append(hit.get(\"le_written_form\"))\n",
    "                        if hit.get(\"sense_examples\"):\n",
    "                            info[\"related_matches_lit\"][\"odwn\"].extend(hit.get(\"sense_examples\"))\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].extend(hit[\"synonyms\"])\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].extend(hit[\"synset_definitions\"])\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].append(hit.get(\"sense_definition\"))\n",
    "                    if hit[\"synset_id\"] == \"\" and hit[\"le_id\"] in info[\"related_matches\"][\"odwn\"][\"le_id\"]:\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].append(hit.get(\"le_written_form\"))\n",
    "                        if hit.get(\"sense_examples\"):\n",
    "                            info[\"related_matches_lit\"][\"odwn\"].extend(hit.get(\"sense_examples\"))\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].extend(hit[\"synonyms\"])\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].extend(hit[\"synset_definitions\"])\n",
    "                        info[\"related_matches_lit\"][\"odwn\"].append(hit.get(\"sense_definition\"))\n",
    "\n",
    "        info[\"related_matches_lit\"][\"odwn\"] = list(set(info[\"related_matches_lit\"][\"odwn\"]))\n",
    "                \n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting file\n",
    "with open('lemmas_query_terms_related_matches.json', 'w') as jf:\n",
    "    json.dump(query_terms_related_matches, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Generating 2 csv files with literlas of related resources\n",
    "related_matches_literals_en.csv, related_matches_literals_nl.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the file generated above\n",
    "with open('lemmas_query_terms_related_matches.json','r') as jf:\n",
    "    rm_lits = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('related_matches_literals_en.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"source_1\",\"source_2\",\"source_3\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for lemma, info in rm_lits[\"en\"].items():\n",
    "        data = [lemma,info[\"related_matches_lit\"][\"wikidata\"],\\\n",
    "                info[\"related_matches_lit\"][\"aat\"],\\\n",
    "                info[\"related_matches_lit\"][\"pwn\"]]\n",
    "    \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('related_matches_literals_nl.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"source_1\",\"source_2\",\"source_3\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for lemma, info in rm_lits[\"nl\"].items():\n",
    "        data = [lemma,info[\"related_matches_lit\"][\"wikidata\"],\\\n",
    "                info[\"related_matches_lit\"][\"aat\"],\\\n",
    "                info[\"related_matches_lit\"][\"odwn\"]]\n",
    "    \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
