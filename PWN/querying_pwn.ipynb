{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !NB WordNet version 3.1\n",
    "We are using WordNet version 3.1. It is available for download at https://github.com/nltk/nltk_data/blob/gh-pages/packages/corpora/wordnet31.zip. Note that it is not currently possible to import the corpus 'wordnet31' from nltk.corpus (as it is possible with the version 3.0: from nltk.corpus import wordnet). See explanations on the WordNet website (retrieved on 10.02.2023): https://wordnet.princeton.edu/download/current-version: \"WordNet 3.1 DATABASE FILES ONLY. You can download the WordNet 3.1 database files. Note that this is not a full package as those above, nor does it contain any code for running WordNet. However, you can replace the files in the database directory of your 3.0 local installation with these files and the WordNet interface will run, returning entries from the 3.1 database. This is simply a compressed tar file of the WordNet 3.1 database files\".<br>\n",
    "We have replaced the files of wordnet 3.0 with the files from version 3.1, as adviced.\n",
    "To check the version use .get_version()\n",
    "<br><br> Steps:\n",
    "1. download nltk and wordnet in python as usual\n",
    "2. download wordnet 3.1 via the link\n",
    "3. replace the content of the folder 'wordnet' in your local repository 'nltk_data/corpora' with the content of 'wordnet31'\n",
    "4. import wordnet in python\n",
    "5. check the version of wordnet: wordnet.get_version() or use the 'pwn31' module function check_version(); it should be '3.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from LODlit import pwn31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwn31.check_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open(\"query_terms.json\",\"r\") as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only English terms\n",
    "en_query_terms = []\n",
    "for lemma, wordforms in query_terms['en'].items():\n",
    "    en_query_terms.extend(wordforms)\n",
    "len(en_query_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwn_results = {}\n",
    "for query_term in en_query_terms:\n",
    "    pwn_results[query_term] = pwn31.find_term(query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results in a json file\n",
    "with open('pwn31_query_results.json', 'w') as jf:\n",
    "    json.dump(pwn_results, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting BoWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the search results generated above\n",
    "pwn31_bows = pwn31.get_bows('pwn31_query_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting bows\n",
    "with open('pwn31_bows.json', 'w') as jf:\n",
    "    json.dump(pwn31_bows, jf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
