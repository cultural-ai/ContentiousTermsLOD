{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query results\n",
    "with open(\"pwn31_query_results.json\",\"r\") as jf:\n",
    "    pwn31_query_results = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open(\"LODlit/query_terms.json\",\"r\") as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. N synsets by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pwn31_synsets_by_query_term.csv\",\"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"query_term\",\"n_synsets\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for term, results in pwn31_query_results.items():\n",
    "        # taking only English terms\n",
    "        for l, wordforms in query_terms[\"en\"].items():\n",
    "                if term in wordforms:\n",
    "                    lemma = l\n",
    "        n_synsets = len(set([hit[\"synset_id\"] for hit in results]))            \n",
    "        row = [lemma,term,n_synsets]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N synsets by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pwn31_synsets_by_query_term.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pwn31_synsets_by_lemma.csv\",\"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"n_synsets\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in df.groupby(\"lemma\"):\n",
    "        row = [group[0],sum(group[1][\"n_synsets\"])]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. N hits (occurences) by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pwn31_hits_by_query_term.csv\",\"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"query_term\",\"synset_lemmas\",\"definitions\",\"examples\",\"total_per_query_term\"]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for term, results in pwn31_query_results.items():\n",
    "        lemmata_count = 0\n",
    "        definition_count = 0\n",
    "        examples_count = 0\n",
    "        \n",
    "        # getting a lemma for the query term\n",
    "        for l, wordforms in query_terms[\"en\"].items():\n",
    "            if term in wordforms:\n",
    "                lemma = l\n",
    "                \n",
    "        # checking where the query term is found\n",
    "        for hit in results:\n",
    "            if hit[\"found_in\"] == \"lemmata\":\n",
    "                lemmata_count += 1\n",
    "            if hit[\"found_in\"] == \"definition\":\n",
    "                definition_count += 1\n",
    "            if hit[\"found_in\"] == \"examples\":\n",
    "                examples_count += 1\n",
    "        total_count = lemmata_count + definition_count + examples_count\n",
    "            \n",
    "        row = [lemma, term, lemmata_count, definition_count, examples_count, total_count]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. N hits (occurences) by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pwn31_hits_by_query_term.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pwn31_hits_by_lemma.csv\",\"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = [\"lemma\",\"synset_lemmas\",\"definitions\",\"examples\",\"total_lemma\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in df.groupby(\"lemma\"):\n",
    "        row = [group[0],sum(group[1][\"synset_lemmas\"]),sum(group[1][\"definitions\"]),\\\n",
    "              sum(group[1][\"examples\"]),sum(group[1][\"total_per_query_term\"])]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. All PWN 3.1\n",
    "This numbers are used for Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lemma_name = 0\n",
    "for synset in list(wn.all_synsets()):\n",
    "    for le in synset.lemmas():\n",
    "        if le.name() != None:\n",
    "            count_lemma_name = count_lemma_name + 1\n",
    "print(count_lemma_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_synset_definition = 0\n",
    "for synset in list(wn.all_synsets()):\n",
    "    if synset.definition() != None:\n",
    "        count_synset_definition = count_synset_definition + 1\n",
    "print(count_synset_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_synset_examples = 0\n",
    "for synset in list(wn.all_synsets()):\n",
    "    if synset.examples() != []:\n",
    "        count_synset_examples = count_synset_examples + 1\n",
    "print(count_synset_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
