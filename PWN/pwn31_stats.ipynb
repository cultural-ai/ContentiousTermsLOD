{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query results\n",
    "with open('/Users/anesterov/reps/LODlit/Princeton_WordNet/pwn31_query_results.json','r') as jf:\n",
    "    pwn31_query_results = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open(\"/Users/anesterov/reps/LODlit/query_terms.json\",\"r\") as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. N synsets by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pwn31_synsets_by_query_term.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','query_term','n_synsets']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for term, results in pwn31_query_results.items():\n",
    "        # taking only English terms\n",
    "        for l, wordforms in query_terms['en'].items():\n",
    "                if term in wordforms:\n",
    "                    lemma = l\n",
    "        n_synsets = len(set([hit['synset_id'] for hit in results]))            \n",
    "        row = [lemma,term,n_synsets]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. N synsets by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pwn31_synsets_by_query_term.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pwn31_synsets_by_lemma.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','n_synsets']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in df.groupby('lemma'):\n",
    "        row = [group[0],sum(group[1]['n_synsets'])]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. N hits (occurences) by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pwn31_hits_by_query_term.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','query_term','synset_lemmas','definitions','examples','total_per_query_term']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for term, results in pwn31_query_results.items():\n",
    "        lemmata_count = 0\n",
    "        definition_count = 0\n",
    "        examples_count = 0\n",
    "        \n",
    "        # getting a lemma for the query term\n",
    "        for l, wordforms in query_terms['en'].items():\n",
    "            if term in wordforms:\n",
    "                lemma = l\n",
    "                \n",
    "        # checking where the query term is found\n",
    "        for hit in results:\n",
    "            if hit['found_in'] == 'lemmata':\n",
    "                lemmata_count += 1\n",
    "            if hit['found_in'] == 'definition':\n",
    "                definition_count += 1\n",
    "            if hit['found_in'] == 'examples':\n",
    "                examples_count += 1\n",
    "        total_count = lemmata_count + definition_count + examples_count\n",
    "            \n",
    "        row = [lemma, term, lemmata_count, definition_count, examples_count, total_count]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. N hits (occurences) by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pwn31_hits_by_query_term.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pwn31_hits_by_lemma.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','synset_lemmas','definitions','examples','total_per_lemma']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for group in df.groupby('lemma'):\n",
    "        row = [group[0],sum(group[1]['synset_lemmas']),sum(group[1]['definitions']),\\\n",
    "              sum(group[1]['examples']),sum(group[1]['total_per_query_term'])]\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
