{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AAT \n",
    "with open('/Users/anesterov/reps/LODlit/AAT/aat_bows_en.json','r') as jf:\n",
    "    aat_bows_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_corpus(existing_corpus:list, sorce_path:str) -> list:\n",
    "    '''\n",
    "    Adds search results from AAT, PWN, or Wikidata to the existing corpus\n",
    "    Every unique search result (hit) is added to the corpus as a list of tokens (bow)\n",
    "    NB! Modifies existing_corpus adding new lists\n",
    "    Returns a str with info about how many new documents were added\n",
    "    existing_corpus: list, \n",
    "    sorce_path: str, a path to search results (a json file) to extend the existing corpus with\n",
    "    requires json library\n",
    "    '''\n",
    "    \n",
    "    added_corpus = []\n",
    "    \n",
    "    # reading source\n",
    "    with open(sorce_path,'r') as jf:\n",
    "        sorce_bows = json.load(jf)\n",
    "    \n",
    "    # this list stores unique bow IDs\n",
    "    # taking only unique entities, so there are no duplicate BoWs in the corpus\n",
    "    ids_list = []\n",
    "    for value in sorce_bows.values():\n",
    "        for v in value:\n",
    "            for id_value, bow in v.items():\n",
    "                if id_value not in ids_list:\n",
    "                    added_corpus.append(bow)\n",
    "                    ids_list.append(id_value)\n",
    "                    \n",
    "    existing_corpus.extend(added_corpus)\n",
    "    \n",
    "    return (f\"{len(added_corpus)} bows added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'169284 bows added'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extend_corpus(corpus_en,\"/Users/anesterov/wd/jan31/wd_bows_en.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179304"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a test corpus (10% of corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus_en = []\n",
    "\n",
    "idx_all = []\n",
    "\n",
    "idx_aat = random.sample(range(0, 5000), 500)\n",
    "idx_pwn = random.sample(range(6000, 10000), 500)\n",
    "idx_wikidata = random.sample(range(10500, 160000), 17000)\n",
    "\n",
    "idx_all.extend(idx_aat)\n",
    "idx_all.extend(idx_pwn)\n",
    "idx_all.extend(idx_wikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in idx_all:\n",
    "    test_corpus_en.append(corpus_en[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_corpus_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging training corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_corpus(corpus:list) -> list:\n",
    "    '''\n",
    "    Adding tags to corpus using gensim TaggedDocument\n",
    "    Returns tagged corpus\n",
    "    '''\n",
    "    tagged_corpus = []\n",
    "    \n",
    "    tag = 0\n",
    "    for bow in corpus:\n",
    "        tag += 1\n",
    "        tagged_corpus.append(gensim.models.doc2vec.TaggedDocument(bow, [tag]))\n",
    "        \n",
    "    return tagged_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus_en = tagging_corpus(corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['chinese', 'coromandel', 'screen', 'refers', 'type', 'chinese', 'folding', 'screen', 'typically', 'large', 'tall', 'ten', 'foot', 'height', 'twenty', 'length', 'twelve', 'panel', 'lacquered', 'gilded', 'coromandel', 'screen', 'feature', 'incised', 'lacquer', 'decoration', 'often', 'wide', 'border', 'around', 'main', 'name', 'come', 'part', 'southeastern', 'indian', 'coast', 'near', 'madras', 'transfer', 'point', 'far', 'eastern', 'good', 'shipped', 'europe', 'east', 'india', 'coromandel', 'screen', 'mainly', 'made', 'china', 'century', 'european', 'chinese', 'coromandel', 'screen', 'chinese', 'coromandels', 'chinese', 'coromandel', 'coromandel', 'screen', 'coromandel', 'lacquer', 'screen', 'kuancai', 'screen'], tags=[2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_corpus_en[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:24:01,123 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>', 'datetime': '2023-03-27T18:24:01.087825', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:24:23,957 : INFO : collecting all words and their counts\n",
      "2023-03-27 18:24:23,958 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-03-27 18:24:24,040 : INFO : PROGRESS: at example #10000, processed 229988 words (2909127 words/s), 29763 word types, 0 tags\n",
      "2023-03-27 18:24:24,065 : INFO : PROGRESS: at example #20000, processed 342363 words (4574504 words/s), 38122 word types, 0 tags\n",
      "2023-03-27 18:24:24,087 : INFO : PROGRESS: at example #30000, processed 421303 words (3639632 words/s), 48651 word types, 0 tags\n",
      "2023-03-27 18:24:24,111 : INFO : PROGRESS: at example #40000, processed 532096 words (4758306 words/s), 55023 word types, 0 tags\n",
      "2023-03-27 18:24:24,135 : INFO : PROGRESS: at example #50000, processed 625950 words (3983566 words/s), 64293 word types, 0 tags\n",
      "2023-03-27 18:24:24,158 : INFO : PROGRESS: at example #60000, processed 715488 words (4111955 words/s), 68767 word types, 0 tags\n",
      "2023-03-27 18:24:24,181 : INFO : PROGRESS: at example #70000, processed 813334 words (4342358 words/s), 73706 word types, 0 tags\n",
      "2023-03-27 18:24:24,205 : INFO : PROGRESS: at example #80000, processed 914641 words (4156085 words/s), 79315 word types, 0 tags\n",
      "2023-03-27 18:24:24,233 : INFO : PROGRESS: at example #90000, processed 1028117 words (4211934 words/s), 86512 word types, 0 tags\n",
      "2023-03-27 18:24:24,258 : INFO : PROGRESS: at example #100000, processed 1127911 words (4121370 words/s), 90656 word types, 0 tags\n",
      "2023-03-27 18:24:24,282 : INFO : PROGRESS: at example #110000, processed 1248312 words (4976550 words/s), 93827 word types, 0 tags\n",
      "2023-03-27 18:24:24,308 : INFO : PROGRESS: at example #120000, processed 1354510 words (4243344 words/s), 97878 word types, 0 tags\n",
      "2023-03-27 18:24:24,333 : INFO : PROGRESS: at example #130000, processed 1455005 words (4134625 words/s), 106435 word types, 0 tags\n",
      "2023-03-27 18:24:24,353 : INFO : PROGRESS: at example #140000, processed 1534921 words (4068222 words/s), 109545 word types, 0 tags\n",
      "2023-03-27 18:24:24,370 : INFO : PROGRESS: at example #150000, processed 1611666 words (4530836 words/s), 111798 word types, 0 tags\n",
      "2023-03-27 18:24:24,388 : INFO : PROGRESS: at example #160000, processed 1697938 words (4993844 words/s), 113945 word types, 0 tags\n",
      "2023-03-27 18:24:24,410 : INFO : PROGRESS: at example #170000, processed 1800108 words (4718197 words/s), 121567 word types, 0 tags\n",
      "2023-03-27 18:24:24,433 : INFO : collected 128990 word types and 179305 unique tags from a corpus of 179304 examples and 1877097 words\n",
      "2023-03-27 18:24:24,434 : INFO : Creating a fresh vocabulary\n",
      "2023-03-27 18:24:24,580 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 57097 unique words (44.26% of original 128990, drops 71893)', 'datetime': '2023-03-27T18:24:24.580184', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-27 18:24:24,580 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 1805204 word corpus (96.17% of original 1877097, drops 71893)', 'datetime': '2023-03-27T18:24:24.580598', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-27 18:24:24,776 : INFO : deleting the raw counts dictionary of 128990 items\n",
      "2023-03-27 18:24:24,778 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-03-27 18:24:24,778 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1599392.7741463939 word corpus (88.6%% of prior 1805204)', 'datetime': '2023-03-27T18:24:24.778915', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-27 18:24:25,129 : INFO : estimated required memory for 57097 words and 50 dimensions: 123109300 bytes\n",
      "2023-03-27 18:24:25,129 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(tagged_corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11747"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times a certain word appears in the corpus\n",
    "model.wv.get_vecattr('black', 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:48:59,965 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 57097 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-03-27T18:48:59.965473', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-03-27 18:49:01,020 : INFO : EPOCH 0 - PROGRESS: at 14.47% examples, 364539 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:02,026 : INFO : EPOCH 0 - PROGRESS: at 32.26% examples, 329466 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:03,027 : INFO : EPOCH 0 - PROGRESS: at 49.73% examples, 318736 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:04,068 : INFO : EPOCH 0 - PROGRESS: at 67.18% examples, 311836 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:05,069 : INFO : EPOCH 0 - PROGRESS: at 86.23% examples, 305238 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:05,838 : INFO : EPOCH 0: training on 1877097 raw words (1778573 effective words) took 5.9s, 303466 effective words/s\n",
      "2023-03-27 18:49:06,847 : INFO : EPOCH 1 - PROGRESS: at 14.47% examples, 377756 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:07,868 : INFO : EPOCH 1 - PROGRESS: at 33.01% examples, 336138 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:08,871 : INFO : EPOCH 1 - PROGRESS: at 50.24% examples, 324076 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:09,892 : INFO : EPOCH 1 - PROGRESS: at 67.75% examples, 317505 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:10,929 : INFO : EPOCH 1 - PROGRESS: at 86.94% examples, 307409 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:11,612 : INFO : EPOCH 1: training on 1877097 raw words (1778532 effective words) took 5.8s, 308116 effective words/s\n",
      "2023-03-27 18:49:12,625 : INFO : EPOCH 2 - PROGRESS: at 14.47% examples, 376369 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:13,700 : INFO : EPOCH 2 - PROGRESS: at 33.76% examples, 330032 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:14,727 : INFO : EPOCH 2 - PROGRESS: at 51.77% examples, 325376 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:15,734 : INFO : EPOCH 2 - PROGRESS: at 68.93% examples, 316884 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:16,794 : INFO : EPOCH 2 - PROGRESS: at 88.72% examples, 308036 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:17,371 : INFO : EPOCH 2: training on 1877097 raw words (1779551 effective words) took 5.8s, 309094 effective words/s\n",
      "2023-03-27 18:49:18,382 : INFO : EPOCH 3 - PROGRESS: at 14.47% examples, 377214 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:19,408 : INFO : EPOCH 3 - PROGRESS: at 33.01% examples, 334986 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:20,417 : INFO : EPOCH 3 - PROGRESS: at 50.81% examples, 326043 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:21,424 : INFO : EPOCH 3 - PROGRESS: at 67.75% examples, 317555 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:22,449 : INFO : EPOCH 3 - PROGRESS: at 86.94% examples, 308240 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:23,172 : INFO : EPOCH 3: training on 1877097 raw words (1778737 effective words) took 5.8s, 306745 effective words/s\n",
      "2023-03-27 18:49:24,186 : INFO : EPOCH 4 - PROGRESS: at 15.27% examples, 385713 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:25,213 : INFO : EPOCH 4 - PROGRESS: at 33.00% examples, 334521 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:26,237 : INFO : EPOCH 4 - PROGRESS: at 50.72% examples, 324029 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:27,274 : INFO : EPOCH 4 - PROGRESS: at 68.93% examples, 318469 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:28,281 : INFO : EPOCH 4 - PROGRESS: at 88.21% examples, 310327 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:28,928 : INFO : EPOCH 4: training on 1877097 raw words (1778850 effective words) took 5.8s, 309172 effective words/s\n",
      "2023-03-27 18:49:29,951 : INFO : EPOCH 5 - PROGRESS: at 15.27% examples, 382002 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:30,965 : INFO : EPOCH 5 - PROGRESS: at 33.01% examples, 334988 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:31,977 : INFO : EPOCH 5 - PROGRESS: at 50.81% examples, 325655 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:33,029 : INFO : EPOCH 5 - PROGRESS: at 68.26% examples, 316257 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:34,029 : INFO : EPOCH 5 - PROGRESS: at 87.65% examples, 308745 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:34,700 : INFO : EPOCH 5: training on 1877097 raw words (1778635 effective words) took 5.8s, 308258 effective words/s\n",
      "2023-03-27 18:49:35,719 : INFO : EPOCH 6 - PROGRESS: at 15.27% examples, 384016 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:36,738 : INFO : EPOCH 6 - PROGRESS: at 33.75% examples, 338269 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:37,761 : INFO : EPOCH 6 - PROGRESS: at 51.29% examples, 327916 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:38,806 : INFO : EPOCH 6 - PROGRESS: at 68.93% examples, 318182 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:39,868 : INFO : EPOCH 6 - PROGRESS: at 88.72% examples, 308814 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:40,446 : INFO : EPOCH 6: training on 1877097 raw words (1779285 effective words) took 5.7s, 309788 effective words/s\n",
      "2023-03-27 18:49:41,456 : INFO : EPOCH 7 - PROGRESS: at 14.47% examples, 377593 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:42,471 : INFO : EPOCH 7 - PROGRESS: at 33.01% examples, 337104 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:43,508 : INFO : EPOCH 7 - PROGRESS: at 50.81% examples, 324422 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:44,541 : INFO : EPOCH 7 - PROGRESS: at 68.93% examples, 318970 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:45,592 : INFO : EPOCH 7 - PROGRESS: at 88.72% examples, 310096 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:46,179 : INFO : EPOCH 7: training on 1877097 raw words (1778904 effective words) took 5.7s, 310431 effective words/s\n",
      "2023-03-27 18:49:47,184 : INFO : EPOCH 8 - PROGRESS: at 14.47% examples, 379397 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:48,194 : INFO : EPOCH 8 - PROGRESS: at 33.01% examples, 338828 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:49,195 : INFO : EPOCH 8 - PROGRESS: at 50.24% examples, 326008 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:50,293 : INFO : EPOCH 8 - PROGRESS: at 68.93% examples, 317441 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:51,307 : INFO : EPOCH 8 - PROGRESS: at 88.72% examples, 311174 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:51,889 : INFO : EPOCH 8: training on 1877097 raw words (1778966 effective words) took 5.7s, 311683 effective words/s\n",
      "2023-03-27 18:49:52,902 : INFO : EPOCH 9 - PROGRESS: at 15.27% examples, 385977 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:53,914 : INFO : EPOCH 9 - PROGRESS: at 33.01% examples, 336955 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:54,961 : INFO : EPOCH 9 - PROGRESS: at 51.77% examples, 329960 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:55,961 : INFO : EPOCH 9 - PROGRESS: at 69.87% examples, 322869 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:49:56,978 : INFO : EPOCH 9 - PROGRESS: at 88.72% examples, 313466 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:57,560 : INFO : EPOCH 9: training on 1877097 raw words (1778487 effective words) took 5.7s, 313717 effective words/s\n",
      "2023-03-27 18:49:58,582 : INFO : EPOCH 10 - PROGRESS: at 14.47% examples, 373021 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:49:59,587 : INFO : EPOCH 10 - PROGRESS: at 33.01% examples, 336623 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:00,593 : INFO : EPOCH 10 - PROGRESS: at 50.24% examples, 324113 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:01,619 : INFO : EPOCH 10 - PROGRESS: at 67.69% examples, 317038 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:02,633 : INFO : EPOCH 10 - PROGRESS: at 86.94% examples, 308561 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:03,309 : INFO : EPOCH 10: training on 1877097 raw words (1778650 effective words) took 5.7s, 309504 effective words/s\n",
      "2023-03-27 18:50:04,319 : INFO : EPOCH 11 - PROGRESS: at 14.47% examples, 377772 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:50:05,320 : INFO : EPOCH 11 - PROGRESS: at 33.01% examples, 339257 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:06,345 : INFO : EPOCH 11 - PROGRESS: at 50.81% examples, 327103 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:07,347 : INFO : EPOCH 11 - PROGRESS: at 68.26% examples, 321371 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:08,373 : INFO : EPOCH 11 - PROGRESS: at 87.51% examples, 311110 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:09,022 : INFO : EPOCH 11: training on 1877097 raw words (1778961 effective words) took 5.7s, 311554 effective words/s\n",
      "2023-03-27 18:50:10,046 : INFO : EPOCH 12 - PROGRESS: at 15.27% examples, 381695 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:11,099 : INFO : EPOCH 12 - PROGRESS: at 34.50% examples, 334617 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:12,111 : INFO : EPOCH 12 - PROGRESS: at 52.89% examples, 334592 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:13,112 : INFO : EPOCH 12 - PROGRESS: at 70.70% examples, 323652 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:14,138 : INFO : EPOCH 12 - PROGRESS: at 89.28% examples, 313799 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:14,701 : INFO : EPOCH 12: training on 1877097 raw words (1778871 effective words) took 5.7s, 313349 effective words/s\n",
      "2023-03-27 18:50:15,715 : INFO : EPOCH 13 - PROGRESS: at 14.47% examples, 375849 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:16,762 : INFO : EPOCH 13 - PROGRESS: at 33.76% examples, 334099 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:17,794 : INFO : EPOCH 13 - PROGRESS: at 51.77% examples, 327608 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:18,812 : INFO : EPOCH 13 - PROGRESS: at 69.87% examples, 319773 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:19,842 : INFO : EPOCH 13 - PROGRESS: at 89.28% examples, 312179 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:20,420 : INFO : EPOCH 13: training on 1877097 raw words (1778451 effective words) took 5.7s, 311045 effective words/s\n",
      "2023-03-27 18:50:21,442 : INFO : EPOCH 14 - PROGRESS: at 14.52% examples, 373037 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:22,452 : INFO : EPOCH 14 - PROGRESS: at 33.01% examples, 335846 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:23,455 : INFO : EPOCH 14 - PROGRESS: at 50.24% examples, 323987 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:24,456 : INFO : EPOCH 14 - PROGRESS: at 67.69% examples, 318905 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:25,499 : INFO : EPOCH 14 - PROGRESS: at 86.94% examples, 308156 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:26,177 : INFO : EPOCH 14: training on 1877097 raw words (1778451 effective words) took 5.8s, 309050 effective words/s\n",
      "2023-03-27 18:50:27,196 : INFO : EPOCH 15 - PROGRESS: at 16.66% examples, 402677 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:28,204 : INFO : EPOCH 15 - PROGRESS: at 34.50% examples, 342918 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:29,231 : INFO : EPOCH 15 - PROGRESS: at 51.77% examples, 331790 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:30,270 : INFO : EPOCH 15 - PROGRESS: at 69.87% examples, 321117 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:31,294 : INFO : EPOCH 15 - PROGRESS: at 89.28% examples, 313626 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:31,855 : INFO : EPOCH 15: training on 1877097 raw words (1778105 effective words) took 5.7s, 313255 effective words/s\n",
      "2023-03-27 18:50:32,872 : INFO : EPOCH 16 - PROGRESS: at 15.27% examples, 384633 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:33,924 : INFO : EPOCH 16 - PROGRESS: at 33.76% examples, 332893 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:34,955 : INFO : EPOCH 16 - PROGRESS: at 51.77% examples, 326833 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:35,968 : INFO : EPOCH 16 - PROGRESS: at 68.26% examples, 315244 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:36,996 : INFO : EPOCH 16 - PROGRESS: at 87.65% examples, 306263 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:37,654 : INFO : EPOCH 16: training on 1877097 raw words (1778102 effective words) took 5.8s, 306779 effective words/s\n",
      "2023-03-27 18:50:38,684 : INFO : EPOCH 17 - PROGRESS: at 15.27% examples, 379528 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:39,692 : INFO : EPOCH 17 - PROGRESS: at 33.75% examples, 338061 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:40,693 : INFO : EPOCH 17 - PROGRESS: at 50.81% examples, 326755 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:41,713 : INFO : EPOCH 17 - PROGRESS: at 68.26% examples, 319654 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:42,752 : INFO : EPOCH 17 - PROGRESS: at 87.51% examples, 309019 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:43,429 : INFO : EPOCH 17: training on 1877097 raw words (1779210 effective words) took 5.8s, 308177 effective words/s\n",
      "2023-03-27 18:50:44,439 : INFO : EPOCH 18 - PROGRESS: at 14.47% examples, 377714 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:45,492 : INFO : EPOCH 18 - PROGRESS: at 33.76% examples, 333917 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:46,509 : INFO : EPOCH 18 - PROGRESS: at 51.29% examples, 325718 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:47,567 : INFO : EPOCH 18 - PROGRESS: at 69.87% examples, 317801 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:48,609 : INFO : EPOCH 18 - PROGRESS: at 89.28% examples, 309929 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:49,167 : INFO : EPOCH 18: training on 1877097 raw words (1778565 effective words) took 5.7s, 310122 effective words/s\n",
      "2023-03-27 18:50:50,179 : INFO : EPOCH 19 - PROGRESS: at 15.27% examples, 386292 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:51,186 : INFO : EPOCH 19 - PROGRESS: at 33.01% examples, 337893 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:52,192 : INFO : EPOCH 19 - PROGRESS: at 50.24% examples, 324871 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:53,196 : INFO : EPOCH 19 - PROGRESS: at 68.26% examples, 321868 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:54,201 : INFO : EPOCH 19 - PROGRESS: at 86.94% examples, 310818 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:54,885 : INFO : EPOCH 19: training on 1877097 raw words (1778377 effective words) took 5.7s, 311117 effective words/s\n",
      "2023-03-27 18:50:55,890 : INFO : EPOCH 20 - PROGRESS: at 15.27% examples, 389072 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:56,915 : INFO : EPOCH 20 - PROGRESS: at 33.75% examples, 339380 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:50:57,953 : INFO : EPOCH 20 - PROGRESS: at 51.29% examples, 327034 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:50:58,990 : INFO : EPOCH 20 - PROGRESS: at 68.26% examples, 316040 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:00,003 : INFO : EPOCH 20 - PROGRESS: at 88.21% examples, 309680 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:00,650 : INFO : EPOCH 20: training on 1877097 raw words (1778728 effective words) took 5.8s, 308669 effective words/s\n",
      "2023-03-27 18:51:01,667 : INFO : EPOCH 21 - PROGRESS: at 15.27% examples, 384077 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:02,692 : INFO : EPOCH 21 - PROGRESS: at 33.75% examples, 337464 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:03,706 : INFO : EPOCH 21 - PROGRESS: at 50.81% examples, 324979 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:04,711 : INFO : EPOCH 21 - PROGRESS: at 68.26% examples, 319512 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:05,737 : INFO : EPOCH 21 - PROGRESS: at 87.51% examples, 309661 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:06,389 : INFO : EPOCH 21: training on 1877097 raw words (1778834 effective words) took 5.7s, 310033 effective words/s\n",
      "2023-03-27 18:51:07,396 : INFO : EPOCH 22 - PROGRESS: at 15.27% examples, 388121 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:08,415 : INFO : EPOCH 22 - PROGRESS: at 33.01% examples, 336891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:09,438 : INFO : EPOCH 22 - PROGRESS: at 50.81% examples, 325843 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:10,456 : INFO : EPOCH 22 - PROGRESS: at 68.26% examples, 319118 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:11,473 : INFO : EPOCH 22 - PROGRESS: at 87.65% examples, 309910 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:51:12,140 : INFO : EPOCH 22: training on 1877097 raw words (1779277 effective words) took 5.7s, 309528 effective words/s\n",
      "2023-03-27 18:51:13,203 : INFO : EPOCH 23 - PROGRESS: at 16.05% examples, 376681 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:14,207 : INFO : EPOCH 23 - PROGRESS: at 34.50% examples, 336141 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:15,237 : INFO : EPOCH 23 - PROGRESS: at 50.72% examples, 320567 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:16,283 : INFO : EPOCH 23 - PROGRESS: at 68.93% examples, 315021 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:17,346 : INFO : EPOCH 23 - PROGRESS: at 88.72% examples, 306300 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:17,933 : INFO : EPOCH 23: training on 1877097 raw words (1777982 effective words) took 5.8s, 307014 effective words/s\n",
      "2023-03-27 18:51:18,962 : INFO : EPOCH 24 - PROGRESS: at 15.27% examples, 380095 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:20,013 : INFO : EPOCH 24 - PROGRESS: at 33.75% examples, 331265 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:21,024 : INFO : EPOCH 24 - PROGRESS: at 51.29% examples, 324666 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:22,026 : INFO : EPOCH 24 - PROGRESS: at 68.26% examples, 316980 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:23,058 : INFO : EPOCH 24 - PROGRESS: at 87.65% examples, 307402 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:23,715 : INFO : EPOCH 24: training on 1877097 raw words (1779002 effective words) took 5.8s, 307817 effective words/s\n",
      "2023-03-27 18:51:24,722 : INFO : EPOCH 25 - PROGRESS: at 14.47% examples, 378633 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:25,759 : INFO : EPOCH 25 - PROGRESS: at 33.01% examples, 333797 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:26,766 : INFO : EPOCH 25 - PROGRESS: at 50.24% examples, 322237 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:27,777 : INFO : EPOCH 25 - PROGRESS: at 67.75% examples, 316842 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:28,802 : INFO : EPOCH 25 - PROGRESS: at 86.94% examples, 307719 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:29,494 : INFO : EPOCH 25: training on 1877097 raw words (1778989 effective words) took 5.8s, 307971 effective words/s\n",
      "2023-03-27 18:51:30,500 : INFO : EPOCH 26 - PROGRESS: at 14.47% examples, 378844 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:31,504 : INFO : EPOCH 26 - PROGRESS: at 33.01% examples, 339489 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:32,544 : INFO : EPOCH 26 - PROGRESS: at 50.24% examples, 322291 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:33,552 : INFO : EPOCH 26 - PROGRESS: at 67.75% examples, 317209 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:34,562 : INFO : EPOCH 26 - PROGRESS: at 86.94% examples, 308889 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:35,264 : INFO : EPOCH 26: training on 1877097 raw words (1779165 effective words) took 5.8s, 308429 effective words/s\n",
      "2023-03-27 18:51:36,271 : INFO : EPOCH 27 - PROGRESS: at 14.47% examples, 378935 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:37,288 : INFO : EPOCH 27 - PROGRESS: at 33.01% examples, 337288 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:38,302 : INFO : EPOCH 27 - PROGRESS: at 50.24% examples, 323622 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:39,357 : INFO : EPOCH 27 - PROGRESS: at 68.26% examples, 316982 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:40,359 : INFO : EPOCH 27 - PROGRESS: at 87.65% examples, 309201 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:41,023 : INFO : EPOCH 27: training on 1877097 raw words (1778623 effective words) took 5.8s, 309010 effective words/s\n",
      "2023-03-27 18:51:42,026 : INFO : EPOCH 28 - PROGRESS: at 14.47% examples, 379709 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:43,072 : INFO : EPOCH 28 - PROGRESS: at 33.75% examples, 336111 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:44,109 : INFO : EPOCH 28 - PROGRESS: at 51.77% examples, 328377 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:45,156 : INFO : EPOCH 28 - PROGRESS: at 69.87% examples, 318065 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:46,176 : INFO : EPOCH 28 - PROGRESS: at 89.28% examples, 311451 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:46,737 : INFO : EPOCH 28: training on 1877097 raw words (1778281 effective words) took 5.7s, 311298 effective words/s\n",
      "2023-03-27 18:51:47,743 : INFO : EPOCH 29 - PROGRESS: at 14.47% examples, 379125 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:48,760 : INFO : EPOCH 29 - PROGRESS: at 33.01% examples, 337385 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:49,767 : INFO : EPOCH 29 - PROGRESS: at 50.24% examples, 324455 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:50,784 : INFO : EPOCH 29 - PROGRESS: at 67.75% examples, 318139 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:51:51,808 : INFO : EPOCH 29 - PROGRESS: at 86.94% examples, 308712 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:52,537 : INFO : EPOCH 29: training on 1877097 raw words (1778794 effective words) took 5.8s, 306822 effective words/s\n",
      "2023-03-27 18:51:53,569 : INFO : EPOCH 30 - PROGRESS: at 15.25% examples, 378907 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:54,589 : INFO : EPOCH 30 - PROGRESS: at 33.75% examples, 335886 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:55,630 : INFO : EPOCH 30 - PROGRESS: at 50.72% examples, 321230 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:56,694 : INFO : EPOCH 30 - PROGRESS: at 68.93% examples, 314165 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:57,738 : INFO : EPOCH 30 - PROGRESS: at 88.72% examples, 306710 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:51:58,340 : INFO : EPOCH 30: training on 1877097 raw words (1778482 effective words) took 5.8s, 306630 effective words/s\n",
      "2023-03-27 18:51:59,360 : INFO : EPOCH 31 - PROGRESS: at 15.27% examples, 383009 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:00,384 : INFO : EPOCH 31 - PROGRESS: at 33.01% examples, 333695 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:01,396 : INFO : EPOCH 31 - PROGRESS: at 50.24% examples, 321649 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:02,406 : INFO : EPOCH 31 - PROGRESS: at 67.75% examples, 316499 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:03,450 : INFO : EPOCH 31 - PROGRESS: at 86.94% examples, 306314 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:04,146 : INFO : EPOCH 31: training on 1877097 raw words (1779038 effective words) took 5.8s, 306516 effective words/s\n",
      "2023-03-27 18:52:05,157 : INFO : EPOCH 32 - PROGRESS: at 14.47% examples, 376840 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:06,214 : INFO : EPOCH 32 - PROGRESS: at 33.01% examples, 330037 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:07,224 : INFO : EPOCH 32 - PROGRESS: at 50.81% examples, 322709 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:08,313 : INFO : EPOCH 32 - PROGRESS: at 68.93% examples, 313410 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:09,334 : INFO : EPOCH 32 - PROGRESS: at 88.72% examples, 307510 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:09,936 : INFO : EPOCH 32: training on 1877097 raw words (1778569 effective words) took 5.8s, 307315 effective words/s\n",
      "2023-03-27 18:52:10,945 : INFO : EPOCH 33 - PROGRESS: at 15.27% examples, 387385 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:12,004 : INFO : EPOCH 33 - PROGRESS: at 33.75% examples, 333080 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:13,059 : INFO : EPOCH 33 - PROGRESS: at 51.77% examples, 324396 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:14,073 : INFO : EPOCH 33 - PROGRESS: at 69.20% examples, 315693 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:15,077 : INFO : EPOCH 33 - PROGRESS: at 88.72% examples, 310180 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:15,680 : INFO : EPOCH 33: training on 1877097 raw words (1778270 effective words) took 5.7s, 309706 effective words/s\n",
      "2023-03-27 18:52:16,687 : INFO : EPOCH 34 - PROGRESS: at 14.47% examples, 378799 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:17,734 : INFO : EPOCH 34 - PROGRESS: at 33.75% examples, 335365 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:18,766 : INFO : EPOCH 34 - PROGRESS: at 51.77% examples, 328442 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 18:52:19,769 : INFO : EPOCH 34 - PROGRESS: at 68.93% examples, 319387 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:20,771 : INFO : EPOCH 34 - PROGRESS: at 89.28% examples, 315427 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:21,340 : INFO : EPOCH 34: training on 1877097 raw words (1779113 effective words) took 5.7s, 314458 effective words/s\n",
      "2023-03-27 18:52:22,351 : INFO : EPOCH 35 - PROGRESS: at 14.47% examples, 376837 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:23,374 : INFO : EPOCH 35 - PROGRESS: at 33.01% examples, 335328 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:24,385 : INFO : EPOCH 35 - PROGRESS: at 50.81% examples, 326069 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:25,453 : INFO : EPOCH 35 - PROGRESS: at 68.93% examples, 317439 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:26,465 : INFO : EPOCH 35 - PROGRESS: at 88.72% examples, 311276 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:27,074 : INFO : EPOCH 35: training on 1877097 raw words (1778610 effective words) took 5.7s, 310273 effective words/s\n",
      "2023-03-27 18:52:28,077 : INFO : EPOCH 36 - PROGRESS: at 14.47% examples, 380311 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:29,126 : INFO : EPOCH 36 - PROGRESS: at 33.01% examples, 332501 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:30,201 : INFO : EPOCH 36 - PROGRESS: at 50.24% examples, 314489 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:31,216 : INFO : EPOCH 36 - PROGRESS: at 65.40% examples, 301093 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:32,224 : INFO : EPOCH 36 - PROGRESS: at 81.59% examples, 288820 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:33,230 : INFO : EPOCH 36 - PROGRESS: at 98.47% examples, 286147 words/s, in_qsize 2, out_qsize 1\n",
      "2023-03-27 18:52:33,268 : INFO : EPOCH 36: training on 1877097 raw words (1778260 effective words) took 6.2s, 287214 effective words/s\n",
      "2023-03-27 18:52:34,345 : INFO : EPOCH 37 - PROGRESS: at 14.47% examples, 353795 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:35,386 : INFO : EPOCH 37 - PROGRESS: at 33.00% examples, 322121 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:36,440 : INFO : EPOCH 37 - PROGRESS: at 50.24% examples, 309845 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:37,490 : INFO : EPOCH 37 - PROGRESS: at 67.18% examples, 302312 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:38,514 : INFO : EPOCH 37 - PROGRESS: at 85.53% examples, 294455 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:39,319 : INFO : EPOCH 37: training on 1877097 raw words (1778296 effective words) took 6.0s, 294004 effective words/s\n",
      "2023-03-27 18:52:40,387 : INFO : EPOCH 38 - PROGRESS: at 14.52% examples, 356985 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:41,404 : INFO : EPOCH 38 - PROGRESS: at 31.52% examples, 320703 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:42,425 : INFO : EPOCH 38 - PROGRESS: at 48.73% examples, 307073 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:43,464 : INFO : EPOCH 38 - PROGRESS: at 66.00% examples, 303148 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:44,501 : INFO : EPOCH 38 - PROGRESS: at 84.84% examples, 296242 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:45,338 : INFO : EPOCH 38: training on 1877097 raw words (1778367 effective words) took 6.0s, 295586 effective words/s\n",
      "2023-03-27 18:52:46,381 : INFO : EPOCH 39 - PROGRESS: at 14.47% examples, 365302 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:47,400 : INFO : EPOCH 39 - PROGRESS: at 31.52% examples, 324190 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:48,424 : INFO : EPOCH 39 - PROGRESS: at 48.73% examples, 309065 words/s, in_qsize 6, out_qsize 0\n",
      "2023-03-27 18:52:49,439 : INFO : EPOCH 39 - PROGRESS: at 66.00% examples, 306483 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:50,454 : INFO : EPOCH 39 - PROGRESS: at 84.84% examples, 300049 words/s, in_qsize 5, out_qsize 0\n",
      "2023-03-27 18:52:51,239 : INFO : EPOCH 39: training on 1877097 raw words (1778824 effective words) took 5.9s, 301559 effective words/s\n",
      "2023-03-27 18:52:51,239 : INFO : Doc2Vec lifecycle event {'msg': 'training on 75083880 raw words (71147767 effective words) took 231.3s, 307633 effective words/s', 'datetime': '2023-03-27T18:52:51.239574', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(tagged_corpus_en, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 13:43:04,303 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2023-03-30 13:43:04,304 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2023-03-30 13:43:04,340 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2023-03-30T13:43:04.305690', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_tmpfile(\"doc2vec_for_literals_disambiguation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpgqs075ed/doc2vec_for_literals_disambiguation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 19:34:22,967 : INFO : Doc2Vec lifecycle event {'fname_or_handle': '/var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpny_bpeoi/doc2vec_for_literals_disambiguation', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-03-27T19:34:22.967074', 'gensim': '4.3.0', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2023-03-27 19:34:22,968 : INFO : not storing attribute cum_table\n",
      "2023-03-27 19:34:23,027 : INFO : saved /var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpny_bpeoi/doc2vec_for_literals_disambiguation\n"
     ]
    }
   ],
   "source": [
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 13:43:39,926 : INFO : loading Doc2Vec object from /var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpgqs075ed/doc2vec_for_literals_disambiguation\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpgqs075ed/doc2vec_for_literals_disambiguation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a7b56071e442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrethrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             logger.error(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \"\"\"\n\u001b[1;32m   1941\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/var/folders/hh/6wcbz37550q71080d_57dlyw0000gn/T/tmpgqs075ed/doc2vec_for_literals_disambiguation'"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10006735, -0.09099598,  0.18476892,  0.05892054,  0.01515821,\n",
       "       -0.00475166, -0.38807815, -0.13774407, -0.19049756,  0.17214076,\n",
       "       -0.04740298, -0.13652608, -0.20511973, -0.16564879, -0.04708961,\n",
       "       -0.11566802,  0.16306467,  0.07564908, -0.07143099,  0.11591461,\n",
       "       -0.08985341,  0.11859614,  0.19277763,  0.1120984 ,  0.10341622,\n",
       "        0.1801612 ,  0.10100152, -0.3975583 ,  0.05903649,  0.15550284,\n",
       "       -0.13116123,  0.02946616,  0.15778813,  0.38174975, -0.03603979,\n",
       "        0.03754644,  0.17478575,  0.27618977,  0.2038919 ,  0.360196  ,\n",
       "        0.10085315,  0.44833648, -0.06487529,  0.11565264, -0.03100512,\n",
       "       -0.25806347,  0.05614974, -0.03233728, -0.48763245, -0.02308856],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['black', 'people', 'art'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related matches\n",
    "with open('/Users/anesterov/reps/LODlit/bg/rm_bows_all.json','r') as jf:\n",
    "    rm_bows = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_black = []\n",
    "rm_black.extend(rm_bows[\"en\"][\"black\"][\"wikidata\"])\n",
    "rm_black.extend(rm_bows[\"en\"][\"black\"][\"aat\"])\n",
    "rm_black.extend(rm_bows[\"en\"][\"black\"][\"pwn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "black = list(set(rm_black))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_black = ['people', 'france', 'human', 'population', 'african', 'immigration', 'france', 'racial', 'multi', 'ethnic', 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36727932]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(model.infer_vector(black).reshape(1, -1), model.infer_vector(experiment_black).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (6142): primitive strain short film film arthur berthelet\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (158216, 0.772796630859375): back primitive short film film francis boggs otis turner\n",
      "\n",
      "MEDIAN (165660, 0.19055573642253876): toyopn indigenous chieftaincy costa rica\n",
      "\n",
      "LEAST (115769, -0.5890066027641296): electric funeral original song written composed performed black sabbath\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus_en) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus_en[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): {}\\n'.format(doc_id, ' '.join(test_corpus_en[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: %s\\n' % (label, sims[index], ' '.join(tagged_corpus_en[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(158216, 0.772796630859375),\n",
       " (158282, 0.7629953026771545),\n",
       " (158484, 0.7434939742088318),\n",
       " (9737, 0.7417248487472534),\n",
       " (158468, 0.735752284526825),\n",
       " (9734, 0.7290006875991821),\n",
       " (158167, 0.727756142616272),\n",
       " (158217, 0.7245995998382568),\n",
       " (157987, 0.7135770320892334),\n",
       " (158211, 0.7120720148086548),\n",
       " (158187, 0.709780216217041),\n",
       " (158235, 0.7083865404129028),\n",
       " (158226, 0.7068758606910706),\n",
       " (158288, 0.6905967593193054),\n",
       " (158190, 0.684939980506897),\n",
       " (158179, 0.6816670298576355),\n",
       " (158269, 0.6815990209579468),\n",
       " (9834, 0.6755386590957642),\n",
       " (9771, 0.6667096018791199),\n",
       " (158672, 0.6601245999336243),\n",
       " (158207, 0.6588665246963501),\n",
       " (9793, 0.6550884246826172),\n",
       " (9751, 0.6447477340698242),\n",
       " (158328, 0.6410449743270874),\n",
       " (9766, 0.6346874833106995),\n",
       " (158718, 0.627562403678894),\n",
       " (158029, 0.6110966801643372),\n",
       " (158174, 0.6094334125518799),\n",
       " (158233, 0.6085729598999023),\n",
       " (9736, 0.6081785559654236),\n",
       " (158240, 0.6054738759994507),\n",
       " (158082, 0.6022983193397522),\n",
       " (4517, 0.6010955572128296),\n",
       " (74705, 0.599717378616333),\n",
       " (9770, 0.5991020798683167),\n",
       " (133917, 0.595787525177002),\n",
       " (158169, 0.5939677953720093),\n",
       " (158022, 0.5938756465911865),\n",
       " (9745, 0.5921677947044373),\n",
       " (158642, 0.5919141173362732),\n",
       " (91168, 0.5915132761001587),\n",
       " (158607, 0.5909786224365234),\n",
       " (158312, 0.5900489091873169),\n",
       " (9757, 0.5895172953605652),\n",
       " (108739, 0.5883352756500244),\n",
       " (158264, 0.584594190120697),\n",
       " (9765, 0.5768918991088867),\n",
       " (9774, 0.5750178694725037),\n",
       " (158170, 0.574998140335083),\n",
       " (40013, 0.5748949646949768),\n",
       " (44339, 0.5745973587036133),\n",
       " (103477, 0.5745652318000793),\n",
       " (4515, 0.5716456174850464),\n",
       " (9744, 0.5686439871788025),\n",
       " (9775, 0.5682722926139832),\n",
       " (79018, 0.5675724744796753),\n",
       " (9748, 0.5675498843193054),\n",
       " (3756, 0.5646816492080688),\n",
       " (55937, 0.5642101168632507),\n",
       " (158721, 0.5633131861686707),\n",
       " (158356, 0.5629311203956604),\n",
       " (9810, 0.5629071593284607),\n",
       " (43866, 0.5626662373542786),\n",
       " (158391, 0.5618293881416321),\n",
       " (121425, 0.5581710338592529),\n",
       " (55517, 0.5575331449508667),\n",
       " (158504, 0.5571067333221436),\n",
       " (89893, 0.5571030378341675),\n",
       " (40285, 0.5562968254089355),\n",
       " (39088, 0.5561891198158264),\n",
       " (58083, 0.5540488958358765),\n",
       " (91486, 0.5527926683425903),\n",
       " (39386, 0.552482545375824),\n",
       " (57097, 0.5520055890083313),\n",
       " (158555, 0.5512470006942749),\n",
       " (173220, 0.5502561330795288),\n",
       " (43443, 0.5488066077232361),\n",
       " (69947, 0.5486923456192017),\n",
       " (9802, 0.5481621026992798),\n",
       " (39305, 0.5473901033401489),\n",
       " (39658, 0.5460453629493713),\n",
       " (99540, 0.5441208481788635),\n",
       " (169550, 0.5438452363014221),\n",
       " (11781, 0.5429463386535645),\n",
       " (49040, 0.5422037839889526),\n",
       " (41993, 0.5420840978622437),\n",
       " (110768, 0.5415100455284119),\n",
       " (9735, 0.5403196215629578),\n",
       " (9768, 0.539900004863739),\n",
       " (45587, 0.5391850471496582),\n",
       " (39199, 0.5383297204971313),\n",
       " (158200, 0.5376482605934143),\n",
       " (7802, 0.5367549061775208),\n",
       " (57033, 0.5365635752677917),\n",
       " (9760, 0.5362400412559509),\n",
       " (41701, 0.5352931618690491),\n",
       " (9784, 0.5351096987724304),\n",
       " (115510, 0.5346991419792175),\n",
       " (56567, 0.5344974398612976),\n",
       " (623, 0.5344451665878296),\n",
       " (158383, 0.533915638923645),\n",
       " (1943, 0.533693253993988),\n",
       " (67365, 0.5333062410354614),\n",
       " (129966, 0.5327501893043518),\n",
       " (113658, 0.5321439504623413),\n",
       " (44430, 0.532012403011322),\n",
       " (9738, 0.5318999290466309),\n",
       " (62568, 0.5310093760490417),\n",
       " (41674, 0.5309878587722778),\n",
       " (66913, 0.5299025774002075),\n",
       " (158171, 0.5298497676849365),\n",
       " (41439, 0.5288386344909668),\n",
       " (44439, 0.5284652709960938),\n",
       " (166489, 0.5283756256103516),\n",
       " (64027, 0.5281593203544617),\n",
       " (12468, 0.5281484127044678),\n",
       " (4514, 0.527169406414032),\n",
       " (40005, 0.5271586775779724),\n",
       " (56003, 0.5261778235435486),\n",
       " (158168, 0.52541184425354),\n",
       " (158175, 0.5249766111373901),\n",
       " (119440, 0.524796724319458),\n",
       " (158237, 0.5246331691741943),\n",
       " (38742, 0.5241604447364807),\n",
       " (62859, 0.523735523223877),\n",
       " (158713, 0.5226492881774902),\n",
       " (55046, 0.5219421982765198),\n",
       " (175127, 0.5215942859649658),\n",
       " (145553, 0.5213798880577087),\n",
       " (61337, 0.5207064151763916),\n",
       " (2567, 0.5199815630912781),\n",
       " (158341, 0.5196482539176941),\n",
       " (158606, 0.518930971622467),\n",
       " (158057, 0.5188698768615723),\n",
       " (158274, 0.5188531875610352),\n",
       " (158717, 0.518619954586029),\n",
       " (158215, 0.5182955265045166),\n",
       " (158421, 0.5180945992469788),\n",
       " (39843, 0.5178229212760925),\n",
       " (158550, 0.5174534320831299),\n",
       " (86375, 0.5171092748641968),\n",
       " (158852, 0.5169399976730347),\n",
       " (27672, 0.5165657997131348),\n",
       " (159686, 0.5164752006530762),\n",
       " (146340, 0.5163947939872742),\n",
       " (52089, 0.5163813829421997),\n",
       " (62690, 0.5153383612632751),\n",
       " (9759, 0.5152344703674316),\n",
       " (44060, 0.5148876905441284),\n",
       " (53279, 0.514824628829956),\n",
       " (61213, 0.5146030187606812),\n",
       " (57436, 0.5140452980995178),\n",
       " (2832, 0.5140201449394226),\n",
       " (117503, 0.5136377215385437),\n",
       " (112466, 0.5133795738220215),\n",
       " (9746, 0.51335209608078),\n",
       " (158883, 0.5130712389945984),\n",
       " (9422, 0.5125501751899719),\n",
       " (158108, 0.5124405026435852),\n",
       " (70001, 0.5122182369232178),\n",
       " (176319, 0.5120552182197571),\n",
       " (70605, 0.511685848236084),\n",
       " (46521, 0.511631965637207),\n",
       " (9755, 0.5111750960350037),\n",
       " (4534, 0.5105684995651245),\n",
       " (70127, 0.5101301670074463),\n",
       " (13166, 0.5097612142562866),\n",
       " (26015, 0.5097306370735168),\n",
       " (14720, 0.5096202492713928),\n",
       " (158461, 0.5091779232025146),\n",
       " (4508, 0.5091198682785034),\n",
       " (62081, 0.508764922618866),\n",
       " (39779, 0.5087205767631531),\n",
       " (109236, 0.5083523988723755),\n",
       " (176964, 0.5082427263259888),\n",
       " (39673, 0.5082398056983948),\n",
       " (158327, 0.5077342987060547),\n",
       " (9800, 0.5074339509010315),\n",
       " (11314, 0.5072648525238037),\n",
       " (112469, 0.5072222352027893),\n",
       " (64392, 0.5071362257003784),\n",
       " (42816, 0.5069515109062195),\n",
       " (39561, 0.5068990588188171),\n",
       " (157885, 0.5068262815475464),\n",
       " (161166, 0.5067412257194519),\n",
       " (57235, 0.5067275166511536),\n",
       " (37820, 0.5066261887550354),\n",
       " (160107, 0.5063652396202087),\n",
       " (50282, 0.5062875747680664),\n",
       " (5869, 0.5060304999351501),\n",
       " (55832, 0.5057141184806824),\n",
       " (158227, 0.5055318474769592),\n",
       " (17943, 0.5055226683616638),\n",
       " (39177, 0.5051615238189697),\n",
       " (158340, 0.5051497220993042),\n",
       " (119861, 0.5050919055938721),\n",
       " (94097, 0.504790186882019),\n",
       " (112584, 0.504353940486908),\n",
       " (11440, 0.5042749643325806),\n",
       " (42918, 0.5041788220405579),\n",
       " (63173, 0.5040082931518555),\n",
       " (9801, 0.503896176815033),\n",
       " (159613, 0.5034649968147278),\n",
       " (66846, 0.5034164190292358),\n",
       " (61476, 0.5033047795295715),\n",
       " (43448, 0.5033000111579895),\n",
       " (41481, 0.5032331943511963),\n",
       " (83434, 0.5031079649925232),\n",
       " (39208, 0.5028591156005859),\n",
       " (2507, 0.5028468370437622),\n",
       " (90705, 0.5024778842926025),\n",
       " (1990, 0.5024284720420837),\n",
       " (69682, 0.5023053288459778),\n",
       " (40755, 0.5022820234298706),\n",
       " (158287, 0.5018291473388672),\n",
       " (89429, 0.5012486577033997),\n",
       " (168629, 0.5011286735534668),\n",
       " (57316, 0.5009865760803223),\n",
       " (60851, 0.5007661581039429),\n",
       " (61752, 0.5006358027458191),\n",
       " (9750, 0.5004228949546814),\n",
       " (63557, 0.5001127123832703),\n",
       " (170370, 0.5001120567321777),\n",
       " (158311, 0.4999098777770996),\n",
       " (87080, 0.499765545129776),\n",
       " (41544, 0.4995478391647339),\n",
       " (41799, 0.49926719069480896),\n",
       " (54871, 0.49924325942993164),\n",
       " (9781, 0.49920907616615295),\n",
       " (9815, 0.49909043312072754),\n",
       " (56974, 0.4990439713001251),\n",
       " (13123, 0.4987046718597412),\n",
       " (158499, 0.49861106276512146),\n",
       " (9799, 0.4985916316509247),\n",
       " (112639, 0.4985559284687042),\n",
       " (39173, 0.49821797013282776),\n",
       " (108172, 0.4971860349178314),\n",
       " (60383, 0.4968997538089752),\n",
       " (103251, 0.4968688189983368),\n",
       " (7101, 0.49677807092666626),\n",
       " (112596, 0.4967305660247803),\n",
       " (161867, 0.49672412872314453),\n",
       " (80807, 0.49649912118911743),\n",
       " (37712, 0.4964587688446045),\n",
       " (158462, 0.4959583878517151),\n",
       " (73319, 0.4957869052886963),\n",
       " (77311, 0.4956454336643219),\n",
       " (62105, 0.495622456073761),\n",
       " (116386, 0.4955863654613495),\n",
       " (4759, 0.49549224972724915),\n",
       " (83241, 0.4954817295074463),\n",
       " (112673, 0.49538901448249817),\n",
       " (9792, 0.4951043128967285),\n",
       " (161983, 0.49504023790359497),\n",
       " (159779, 0.4948030710220337),\n",
       " (158474, 0.4945363700389862),\n",
       " (56973, 0.4941081404685974),\n",
       " (9752, 0.49409541487693787),\n",
       " (109722, 0.4940941035747528),\n",
       " (61695, 0.49371570348739624),\n",
       " (55953, 0.49371421337127686),\n",
       " (142642, 0.49363574385643005),\n",
       " (100183, 0.49351125955581665),\n",
       " (66812, 0.4931810796260834),\n",
       " (59266, 0.4931410253047943),\n",
       " (120525, 0.49276068806648254),\n",
       " (56912, 0.49271926283836365),\n",
       " (65743, 0.49271512031555176),\n",
       " (67297, 0.4926546812057495),\n",
       " (76380, 0.492502361536026),\n",
       " (113208, 0.49239566922187805),\n",
       " (9839, 0.49213194847106934),\n",
       " (171644, 0.49181053042411804),\n",
       " (158153, 0.4917142987251282),\n",
       " (170798, 0.49148625135421753),\n",
       " (118263, 0.4914513826370239),\n",
       " (91639, 0.4912346601486206),\n",
       " (56911, 0.4912162721157074),\n",
       " (39671, 0.4912128448486328),\n",
       " (102083, 0.4912041425704956),\n",
       " (77073, 0.4911816120147705),\n",
       " (24463, 0.4910229444503784),\n",
       " (8494, 0.49090683460235596),\n",
       " (63854, 0.4908882975578308),\n",
       " (44462, 0.4908757209777832),\n",
       " (56357, 0.4907412528991699),\n",
       " (112150, 0.4907158315181732),\n",
       " (177061, 0.4906232953071594),\n",
       " (58663, 0.4905893802642822),\n",
       " (9754, 0.49041229486465454),\n",
       " (158010, 0.49040278792381287),\n",
       " (29342, 0.4903370141983032),\n",
       " (56866, 0.4899900555610657),\n",
       " (105674, 0.4896879196166992),\n",
       " (77312, 0.489532470703125),\n",
       " (91510, 0.48934486508369446),\n",
       " (129873, 0.4893420338630676),\n",
       " (158199, 0.4890562891960144),\n",
       " (58933, 0.48882079124450684),\n",
       " (55822, 0.48876845836639404),\n",
       " (143281, 0.4887315332889557),\n",
       " (158178, 0.48871326446533203),\n",
       " (167076, 0.4886028468608856),\n",
       " (126558, 0.48832273483276367),\n",
       " (105837, 0.48819783329963684),\n",
       " (112703, 0.487982839345932),\n",
       " (11321, 0.487916499376297),\n",
       " (54714, 0.48776525259017944),\n",
       " (81502, 0.48758092522621155),\n",
       " (146435, 0.4875183701515198),\n",
       " (41348, 0.48747938871383667),\n",
       " (60134, 0.48746323585510254),\n",
       " (158512, 0.4872840642929077),\n",
       " (158366, 0.487171471118927),\n",
       " (46230, 0.48716047406196594),\n",
       " (91167, 0.4871371388435364),\n",
       " (68492, 0.48698633909225464),\n",
       " (64745, 0.4869525730609894),\n",
       " (103848, 0.48684820532798767),\n",
       " (116049, 0.4867444932460785),\n",
       " (158481, 0.48658567667007446),\n",
       " (39810, 0.48655965924263),\n",
       " (61716, 0.48635008931159973),\n",
       " (148175, 0.4862616956233978),\n",
       " (39680, 0.48620983958244324),\n",
       " (112739, 0.4861764907836914),\n",
       " (55433, 0.4860287308692932),\n",
       " (105328, 0.48591285943984985),\n",
       " (154341, 0.48579490184783936),\n",
       " (122103, 0.4855676591396332),\n",
       " (41159, 0.4854430556297302),\n",
       " (145054, 0.4851703345775604),\n",
       " (39307, 0.48516497015953064),\n",
       " (39496, 0.48515236377716064),\n",
       " (74560, 0.4850325584411621),\n",
       " (39444, 0.485015332698822),\n",
       " (97011, 0.4849597215652466),\n",
       " (152155, 0.4847196340560913),\n",
       " (64591, 0.4845779240131378),\n",
       " (119356, 0.48436546325683594),\n",
       " (112769, 0.48435160517692566),\n",
       " (9747, 0.4842365086078644),\n",
       " (57121, 0.48400139808654785),\n",
       " (139263, 0.48389333486557007),\n",
       " (60557, 0.4838412404060364),\n",
       " (158000, 0.4835771322250366),\n",
       " (38110, 0.4835507571697235),\n",
       " (92861, 0.4834771454334259),\n",
       " (4516, 0.4834364354610443),\n",
       " (175469, 0.48334816098213196),\n",
       " (158298, 0.48323217034339905),\n",
       " (84563, 0.4832231402397156),\n",
       " (155830, 0.48307186365127563),\n",
       " (112745, 0.4829483926296234),\n",
       " (158270, 0.4828529953956604),\n",
       " (166482, 0.48252108693122864),\n",
       " (63006, 0.4823603630065918),\n",
       " (56023, 0.4823494255542755),\n",
       " (104744, 0.4822847247123718),\n",
       " (108003, 0.48220109939575195),\n",
       " (158480, 0.4821206033229828),\n",
       " (61151, 0.4820288419723511),\n",
       " (161746, 0.48183661699295044),\n",
       " (158164, 0.48170074820518494),\n",
       " (62338, 0.48137524724006653),\n",
       " (158186, 0.48108696937561035),\n",
       " (109465, 0.4810752868652344),\n",
       " (38903, 0.48085176944732666),\n",
       " (66136, 0.48084384202957153),\n",
       " (140707, 0.48078203201293945),\n",
       " (28210, 0.48075664043426514),\n",
       " (174939, 0.4805450141429901),\n",
       " (140607, 0.4804781377315521),\n",
       " (158995, 0.4803653657436371),\n",
       " (59413, 0.48036089539527893),\n",
       " (61419, 0.48035869002342224),\n",
       " (53501, 0.4801734387874603),\n",
       " (43847, 0.4800978899002075),\n",
       " (65586, 0.4799724519252777),\n",
       " (62612, 0.4798901081085205),\n",
       " (62947, 0.47982603311538696),\n",
       " (118902, 0.47981497645378113),\n",
       " (64239, 0.4797974228858948),\n",
       " (62878, 0.4795100688934326),\n",
       " (39771, 0.4795088469982147),\n",
       " (38536, 0.47947701811790466),\n",
       " (105452, 0.47946763038635254),\n",
       " (59064, 0.4794451594352722),\n",
       " (133451, 0.4794100821018219),\n",
       " (9756, 0.4793356657028198),\n",
       " (126702, 0.4793316721916199),\n",
       " (5173, 0.4793242812156677),\n",
       " (158878, 0.47932323813438416),\n",
       " (62154, 0.4793211817741394),\n",
       " (60237, 0.4793160855770111),\n",
       " (9394, 0.47922787070274353),\n",
       " (24369, 0.47910168766975403),\n",
       " (47060, 0.479024738073349),\n",
       " (68709, 0.47889068722724915),\n",
       " (11317, 0.4785407781600952),\n",
       " (16102, 0.4783543050289154),\n",
       " (112672, 0.4783109128475189),\n",
       " (77305, 0.47825098037719727),\n",
       " (132903, 0.4781900942325592),\n",
       " (46114, 0.4781743288040161),\n",
       " (107103, 0.47813862562179565),\n",
       " (163329, 0.4779774248600006),\n",
       " (42920, 0.4778273403644562),\n",
       " (9830, 0.4777403473854065),\n",
       " (103141, 0.4776724576950073),\n",
       " (159958, 0.47752371430397034),\n",
       " (38390, 0.4774726331233978),\n",
       " (89793, 0.47739243507385254),\n",
       " (104266, 0.477387934923172),\n",
       " (2809, 0.4773797392845154),\n",
       " (113550, 0.4771924912929535),\n",
       " (61405, 0.47688084840774536),\n",
       " (79426, 0.4767254889011383),\n",
       " (59652, 0.4765508472919464),\n",
       " (162529, 0.4762031137943268),\n",
       " (112481, 0.4760608673095703),\n",
       " (45953, 0.47601398825645447),\n",
       " (56672, 0.47593820095062256),\n",
       " (44049, 0.4758525788784027),\n",
       " (56641, 0.47566699981689453),\n",
       " (50824, 0.4756469428539276),\n",
       " (61228, 0.475604385137558),\n",
       " (160613, 0.47536584734916687),\n",
       " (53616, 0.4753570854663849),\n",
       " (100894, 0.47521957755088806),\n",
       " (49334, 0.4750651717185974),\n",
       " (13010, 0.4750230014324188),\n",
       " (116910, 0.47501862049102783),\n",
       " (158463, 0.4749305546283722),\n",
       " (38939, 0.4747098386287689),\n",
       " (36585, 0.47470369935035706),\n",
       " (45251, 0.47457355260849),\n",
       " (61660, 0.47455981373786926),\n",
       " (77304, 0.47453659772872925),\n",
       " (104010, 0.4745139479637146),\n",
       " (17842, 0.47412100434303284),\n",
       " (61180, 0.47411713004112244),\n",
       " (50086, 0.4740898907184601),\n",
       " (175753, 0.4740774929523468),\n",
       " (99566, 0.4739246964454651),\n",
       " (143466, 0.47388213872909546),\n",
       " (57240, 0.47379323840141296),\n",
       " (92344, 0.4736906588077545),\n",
       " (53881, 0.4736800193786621),\n",
       " (109570, 0.4734969735145569),\n",
       " (18306, 0.4733332395553589),\n",
       " (43036, 0.4731847643852234),\n",
       " (100458, 0.4730987548828125),\n",
       " (50511, 0.47309452295303345),\n",
       " (56744, 0.47308826446533203),\n",
       " (38273, 0.47307637333869934),\n",
       " (101171, 0.4729797840118408),\n",
       " (57766, 0.4729347229003906),\n",
       " (167050, 0.47292208671569824),\n",
       " (113503, 0.4725790023803711),\n",
       " (112702, 0.4723234474658966),\n",
       " (60791, 0.4722681939601898),\n",
       " (152736, 0.4721772074699402),\n",
       " (78566, 0.4720531105995178),\n",
       " (112890, 0.4720398187637329),\n",
       " (158582, 0.47203341126441956),\n",
       " (39080, 0.47189319133758545),\n",
       " (9052, 0.47181347012519836),\n",
       " (122109, 0.4717990756034851),\n",
       " (25727, 0.4717511832714081),\n",
       " (91498, 0.47168803215026855),\n",
       " (27252, 0.47150325775146484),\n",
       " (151995, 0.4714599847793579),\n",
       " (59158, 0.47144508361816406),\n",
       " (65645, 0.4713309109210968),\n",
       " (58913, 0.47125643491744995),\n",
       " (41118, 0.47121042013168335),\n",
       " (72764, 0.47117745876312256),\n",
       " (148460, 0.47115811705589294),\n",
       " (87503, 0.4711121916770935),\n",
       " (14698, 0.47107741236686707),\n",
       " (9772, 0.47096264362335205),\n",
       " (39101, 0.47091689705848694),\n",
       " (139030, 0.47083809971809387),\n",
       " (38754, 0.47081905603408813),\n",
       " (57885, 0.4707118570804596),\n",
       " (86380, 0.47069066762924194),\n",
       " (59564, 0.47039076685905457),\n",
       " (112676, 0.47038960456848145),\n",
       " (36223, 0.47037839889526367),\n",
       " (56393, 0.47034770250320435),\n",
       " (9809, 0.4702679216861725),\n",
       " (23782, 0.4701565206050873),\n",
       " (125009, 0.47003281116485596),\n",
       " (158245, 0.4700029492378235),\n",
       " (55610, 0.46997228264808655),\n",
       " (117631, 0.46991580724716187),\n",
       " (105281, 0.46980735659599304),\n",
       " (25608, 0.46973279118537903),\n",
       " (58737, 0.4697226583957672),\n",
       " (102495, 0.46965813636779785),\n",
       " (41124, 0.4696214199066162),\n",
       " (162952, 0.46961334347724915),\n",
       " (9143, 0.4695899188518524),\n",
       " (154371, 0.4695141017436981),\n",
       " (20380, 0.46948522329330444),\n",
       " (45386, 0.46942615509033203),\n",
       " (89910, 0.4692862331867218),\n",
       " (40818, 0.469246506690979),\n",
       " (72934, 0.4691869914531708),\n",
       " (62714, 0.4691198170185089),\n",
       " (3316, 0.46905747056007385),\n",
       " (58953, 0.46904292702674866),\n",
       " (121353, 0.4690096378326416),\n",
       " (57699, 0.4689646065235138),\n",
       " (42453, 0.46892955899238586),\n",
       " (26084, 0.46889644861221313),\n",
       " (63415, 0.468782901763916),\n",
       " (158829, 0.46873679757118225),\n",
       " (159679, 0.4687254726886749),\n",
       " (161433, 0.468725323677063),\n",
       " (101855, 0.46872439980506897),\n",
       " (51996, 0.4686947762966156),\n",
       " (24118, 0.4686937630176544),\n",
       " (67464, 0.46869349479675293),\n",
       " (111999, 0.4686557352542877),\n",
       " (158350, 0.46864092350006104),\n",
       " (146752, 0.4685893952846527),\n",
       " (107130, 0.46858304738998413),\n",
       " (132378, 0.4685278832912445),\n",
       " (27819, 0.46851420402526855),\n",
       " (58703, 0.4684276580810547),\n",
       " (145949, 0.4683420956134796),\n",
       " (110649, 0.4679769277572632),\n",
       " (106764, 0.4679189622402191),\n",
       " (153036, 0.4677391052246094),\n",
       " (158095, 0.4676766097545624),\n",
       " (91815, 0.46766749024391174),\n",
       " (39929, 0.46764516830444336),\n",
       " (151180, 0.4675341546535492),\n",
       " (69148, 0.467500776052475),\n",
       " (161003, 0.46745750308036804),\n",
       " (51812, 0.46739086508750916),\n",
       " (162246, 0.46719059348106384),\n",
       " (171802, 0.46700575947761536),\n",
       " (11420, 0.46689334511756897),\n",
       " (45204, 0.4668339490890503),\n",
       " (36376, 0.46681562066078186),\n",
       " (73189, 0.4667954742908478),\n",
       " (74939, 0.4667409360408783),\n",
       " (158299, 0.46673399209976196),\n",
       " (168081, 0.4667223393917084),\n",
       " (111871, 0.4666807949542999),\n",
       " (40176, 0.4665205478668213),\n",
       " (161600, 0.46650931239128113),\n",
       " (83724, 0.4664400517940521),\n",
       " (41665, 0.46638187766075134),\n",
       " (19202, 0.46637213230133057),\n",
       " (9778, 0.4663147032260895),\n",
       " (178499, 0.4662165343761444),\n",
       " (89497, 0.4661048650741577),\n",
       " (134692, 0.46591827273368835),\n",
       " (65352, 0.46571505069732666),\n",
       " (39668, 0.4656718969345093),\n",
       " (78963, 0.4656144380569458),\n",
       " (158361, 0.46561095118522644),\n",
       " (154750, 0.4655725359916687),\n",
       " (13389, 0.4654929041862488),\n",
       " (91512, 0.4654683768749237),\n",
       " (83018, 0.4653703570365906),\n",
       " (61839, 0.4650324881076813),\n",
       " (158351, 0.4650302231311798),\n",
       " (37312, 0.4649915099143982),\n",
       " (164588, 0.4649677276611328),\n",
       " (132471, 0.464843213558197),\n",
       " (109659, 0.46475955843925476),\n",
       " (91487, 0.46467891335487366),\n",
       " (61132, 0.4645398259162903),\n",
       " (23257, 0.4644968509674072),\n",
       " (119763, 0.46446627378463745),\n",
       " (154853, 0.46445485949516296),\n",
       " (39354, 0.46438512206077576),\n",
       " (81818, 0.46425583958625793),\n",
       " (40241, 0.4642387330532074),\n",
       " (101250, 0.46418073773384094),\n",
       " (136582, 0.46413829922676086),\n",
       " (78101, 0.4640270471572876),\n",
       " (22850, 0.4639871418476105),\n",
       " (41560, 0.46390300989151),\n",
       " (40331, 0.46374428272247314),\n",
       " (136833, 0.46368369460105896),\n",
       " (158548, 0.463487446308136),\n",
       " (112607, 0.46345531940460205),\n",
       " (55001, 0.46341899037361145),\n",
       " (93248, 0.4634164273738861),\n",
       " (158026, 0.46339407563209534),\n",
       " (158204, 0.463127464056015),\n",
       " (104278, 0.463096559047699),\n",
       " (146289, 0.4629501700401306),\n",
       " (63354, 0.4629036486148834),\n",
       " (55971, 0.46275240182876587),\n",
       " (60177, 0.4626994729042053),\n",
       " (62503, 0.4626675546169281),\n",
       " (20390, 0.46266090869903564),\n",
       " (77168, 0.46264177560806274),\n",
       " (145947, 0.4626372456550598),\n",
       " (170836, 0.462632954120636),\n",
       " (2927, 0.4625864326953888),\n",
       " (102362, 0.4625682532787323),\n",
       " (19824, 0.4625154435634613),\n",
       " (155898, 0.4625088572502136),\n",
       " (28272, 0.46244800090789795),\n",
       " (85716, 0.4624217748641968),\n",
       " (177625, 0.4622907042503357),\n",
       " (45706, 0.4622900187969208),\n",
       " (8637, 0.46228522062301636),\n",
       " (18859, 0.46220913529396057),\n",
       " (59007, 0.462131530046463),\n",
       " (5707, 0.46207907795906067),\n",
       " (57442, 0.46196073293685913),\n",
       " (155489, 0.4619123041629791),\n",
       " (23519, 0.46177244186401367),\n",
       " (13692, 0.4616614878177643),\n",
       " (46849, 0.46164777874946594),\n",
       " (111560, 0.46162423491477966),\n",
       " (4525, 0.46152397990226746),\n",
       " (103525, 0.46147024631500244),\n",
       " (112771, 0.4614485204219818),\n",
       " (8982, 0.4614339768886566),\n",
       " (61170, 0.46141600608825684),\n",
       " (45685, 0.4614000618457794),\n",
       " (43542, 0.4611968696117401),\n",
       " (175345, 0.4608898460865021),\n",
       " (158314, 0.46057868003845215),\n",
       " (62304, 0.46038398146629333),\n",
       " (52750, 0.4603773057460785),\n",
       " (161571, 0.46025028824806213),\n",
       " (99327, 0.46020999550819397),\n",
       " (68347, 0.4601876437664032),\n",
       " (158273, 0.4601271450519562),\n",
       " (112570, 0.45987361669540405),\n",
       " (112828, 0.45985427498817444),\n",
       " (91169, 0.4598495662212372),\n",
       " (46448, 0.45983394980430603),\n",
       " (158513, 0.45969900488853455),\n",
       " (153516, 0.45961374044418335),\n",
       " (158443, 0.4596112072467804),\n",
       " (39685, 0.4595580995082855),\n",
       " (63208, 0.4595026671886444),\n",
       " (64754, 0.45942649245262146),\n",
       " (159620, 0.4593687653541565),\n",
       " (59010, 0.459338515996933),\n",
       " (56525, 0.4592762887477875),\n",
       " (42609, 0.45920926332473755),\n",
       " (109682, 0.45919373631477356),\n",
       " (148230, 0.45918142795562744),\n",
       " (25944, 0.45909813046455383),\n",
       " (9769, 0.4590476453304291),\n",
       " (1956, 0.4590388238430023),\n",
       " (40969, 0.4590316414833069),\n",
       " (65646, 0.45900166034698486),\n",
       " (149010, 0.45893529057502747),\n",
       " (112492, 0.45880797505378723),\n",
       " (63496, 0.4587153494358063),\n",
       " (39376, 0.4586825668811798),\n",
       " (159927, 0.45861953496932983),\n",
       " (57688, 0.4584895968437195),\n",
       " (43585, 0.4584868550300598),\n",
       " (89947, 0.4584423005580902),\n",
       " (131699, 0.4584024250507355),\n",
       " (91218, 0.45837464928627014),\n",
       " (112300, 0.4583606719970703),\n",
       " (143756, 0.45834749937057495),\n",
       " (174075, 0.4583355188369751),\n",
       " (22728, 0.4582464396953583),\n",
       " (145909, 0.4581737518310547),\n",
       " (158017, 0.4580218493938446),\n",
       " (63298, 0.4580077528953552),\n",
       " (72011, 0.45782482624053955),\n",
       " (41941, 0.45781463384628296),\n",
       " (151724, 0.4578052759170532),\n",
       " (90962, 0.4577973484992981),\n",
       " (37245, 0.4577467441558838),\n",
       " (158622, 0.4577086567878723),\n",
       " (145950, 0.45763108134269714),\n",
       " (9782, 0.45753636956214905),\n",
       " (281, 0.45752960443496704),\n",
       " (46924, 0.45740652084350586),\n",
       " (62323, 0.45738235116004944),\n",
       " (122101, 0.4573322534561157),\n",
       " (40602, 0.4573018252849579),\n",
       " (31034, 0.45721930265426636),\n",
       " (9912, 0.45714807510375977),\n",
       " (112532, 0.45706334710121155),\n",
       " (154756, 0.4570532441139221),\n",
       " (91727, 0.4569990634918213),\n",
       " (45668, 0.4569748640060425),\n",
       " (158553, 0.45680466294288635),\n",
       " (114871, 0.45665794610977173),\n",
       " (119811, 0.4566067159175873),\n",
       " (158051, 0.456301212310791),\n",
       " (36071, 0.45627012848854065),\n",
       " (19297, 0.4562576413154602),\n",
       " (115715, 0.45616352558135986),\n",
       " (20137, 0.4561493992805481),\n",
       " (104806, 0.45612964034080505),\n",
       " (63431, 0.45610061287879944),\n",
       " (63455, 0.4560903310775757),\n",
       " (174768, 0.45603448152542114),\n",
       " (12467, 0.4559919536113739),\n",
       " (106638, 0.45592135190963745),\n",
       " (57930, 0.45585840940475464),\n",
       " (116914, 0.45583584904670715),\n",
       " (141279, 0.4557432234287262),\n",
       " (42159, 0.45574280619621277),\n",
       " (89186, 0.4556179642677307),\n",
       " (61731, 0.4556163251399994),\n",
       " (158093, 0.45561206340789795),\n",
       " (73210, 0.4555732011795044),\n",
       " (117944, 0.4555448591709137),\n",
       " (9743, 0.4554823040962219),\n",
       " (15758, 0.45541122555732727),\n",
       " (67826, 0.45532092452049255),\n",
       " (59906, 0.4552939236164093),\n",
       " (60978, 0.45525139570236206),\n",
       " (57459, 0.45521700382232666),\n",
       " (128419, 0.4551577568054199),\n",
       " (158297, 0.45512720942497253),\n",
       " (59127, 0.4550975561141968),\n",
       " (38866, 0.4549233615398407),\n",
       " (42937, 0.45490896701812744),\n",
       " (112543, 0.45488449931144714),\n",
       " (57923, 0.454874187707901),\n",
       " (60735, 0.45479217171669006),\n",
       " (63599, 0.4547123908996582),\n",
       " (118400, 0.4547080397605896),\n",
       " (43930, 0.454683780670166),\n",
       " (104282, 0.4546394348144531),\n",
       " (41157, 0.45463043451309204),\n",
       " (25419, 0.4545069634914398),\n",
       " (108168, 0.4545060992240906),\n",
       " (41565, 0.4544979929924011),\n",
       " (62051, 0.45449769496917725),\n",
       " (167264, 0.4544873833656311),\n",
       " (148407, 0.45444151759147644),\n",
       " (177062, 0.4544326663017273),\n",
       " (40649, 0.454367995262146),\n",
       " (9808, 0.454338401556015),\n",
       " (59260, 0.4543329179286957),\n",
       " (158581, 0.4543043375015259),\n",
       " (59821, 0.454277366399765),\n",
       " (7227, 0.4541809558868408),\n",
       " (51832, 0.4541303813457489),\n",
       " (10931, 0.45406922698020935),\n",
       " (54972, 0.4540468752384186),\n",
       " (3248, 0.45399564504623413),\n",
       " (42014, 0.453980416059494),\n",
       " (63836, 0.45394405722618103),\n",
       " (136424, 0.4539240300655365),\n",
       " (150142, 0.4539070725440979),\n",
       " (150676, 0.4538973271846771),\n",
       " (80458, 0.45386406779289246),\n",
       " (8558, 0.4537845551967621),\n",
       " (170243, 0.45364341139793396),\n",
       " (108701, 0.45360517501831055),\n",
       " (165702, 0.45355379581451416),\n",
       " (44862, 0.45355263352394104),\n",
       " (40845, 0.45350757241249084),\n",
       " (59875, 0.4534520208835602),\n",
       " (172027, 0.4532672166824341),\n",
       " (161211, 0.45325878262519836),\n",
       " (56763, 0.45324307680130005),\n",
       " (3318, 0.4531232714653015),\n",
       " (141307, 0.45305851101875305),\n",
       " (103142, 0.4530382752418518),\n",
       " (42545, 0.45294877886772156),\n",
       " (56134, 0.4529033899307251),\n",
       " (132472, 0.4528987407684326),\n",
       " (71522, 0.452856183052063),\n",
       " (134666, 0.4528420865535736),\n",
       " (155979, 0.4527861773967743),\n",
       " (158176, 0.4527623951435089),\n",
       " (60921, 0.45269039273262024),\n",
       " (8952, 0.4526786208152771),\n",
       " (48241, 0.4526289403438568),\n",
       " (55069, 0.4525773525238037),\n",
       " (153498, 0.4525730311870575),\n",
       " (62627, 0.45253700017929077),\n",
       " (92162, 0.45252472162246704),\n",
       " (164768, 0.4523349106311798),\n",
       " (69455, 0.45231926441192627),\n",
       " (37949, 0.45230787992477417),\n",
       " (1617, 0.4522026777267456),\n",
       " (164355, 0.45209625363349915),\n",
       " (43944, 0.4520595967769623),\n",
       " (158289, 0.45205575227737427),\n",
       " (42975, 0.4520041346549988),\n",
       " (61241, 0.4519558250904083),\n",
       " (37493, 0.45190417766571045),\n",
       " (4533, 0.45188188552856445),\n",
       " (81132, 0.45185574889183044),\n",
       " (58443, 0.4517280161380768),\n",
       " (42400, 0.45160987973213196),\n",
       " (92674, 0.45160338282585144),\n",
       " (64603, 0.45158642530441284),\n",
       " (159000, 0.45156610012054443),\n",
       " (156274, 0.4515407383441925),\n",
       " (106989, 0.45150867104530334),\n",
       " (85501, 0.45144298672676086),\n",
       " (108230, 0.4513416886329651),\n",
       " (158271, 0.45134007930755615),\n",
       " (113634, 0.451264351606369),\n",
       " (158346, 0.4511200785636902),\n",
       " (158020, 0.4510243535041809),\n",
       " (55909, 0.4510166347026825),\n",
       " (39005, 0.4509187638759613),\n",
       " (36834, 0.4508558213710785),\n",
       " (38311, 0.45085474848747253),\n",
       " (118081, 0.45082366466522217),\n",
       " (40368, 0.45076048374176025),\n",
       " (59767, 0.45068779587745667),\n",
       " (112713, 0.4506361484527588),\n",
       " (112087, 0.45058679580688477),\n",
       " (39401, 0.4503939747810364),\n",
       " (109950, 0.45038795471191406),\n",
       " (163941, 0.4503505825996399),\n",
       " (131281, 0.4503325819969177),\n",
       " (40229, 0.45023974776268005),\n",
       " (49737, 0.4502069652080536),\n",
       " (90765, 0.4502064287662506),\n",
       " (89912, 0.45010480284690857),\n",
       " (101104, 0.4500344693660736),\n",
       " (1992, 0.4500276744365692),\n",
       " (45417, 0.4499589204788208),\n",
       " (61127, 0.4499373137950897),\n",
       " (142971, 0.44992879033088684),\n",
       " (107779, 0.44991496205329895),\n",
       " (74372, 0.4498726427555084),\n",
       " (92996, 0.4498177468776703),\n",
       " (97190, 0.44964471459388733),\n",
       " (115577, 0.44961968064308167),\n",
       " (56745, 0.4496135413646698),\n",
       " (106805, 0.4495790898799896),\n",
       " (25385, 0.44957226514816284),\n",
       " (158519, 0.4494469165802002),\n",
       " (62072, 0.4494268298149109),\n",
       " (20462, 0.4493895471096039),\n",
       " (143236, 0.449288934469223),\n",
       " (96750, 0.44919899106025696),\n",
       " (50619, 0.4491982161998749),\n",
       " (162089, 0.4491785764694214),\n",
       " (107092, 0.44915035367012024),\n",
       " (128917, 0.44908836483955383),\n",
       " (147179, 0.4490543305873871),\n",
       " (158272, 0.44901981949806213),\n",
       " (9818, 0.4490152895450592),\n",
       " (66315, 0.4490000903606415),\n",
       " (17955, 0.4489993751049042),\n",
       " (91259, 0.44884762167930603),\n",
       " (162213, 0.44880568981170654),\n",
       " (72140, 0.4487321376800537),\n",
       " (60135, 0.4487287104129791),\n",
       " (103823, 0.4486575126647949),\n",
       " (39361, 0.44865092635154724),\n",
       " (58801, 0.44861552119255066),\n",
       " (102794, 0.44849419593811035),\n",
       " (116408, 0.4484013319015503),\n",
       " (63798, 0.44836094975471497),\n",
       " (152053, 0.44834789633750916),\n",
       " (54749, 0.44827038049697876),\n",
       " (29341, 0.44824931025505066),\n",
       " (108997, 0.4482157826423645),\n",
       " (17839, 0.44818469882011414),\n",
       " (88092, 0.4481789171695709),\n",
       " (121606, 0.44817784428596497),\n",
       " (58391, 0.44813352823257446),\n",
       " (148331, 0.4480753242969513),\n",
       " (114558, 0.447998970746994),\n",
       " (341, 0.447997123003006),\n",
       " (37523, 0.44797462224960327),\n",
       " (41940, 0.44795024394989014),\n",
       " (112514, 0.4478473365306854),\n",
       " (140737, 0.4477660059928894),\n",
       " (112548, 0.44771501421928406),\n",
       " (130973, 0.4476752281188965),\n",
       " (124193, 0.4476652443408966),\n",
       " (158154, 0.4475301206111908),\n",
       " (112504, 0.4474886953830719),\n",
       " (39787, 0.447420597076416),\n",
       " (162564, 0.447420209646225),\n",
       " (63264, 0.447384238243103),\n",
       " (18599, 0.44732391834259033),\n",
       " (161431, 0.44730889797210693),\n",
       " (41668, 0.4472914934158325),\n",
       " (94525, 0.447264164686203),\n",
       " (46646, 0.4472615122795105),\n",
       " (10725, 0.447257936000824),\n",
       " (101405, 0.4472525417804718),\n",
       " (37572, 0.44724544882774353),\n",
       " (29265, 0.44713181257247925),\n",
       " (80494, 0.44708192348480225),\n",
       " (112706, 0.4469338655471802),\n",
       " (174979, 0.44692444801330566),\n",
       " (133346, 0.44691741466522217),\n",
       " (158349, 0.4468632638454437),\n",
       " (164717, 0.4468459486961365),\n",
       " (24610, 0.44683319330215454),\n",
       " (177981, 0.4467177093029022),\n",
       " (112729, 0.4467103183269501),\n",
       " (152450, 0.44663992524147034),\n",
       " (92750, 0.44653448462486267),\n",
       " (57242, 0.4464992582798004),\n",
       " (160160, 0.44649916887283325),\n",
       " (42337, 0.44648221135139465),\n",
       " (3406, 0.4464694559574127),\n",
       " (70595, 0.44641435146331787),\n",
       " (89909, 0.44640132784843445),\n",
       " (37802, 0.4464002847671509),\n",
       " (79716, 0.4463769495487213),\n",
       " (156248, 0.44637131690979004),\n",
       " (65353, 0.4463028013706207),\n",
       " (63646, 0.44628119468688965),\n",
       " (63672, 0.4462096691131592),\n",
       " (102444, 0.44618552923202515),\n",
       " (62376, 0.4461820721626282),\n",
       " (76688, 0.44605711102485657),\n",
       " (37777, 0.4459657073020935),\n",
       " (38573, 0.44595950841903687),\n",
       " (112635, 0.4458562731742859),\n",
       " (153580, 0.44577279686927795),\n",
       " (158514, 0.44567665457725525),\n",
       " (37940, 0.445661336183548),\n",
       " (56390, 0.4456454813480377),\n",
       " (46019, 0.4456371068954468),\n",
       " (129168, 0.44560685753822327),\n",
       " (166928, 0.44559767842292786),\n",
       " (146424, 0.4455762207508087),\n",
       " (61013, 0.44555217027664185),\n",
       " (44091, 0.44554245471954346),\n",
       " (39922, 0.4455093741416931),\n",
       " (116834, 0.44550448656082153),\n",
       " (65321, 0.4454827904701233),\n",
       " (112499, 0.445414662361145),\n",
       " (112666, 0.44539856910705566),\n",
       " (164650, 0.44538894295692444),\n",
       " (85522, 0.4453405439853668),\n",
       " (24670, 0.4453105330467224),\n",
       " (100189, 0.445302277803421),\n",
       " (119604, 0.44527313113212585),\n",
       " (58485, 0.44526156783103943),\n",
       " (75121, 0.44512107968330383),\n",
       " (9826, 0.44511210918426514),\n",
       " (112381, 0.44511091709136963),\n",
       " (56932, 0.4451102912425995),\n",
       " (61480, 0.4450858533382416),\n",
       " (167064, 0.44508305191993713),\n",
       " (112743, 0.4450177848339081),\n",
       " (121599, 0.4449508786201477),\n",
       " (130495, 0.44486597180366516),\n",
       " (45654, 0.4448610544204712),\n",
       " (69954, 0.4447559416294098),\n",
       " (65101, 0.44469398260116577),\n",
       " (74531, 0.4446597993373871),\n",
       " (97597, 0.4446454644203186),\n",
       " (122235, 0.44462791085243225),\n",
       " (101382, 0.4446035325527191),\n",
       " (140717, 0.4443010091781616),\n",
       " (154373, 0.44429200887680054),\n",
       " (61838, 0.44426682591438293),\n",
       " (4530, 0.44422516226768494),\n",
       " (106893, 0.4442007541656494),\n",
       " (157165, 0.44416573643684387),\n",
       " (60103, 0.44414326548576355),\n",
       " (158046, 0.44408494234085083),\n",
       " (90157, 0.44407787919044495),\n",
       " (114225, 0.4440556764602661),\n",
       " (67467, 0.4440353512763977),\n",
       " (113014, 0.4440011978149414),\n",
       " (91490, 0.4439941346645355),\n",
       " (11860, 0.4439938962459564),\n",
       " (99215, 0.4439850151538849),\n",
       " (172967, 0.4439155161380768),\n",
       " (34206, 0.4438876211643219),\n",
       " (64908, 0.4438857138156891),\n",
       " (57312, 0.4438311755657196),\n",
       " (143131, 0.44377246499061584),\n",
       " (11368, 0.4437211751937866),\n",
       " (117778, 0.443707674741745),\n",
       " (41754, 0.4437031149864197),\n",
       " (79403, 0.4436522126197815),\n",
       " (56891, 0.4436297118663788),\n",
       " (56491, 0.4435676634311676),\n",
       " (58915, 0.4435364902019501),\n",
       " (178822, 0.44351381063461304),\n",
       " (158994, 0.4434870481491089),\n",
       " (91811, 0.4434836804866791),\n",
       " (12727, 0.44336679577827454),\n",
       " (122125, 0.4433034062385559),\n",
       " (18922, 0.44325605034828186),\n",
       " (29031, 0.4431946575641632),\n",
       " ...]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2 = ['people', 'race', 'human', 'categorization', 'person', 'color', 'man', 'woman', 'racialized', 'classification', 'people', 'usually', 'political', 'skin', 'color', 'based', 'category', 'specific', 'population', 'mid', 'dark', 'brown', 'complexion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_exp_2 = list(set(exp_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_3 = ['friday', 'song', 'rebecca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_4 = ['unicode', 'medium', 'right', 'pointing', 'triangle', 'centred', 'character']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15534548461437225"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - spatial.distance.cosine(model.infer_vector(black), model.infer_vector(exp_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105686"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Checking the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3839839 , -1.0829922 ,  0.7284176 ,  0.5750398 ,  1.2946204 ,\n",
       "        0.345347  ,  0.29598656,  0.41384223,  0.2510188 ,  0.03540819,\n",
       "        0.05011204, -0.59316385,  0.12808923,  0.6006127 ,  0.18617561,\n",
       "        1.1059247 ,  0.65699714,  0.078219  ,  0.01079204,  0.29751384,\n",
       "        0.54070127,  0.42675695,  0.03375255,  0.42763433, -0.23321885,\n",
       "       -0.09180884, -0.22085252,  0.3998829 ,  0.36516744, -0.50999606,\n",
       "       -0.00400811, -0.2572781 , -1.4095058 ,  0.76877743, -0.09868379,\n",
       "        0.9310032 , -0.22179867,  0.5913735 , -0.04960841,  0.45175368,\n",
       "       -0.54530907,  0.04237929, -0.56336325,  0.13590619,  0.51679635,\n",
       "        0.05895659,  0.03372746,  0.39298773,  0.21641119, -0.02584014],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_similar = []\n",
    "for bow in test_corpus_en:\n",
    "    inferred_vector = model.infer_vector(bow)\n",
    "    most_similar_score = model.dv.most_similar([inferred_vector], topn=1)\n",
    "    most_similar = tagged_corpus_en[most_similar_score[0][0]].words\n",
    "    if bow == most_similar:\n",
    "        n_similar.append(most_similar_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = len(n_similar) / len(test_corpus_en) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_corpus_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_match = model.infer_vector(['aboriginal','indigenous', 'people', 'population', 'group', 'people', 'ethnic', 'group', 'minority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aboriginal', 'heritage', 'act', 'south', 'australian', 'legislation']\n",
      "['bhramar', 'mukherjee', 'indian', 'american', 'biostatistician', 'data', 'scientist']\n",
      "['bombay', 'rava']\n",
      "['gokana', 'kana', 'nigeria', 'ethnic', 'group']\n",
      "['kalinda', 'griffith', 'kalinda', 'griffith', 'kalinda', 'e', 'griffith', 'australian', 'indigenous', 'health', 'researcher']\n",
      "['french', 'people', 'madagascar', 'ethnic', 'group']\n",
      "['binza', 'watercourse', 'kasai', 'oriental', 'democratic', 'republic', 'congo']\n",
      "['instance', 'macromolecular', 'complex', 'homo', 'sapiens', 'reactome', 'id', 'r', 'hsa']\n",
      "['nkum', 'nigeria', 'ethnic', 'group']\n",
      "['negro', 'romance', 'comic', 'book', 'series', 'comic', 'book']\n"
     ]
    }
   ],
   "source": [
    "for top in model.dv.most_similar([related_match], topn=10):\n",
    "    print(tagged_corpus_en[top[0]].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
