{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising 1D array\n",
    "#preprocessing.normalize([scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New RM bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing related matches\n",
    "with open(\"/Users/anesterov/reps/LODlit/bg/rm_bows_all.json\",\"r\") as jf:\n",
    "    rm = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing WM text EN\n",
    "with open(\"/Users/anesterov/reps/LODlit/en_wm_bows.json\",\"r\") as jf:\n",
    "    en_wm_bows = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing WM text NL\n",
    "with open(\"/Users/anesterov/reps/LODlit/nl_wm_bows.json\",\"r\") as jf:\n",
    "    nl_wm_bows = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open(\"/Users/anesterov/reps/LODlit/query_terms.json\") as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(doc:list, token:str) -> float:\n",
    "    '''\n",
    "    Calculates term frequency\n",
    "    doc: list, alll documents\n",
    "    token: str, a token to get the TF score of\n",
    "    Returns float\n",
    "    '''\n",
    "    n_found = len([t for t in doc if t == token])\n",
    "    tf_score = n_found / len(doc)\n",
    "    \n",
    "    return tf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(token:str, doc_freq:dict, n_docs:int) -> float:\n",
    "    '''\n",
    "    Calculates inverse document frequency:\n",
    "        adds 1 to DF to avoid zero division\n",
    "    token: str, a token to get the IDF score of\n",
    "    doc_freq: dict, document frequency, in how many documents tokens appear\n",
    "    n_docs: int, a number of documents\n",
    "    Returns float\n",
    "    '''\n",
    "    idf_score = math.log(n_docs / (doc_freq[token] + 1))\n",
    "        \n",
    "    return idf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tokens_tfidf(bow:list,doc_freq:dict,n_docs:int) -> list:\n",
    "    '''\n",
    "    Getting top tokens based on their TF-IDF weighting in one BoW\n",
    "    Depends on the tf and idf functions\n",
    "    bow: list of str, tokens in one BoW\n",
    "    doc_freq: dict, document frequency, in how many documents tokens appear\n",
    "    n_docs: int, a number of documents\n",
    "    Returns list: Top 10 tokens in a bow by their TF-IDF scores\n",
    "    '''\n",
    "    top_tokens = []\n",
    "    tf_idf_scores = {}\n",
    "    \n",
    "    for token in bow:\n",
    "        tf_idf = tf(bow,token) * idf(token,doc_freq,n_docs)\n",
    "        tf_idf_scores[token] = tf_idf\n",
    "        \n",
    "    tokens_scores = sorted(tf_idf_scores.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    if len(tokens_scores) < 10:\n",
    "        top_tokens = [t[0] for t in tokens_scores]\n",
    "    else:\n",
    "        #cut_off_score = tokens_scores[9][1] # taking top 10 scores\n",
    "        #top_tokens = [t[0] for t in tokens_scores if t[1] >= cut_off_score]\n",
    "        #if len(top_tokens) > 10:\n",
    "        top_tokens = [t[0] for t in tokens_scores[0:10]]\n",
    "    \n",
    "    return top_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens_and_docs(source:dict) -> tuple:\n",
    "    '''\n",
    "    Gets unique tokens and documents in a file\n",
    "    source: dict\n",
    "    Prints N of unique tokens\n",
    "    Returns a tuple, where 0: list of tokens (str), 1: list of documents (list)\n",
    "    '''\n",
    "    all_docs = []\n",
    "    all_tokens = []\n",
    "    \n",
    "    for value in source.values():\n",
    "        # taking only unique bows\n",
    "        for bow in value[\"bow\"]:\n",
    "            if bow not in all_docs:\n",
    "                all_docs.append(bow)\n",
    "                # collecting all unique tokens\n",
    "                for token in bow:\n",
    "                    if token not in all_tokens:\n",
    "                        all_tokens.append(token)\n",
    "    \n",
    "    print(f\"Unique tokens: {len(all_tokens)}\")\n",
    "    \n",
    "    tokens_docs = (all_tokens, all_docs) \n",
    "    \n",
    "    return tokens_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: 1166\n"
     ]
    }
   ],
   "source": [
    "# list of unique tokens and number of documents in WM EN\n",
    "tokens_docs_en = get_unique_tokens_and_docs(en_wm_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_en = tokens_docs_en[0]\n",
    "all_docs_en = tokens_docs_en[1]\n",
    "n_docs_en = len(all_docs_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dict with document frequency (DF) scores for every unique token\n",
    "en_df = {}\n",
    "for token in all_tokens_en:\n",
    "    token_count = 0\n",
    "    for bow in all_docs_en:\n",
    "        if token in bow:\n",
    "            token_count += 1\n",
    "    en_df[token] = token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding two new bows to the file 'en_wm_bows':\n",
    "# (1) top tokens based on TF-IDF; (2) joint bow with the 1 + suggestions\n",
    "\n",
    "for value in en_wm_bows.values():\n",
    "    \n",
    "    # there can be muttiple bows for one term\n",
    "    top_tokens = [] \n",
    "    \n",
    "    for bow in value[\"bow\"]:\n",
    "        top_tokens.extend(get_top_tokens_tfidf(bow,en_df,n_docs_en))\n",
    "        \n",
    "    value[\"bow_tf_idf\"] = top_tokens\n",
    "    \n",
    "    # metging top tokens and suggestions\n",
    "    joint_bow = []\n",
    "    joint_bow.extend(top_tokens)\n",
    "    joint_bow.extend(value[\"suggestions\"])\n",
    "    \n",
    "    value[\"bow_joint\"] = joint_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting\n",
    "with open('en_wm_bows_tf_idf.json', 'w') as jf:\n",
    "    json.dump(en_wm_bows, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: 1182\n"
     ]
    }
   ],
   "source": [
    "# list of unique tokens and number of documents in WM NL\n",
    "tokens_docs_nl = get_unique_tokens_and_docs(nl_wm_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_nl = tokens_docs_nl[0]\n",
    "all_docs_nl = tokens_docs_nl[1]\n",
    "n_docs_nl = len(all_docs_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dict with document frequency (DF) scores for every unique token\n",
    "nl_df = {}\n",
    "for token in all_tokens_nl:\n",
    "    token_count = 0\n",
    "    for bow in all_docs_nl:\n",
    "        if token in bow:\n",
    "            token_count += 1\n",
    "    nl_df[token] = token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding two new bows to the file 'nl_wm_bows':\n",
    "# (1) top tokens based on TF-IDF; (2) joint bow with the 1 + suggestions\n",
    "\n",
    "for value in nl_wm_bows.values():\n",
    "    \n",
    "    # there can be muttiple bows for one term\n",
    "    top_tokens = [] \n",
    "    \n",
    "    for bow in value[\"bow\"]:\n",
    "        top_tokens.extend(get_top_tokens_tfidf(bow,nl_df,n_docs_nl))\n",
    "        \n",
    "    value[\"bow_tf_idf\"] = top_tokens\n",
    "    \n",
    "    # metging top tokens and suggestions\n",
    "    joint_bow = []\n",
    "    joint_bow.extend(top_tokens)\n",
    "    joint_bow.extend(value[\"suggestions\"])\n",
    "    \n",
    "    value[\"bow_joint\"] = joint_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting\n",
    "with open('nl_wm_bows_tf_idf.json', 'w') as jf:\n",
    "    json.dump(nl_wm_bows, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
