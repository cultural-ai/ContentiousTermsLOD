{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting terms to be queried in the resources\n",
    "This notebook generates the following files:\n",
    "- (1) query_terms.json -- contains all query terms by lang\n",
    "- (2) en_lemmas_with_label_uris.json -- lemmas of EN query terms connected to the corresponding label URIs in the Words Matter knowledge graph\n",
    "- (3) nl_lemmas_with_label_uris.json -- lemmas of NL query terms connected to the corresponding label URIs in the Words Matter knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to query terms from Cultural AI GitHub\n",
    "# EN\n",
    "url_en = \"https://github.com/cultural-ai/wordsmatter/raw/main/query_terms_cont_en.json\"\n",
    "# NL\n",
    "url_nl = \"https://github.com/cultural-ai/wordsmatter/raw/main/query_terms_cont_nl.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getting_en = requests.get(url_en)\n",
    "wordforms_en = json.loads(getting_en.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getting_nl = requests.get(url_nl)\n",
    "wordforms_nl = json.loads(getting_nl.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging query terms together in one dict\n",
    "# {'en':{'lemma':[all wordforms inclusing lemma]}}\n",
    "\n",
    "query_terms = {}\n",
    "query_terms['en'] = wordforms_en\n",
    "query_terms['nl'] = wordforms_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for values in query_terms.values():\n",
    "    for lemma, wordforms in values.items():\n",
    "        wordforms.append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all query terms\n",
    "with open('query_terms.json', 'w') as jf:\n",
    "    json.dump(query_terms, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats\n",
    "en_total = 0\n",
    "en_lemmas = 0\n",
    "nl_total = 0\n",
    "nl_lemmas = 0\n",
    "\n",
    "for lemma, wordforms in query_terms['en'].items():\n",
    "    en_lemmas += 1\n",
    "    en_total += len(wordforms)\n",
    "    \n",
    "for lemma, wordforms in query_terms['nl'].items():\n",
    "    nl_lemmas += 1\n",
    "    nl_total += len(wordforms)\n",
    "    \n",
    "print(\"EN:\",en_lemmas,en_total)\n",
    "print(\"NL:\",nl_lemmas,nl_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting query terms (lemmas) to the corresponding contentious labels URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open(\"/Users/anesterov/reps/LODlit/query_terms.json\",\"r\") as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing contentious issues with contentious labels\n",
    "CI_url = \"https://raw.githubusercontent.com/cultural-ai/wordsmatter/main/CI_with_cont_terms.json\"\n",
    "requesting_CI_url = requests.get(CI_url)\n",
    "CI = json.loads(requesting_CI_url.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "en_uri_labels = {}\n",
    "for value in CI.values():\n",
    "    for label_uri, lit in value[\"contentious_labels\"].items():\n",
    "        if lit['lang'] == 'en':\n",
    "            en_uri_labels[label_uri] = lit['literal_form'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(en_uri_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "nl_uri_labels = {}\n",
    "for value in CI.values():\n",
    "    for label_uri, lit in value[\"contentious_labels\"].items():\n",
    "        if lit['lang'] == 'nl':\n",
    "            nl_uri_labels[label_uri] = lit['literal_form'].lower().replace('\\xad','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL labels l_238 ('Jappenkamp') and l_236 ('Jappenkampen') have the same lemma 'jappenkamp';\n",
    "# so there are 83 NL label URIs but 82 NL lemmas\n",
    "len(nl_uri_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "# checking wordforms bc in some cases, literal form of contentious terms is not the same as its lemma\n",
    "en_lemmas_of_label_uris = {}\n",
    "for lemma, wordforms in query_terms['en'].items():\n",
    "    uri_list = [] # one lemma can have one or more label uris\n",
    "    for l_uri, cont_label in en_uri_labels.items():  \n",
    "        if cont_label in wordforms:\n",
    "            uri_list.append(l_uri)\n",
    "            en_lemmas_of_label_uris[lemma] = uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN: exporting lemmas with label URIs\n",
    "with open('en_lemmas_with_label_uris.json', 'w') as jf:\n",
    "    json.dump(en_lemmas_of_label_uris, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "nl_lemmas_of_label_uris = {}\n",
    "for lemma, wordforms in query_terms['nl'].items():\n",
    "    uri_list = []\n",
    "    for l_uri, cont_label in nl_uri_labels.items():  \n",
    "        if cont_label in wordforms:\n",
    "            uri_list.append(l_uri)\n",
    "            nl_lemmas_of_label_uris[lemma] = uri_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL: exporting lemmas with label URIs\n",
    "with open('nl_lemmas_with_label_uris.json', 'w') as jf:\n",
    "    json.dump(nl_lemmas_of_label_uris, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
