{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook generates annotation sheets for Top-10 in Wikidata (EN), Wikidata (NL), AAT (EN), AAT (NL), PWN, and ODWN\n",
    "\n",
    "* annotation_sheet_wikidata_en.csv\n",
    "* annotation_sheet_wikidata_nl.csv\n",
    "* annotation_sheet_aat_en.csv\n",
    "* annotation_sheet_aat_nl.cs\n",
    "* annotation_sheet_pwn_en.csv\n",
    "* annotation_sheet_odwn_nl.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annotation_sheet(resource:str, lang:str, filename:str, score_type=None):\n",
    "    '''\n",
    "    score_type: str, 'cs_rm', 'cs_wm', 'cs_rm_wm' or None, default None\n",
    "    filename: str, corresponding csv file (top-10 or additional entities) in the 'cs' directory,\n",
    "    without '.csv' extention, for example 'top_10_rm_wikidata_en'\n",
    "    Returns pandas df\n",
    "    '''\n",
    "    \n",
    "    if resource == \"wikidata\":\n",
    "        annotation_sheet_df = pd.DataFrame(columns=[\"term\",\"entity_id\",\"text_1\",\"text_2\",\"text_3\",\"text_4\",\"text_5\"])\n",
    "        \n",
    "        # import search results\n",
    "        with open(f\"/Users/anesterov/wd/jan31/results_clean_{lang}.json\",'r') as jf:\n",
    "            search_results = json.load(jf)\n",
    "        # import top-10\n",
    "        top_10 = pd.read_csv(f\"/Users/anesterov/reps/LODlit/cs/{filename}.csv\")\n",
    "\n",
    "        for group in top_10.groupby(\"term\"):\n",
    "            # if there is a score in the df\n",
    "            # check if the highest cs score != 0\n",
    "            if score_type == None or list(group[1][score_type])[0] > 0:\n",
    "                for hit_id in list(group[1][\"hit_id\"]):\n",
    "                    for hit in search_results[group[0]]:\n",
    "                        if hit[\"QID\"] == hit_id:\n",
    "                            data = [group[0],hit_id,hit[\"prefLabel\"],hit[\"aliases\"],hit[\"description\"],hit[\"instance_of\"],\\\n",
    "                                   hit[\"subclass_of\"]]\n",
    "                            annotation_sheet_df.loc[len(annotation_sheet_df)] = data\n",
    "                        \n",
    "    if resource == \"aat\":\n",
    "        annotation_sheet_df = pd.DataFrame(columns=[\"term\",\"entity_id\",\"text_1\",\"text_2\",\"text_3\",\"text_4\",\"text_5\"])\n",
    "\n",
    "        # import search results\n",
    "        with open(f\"/Users/anesterov/reps/LODlit/AAT/aat_query_results_{lang}.json\",'r') as jf:\n",
    "            search_results = json.load(jf)\n",
    "        # import top-10\n",
    "        top_10 = pd.read_csv(f\"/Users/anesterov/reps/LODlit/cs/{filename}.csv\")\n",
    "        \n",
    "        for group in top_10.groupby(\"term\"):\n",
    "            # if there is a score in the df\n",
    "            # check if the highest cs score != 0\n",
    "            if score_type == None or list(group[1][score_type])[0] > 0:\n",
    "                ids_per_term = [str(i).replace('.0','') for i in list(group[1][\"hit_id\"])]\n",
    "                for hit_id in ids_per_term:\n",
    "                    for hit in search_results[group[0]]:\n",
    "                        if hit[\"aat_uri\"] == hit_id:\n",
    "                            data = [group[0],hit_id,hit[\"prefLabel\"],hit[\"altLabel\"],\\\n",
    "                                    hit[\"scopeNote\"],hit[\"prefLabel_comment\"],hit[\"altLabel_comment\"]]\n",
    "                            annotation_sheet_df.loc[len(annotation_sheet_df)] = data\n",
    "                        \n",
    "    if resource == \"pwn\":\n",
    "        annotation_sheet_df = pd.DataFrame(columns=[\"term\",\"entity_id\",\"text_1\",\"text_2\",\"text_3\"])\n",
    "\n",
    "        # import search results\n",
    "        with open(\"/Users/anesterov/reps/LODlit/PWN/pwn31_query_results.json\",'r') as jf:\n",
    "            search_results = json.load(jf)\n",
    "        # import top-10\n",
    "        top_10 = pd.read_csv(f\"/Users/anesterov/reps/LODlit/cs/{filename}.csv\")\n",
    "        \n",
    "        for group in top_10.groupby(\"term\"):\n",
    "            # if there is a score in the df\n",
    "            # check if the highest cs score != 0\n",
    "            if score_type == None or list(group[1][score_type])[0] > 0:\n",
    "                for hit_id in list(group[1][\"hit_id\"]):\n",
    "                    for hit in search_results[group[0]]:\n",
    "                        if hit[\"synset_id\"] == hit_id:\n",
    "                            data = [group[0],hit_id,hit[\"lemmata\"],hit[\"definition\"],hit[\"examples\"]]\n",
    "                            annotation_sheet_df.loc[len(annotation_sheet_df)] = data\n",
    "    \n",
    "    if resource == \"odwn\":\n",
    "        annotation_sheet_df = pd.DataFrame(columns=[\"term\",\"entity_id\",\"text_1\",\"text_2\",\"text_3\",\"text_4\",\"text_5\"])\n",
    "        # import search results\n",
    "        with open(\"/Users/anesterov/reps/LODlit/ODWN/odwn_query_results.json\",'r') as jf:\n",
    "            search_results = json.load(jf)\n",
    "        # import top-10\n",
    "        top_10 = pd.read_csv(f\"/Users/anesterov/reps/LODlit/cs/{filename}.csv\")\n",
    "        \n",
    "        for group in top_10.groupby(\"term\"):\n",
    "            # if there is a score in the df\n",
    "            # check if the highest cs score != 0\n",
    "            if score_type == None or list(group[1][score_type])[0] > 0:\n",
    "                for hit_id in list(group[1][\"hit_id\"]):\n",
    "                    for hit in search_results[group[0]]:\n",
    "                        if hit[\"synset_id\"] != \"\":\n",
    "                            if hit[\"synset_id\"] == hit_id:\n",
    "                                data = [group[0],hit_id,hit.get(\"le_written_form\"),hit.get(\"sense_definition\"),\\\n",
    "                                   hit.get(\"sense_examples\"),hit.get(\"synonyms\"),hit.get(\"synset_definitions\")]\n",
    "                                annotation_sheet_df.loc[len(annotation_sheet_df)] = data\n",
    "                        else:\n",
    "                            if hit[\"le_id\"] == hit_id:\n",
    "                                data = [group[0],hit_id,hit.get(\"le_written_form\"),hit.get(\"sense_definition\"),\\\n",
    "                                   hit.get(\"sense_examples\"),hit.get(\"synonyms\"),hit.get(\"synset_definitions\")]\n",
    "                                annotation_sheet_df.loc[len(annotation_sheet_df)] = data\n",
    "\n",
    "                        \n",
    "                        \n",
    "    annotation_sheet_df.drop_duplicates(subset=[\"term\",\"entity_id\"], inplace=True)\n",
    "                        \n",
    "    return annotation_sheet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"pwn\",\"en\",\"top_10_rm_pwn\",score_type=\"cs_rm\").to_csv(\"annotation_sheet_pwn_en.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating additional anntation sheets\n",
    "* difference between Top-10 based on RM and Top-10 based on WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"wikidata\",\"en\",\"wm_additional_wd_en\").to_csv(\"additional_annotation_wd_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"wikidata\",\"nl\",\"wm_additional_wd_nl\").to_csv(\"additional_annotation_wd_nl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"aat\",\"en\",\"wm_additional_aat_en\").to_csv(\"additional_annotation_aat_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"aat\",\"nl\",\"wm_additional_aat_nl\").to_csv(\"additional_annotation_aat_nl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"pwn\",\"en\",\"wm_additional_pwn\").to_csv(\"additional_annotation_pwn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation_sheet(\"odwn\",\"nl\",\"wm_additional_odwn\").to_csv(\"additional_annotation_odwn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
