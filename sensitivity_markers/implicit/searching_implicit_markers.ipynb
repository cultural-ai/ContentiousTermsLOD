{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_term(query_term:str, lang:str) -> str:\n",
    "    '''\n",
    "    Getting a lemma of a query term\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns str, 'not found' if lemma was not found\n",
    "    '''\n",
    "    \n",
    "    return_lemma = 'not found'\n",
    "    \n",
    "    # importing query terms with lemmas\n",
    "    # change path to GitHub\n",
    "    \n",
    "    with open('/Users/anesterov/reps/LODlit/query_terms.json','r') as jf:\n",
    "        query_terms = json.load(jf)\n",
    "        \n",
    "    for lemma, qt in query_terms[lang].items():\n",
    "        if query_term in qt:\n",
    "            return_lemma = lemma\n",
    "            \n",
    "    return return_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_implicit_markers_wd(lang:str):\n",
    "    '''\n",
    "    lang: str, \"en\" or \"nl\"\n",
    "    Returns pandas DataFrame\n",
    "    '''\n",
    "    \n",
    "    wd_implicit = pd.DataFrame(columns=[\"resource\",lang,\"lemma\",\"entity_id\",\"property\",\"value\",\"implicit_marker\",\"level\"])\n",
    "    \n",
    "    # importing implicit markers dict\n",
    "    with open('/Users/anesterov/reps/LODlit/sensitivity_markers/implicit/implicit_markers.json','r') as jf:\n",
    "        implicit_markers = json.load(jf)\n",
    "    \n",
    "    # importing all search results\n",
    "    with open(f\"/Users/anesterov/LODlit_local/wd/jan31/results_clean_{lang}.json\",'r') as jf:\n",
    "        wd_all = json.load(jf)\n",
    "        \n",
    "    # import subset\n",
    "    with open(f\"/Users/anesterov/reps/LODlit/Wikidata/wd_{lang}_subset.json\",'r') as jf:\n",
    "        wd_subset = json.load(jf)\n",
    "        \n",
    "    # get all QIDs in the subset\n",
    "    subset_quids = []\n",
    "    for hits in wd_subset.values():\n",
    "        for hit in hits:\n",
    "            subset_quids.append(hit[\"QID\"])\n",
    "            \n",
    "    # import rm\n",
    "    wd_rm = pd.read_csv(\"/Users/anesterov/reps/LODlit/rm/rm_entities_unique.csv\")\n",
    "    rm_quids = list(wd_rm[wd_rm[\"resource\"] == \"wikidata\"][wd_rm[\"lang\"] == lang][\"entity_id\"])\n",
    "    \n",
    "    # searching in descriptions\n",
    "    for term, hits in wd_all.items():\n",
    "        lemma = get_lemma_by_term(term, lang)\n",
    "        \n",
    "        for hit in hits:\n",
    "\n",
    "            level = \"1\"\n",
    "            # check entity level\n",
    "            if hit[\"QID\"] in set(subset_quids):\n",
    "                level = \"2\"\n",
    "            if hit[\"QID\"] in set(rm_quids):\n",
    "                level = \"3\"\n",
    "\n",
    "            # check descriptions type\n",
    "            if type(hit[\"description\"]) == list:\n",
    "                for d in hit[\"description\"]:\n",
    "                    # iterating over all markers\n",
    "                    for marker in implicit_markers[\"wikidata\"][lang]:\n",
    "                        match = re.search(f\"\\\\b{marker}\\\\b\",d)\n",
    "                        if match:\n",
    "                            row = [\"wikidata\",lang,lemma,hit[\"QID\"],\"description\",d,match[0],level]\n",
    "                            wd_implicit.loc[len(wd_implicit)] = row\n",
    "\n",
    "            if type(hit[\"description\"]) == str:\n",
    "                for marker in implicit_markers[\"wikidata\"][lang]:\n",
    "                    match = re.search(f\"\\\\b{marker}\\\\b\",hit[\"description\"])\n",
    "                    if match:\n",
    "                        row = [\"wikidata\",lang,lemma,hit[\"QID\"],\"description\",hit[\"description\"],match[0],level]\n",
    "                        wd_implicit.loc[len(wd_implicit)] = row\n",
    "                        \n",
    "    return wd_implicit.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-93c9a52dc902>:29: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rm_quids = list(wd_rm[wd_rm[\"resource\"]==\"wikidata\"][wd_rm[\"lang\"]==lang][\"entity_id\"])\n"
     ]
    }
   ],
   "source": [
    "wd_nl_implicit = search_implicit_markers_wd(\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv\n",
    "wd_nl_implicit.to_csv(\"wd_nl_implicit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
