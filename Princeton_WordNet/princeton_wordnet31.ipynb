{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "# the directory 'wordnet' actually contains wordnet31\n",
    "# the script to get definition and examples was edited (see 'wordnet.py')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('query_terms_cont_en.json','r') as jf:\n",
    "    query_terms_cont_en = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# there are 75 English query terms\n",
    "len(query_terms_cont_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_results_en = {}\n",
    "\n",
    "for lemma, forms in query_terms_cont_en.items():\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    list_of_query_terms = [] # searching for lemmas and forms of query terms\n",
    "    list_of_query_terms.append(lemma)\n",
    "    list_of_query_terms.extend(forms)\n",
    "    \n",
    "    for query_term in list_of_query_terms:\n",
    "\n",
    "        # searching in lemmata\n",
    "        # getting synset_id, lemmata (synonyms), definition, examples\n",
    "\n",
    "        for synset in wn.synsets(query_term):\n",
    "            for le in synset.lemmas():\n",
    "                # exact match between query term and lemma name\n",
    "                if query_term == le.name().lower(): # lemmas can be capitalized\n",
    "                    result_dict = {}\n",
    "                    result_dict['query_term'] = query_term\n",
    "                    result_dict['synset_id'] = synset.name()\n",
    "                    result_dict['lemmata'] = [l.name() for l in synset.lemmas()]\n",
    "                    result_dict['definition'] = synset.definition()\n",
    "                    result_dict['examples'] = synset.examples()\n",
    "                    result_dict['found_in'] = 'lemmata'\n",
    "                    results.append(result_dict)\n",
    "\n",
    "    # searching in all definitions\n",
    "    \n",
    "        for synset in list(wn.all_synsets()):\n",
    "            if len(re.findall(f'\\\\b{query_term}\\\\b',synset.definition(),re.IGNORECASE)) > 0:\n",
    "                result_dict = {}\n",
    "                result_dict['query_term'] = query_term\n",
    "                result_dict['synset_id'] = synset.name()\n",
    "                result_dict['lemmata'] = [l.name() for l in synset.lemmas()]\n",
    "                result_dict['definition'] = synset.definition()\n",
    "                result_dict['examples'] = synset.examples()\n",
    "                result_dict['found_in'] = 'definition'\n",
    "                results.append(result_dict)\n",
    "\n",
    "            # searching in all examples\n",
    "            for example in synset.examples():\n",
    "                if len(re.findall(f'\\\\b{query_term}\\\\b',example,re.IGNORECASE)) > 0:\n",
    "                    result_dict = {}\n",
    "                    result_dict['query_term'] = query_term\n",
    "                    result_dict['synset_id'] = synset.name()\n",
    "                    result_dict['lemmata'] = [l.name() for l in synset.lemmas()]\n",
    "                    result_dict['definition'] = synset.definition()\n",
    "                    result_dict['examples'] = synset.examples()\n",
    "                    result_dict['found_in'] = 'examples'\n",
    "                    results.append(result_dict)\n",
    "\n",
    "    wn_results_en[lemma] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the query results\n",
    "\n",
    "with open('Princeton_WordNet/princeton_wordnet31_query_results.json', 'w') as jf:\n",
    "    json.dump(wn_results_en, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count by query term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Princeton_WordNet/princeton_wordnet31_count_by_query_term.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','query_term','synsets','definitions','examples','total_per_query_term']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for key, forms in query_terms_cont_en.items():\n",
    "\n",
    "        list_of_query_terms = [] # lemmas and forms of query terms\n",
    "        list_of_query_terms.append(key)\n",
    "        list_of_query_terms.extend(forms)\n",
    "\n",
    "        for query_term in list_of_query_terms:\n",
    "\n",
    "            lemmata_count = 0\n",
    "            definition_count = 0\n",
    "            examples_count = 0\n",
    "\n",
    "            for lemma, results in wn_results_en.items():\n",
    "                for result in results:\n",
    "                    if result['query_term'] == query_term:\n",
    "                        if result['found_in'] == 'lemmata':\n",
    "                            lemmata_count += 1\n",
    "                        if result['found_in'] == 'definition':\n",
    "                            definition_count += 1\n",
    "                        if result['found_in'] == 'examples':\n",
    "                            examples_count += 1\n",
    "            total_count = lemmata_count + definition_count + examples_count\n",
    "\n",
    "            writer.writerow([key,query_term,lemmata_count,definition_count,examples_count,total_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count by lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Princeton_WordNet/princeton_wordnet31_count_by_lemma.csv','w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    header = ['lemma','synsets','definitions','examples','total_per_lemma']\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for lemma, results in wn_results_en.items():\n",
    "        lemmata_count = 0\n",
    "        definition_count = 0\n",
    "        examples_count = 0\n",
    "        total_count = 0\n",
    "        for result in results:\n",
    "            if result['found_in'] == 'lemmata':\n",
    "                lemmata_count += 1\n",
    "            if result['found_in'] == 'definition':\n",
    "                definition_count += 1\n",
    "            if result['found_in'] == 'examples':\n",
    "                examples_count += 1\n",
    "        total_count = len(results)\n",
    "        \n",
    "        writer.writerow([lemma,lemmata_count,definition_count,examples_count,total_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
