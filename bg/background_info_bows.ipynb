{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from LODlit import bows, aat, wd, pwn31, odwn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting BoWs with background info for every term\n",
    "The backgound info consists of:\n",
    "* Literals of related matches (resources from the knowledge graph)\n",
    "* Words Matter text\n",
    "\n",
    "This notebook generates the following files:\n",
    "- file names: {rm} = \"related matches\", {bows} = \"bags of words\", {dataset}, {language suffix})\n",
    "- (1) rm_bows_wikidata_en.json\n",
    "- (2) rm_bows_wikidata_nl.json\n",
    "- (3) rm_bows_aat_en.json\n",
    "- (4) rm_bows_aat_nl.json\n",
    "- (5) rm_bows_pwn.json -- (PWN results are only in EN)\n",
    "- (6) rm_bows_odwn.json -- (ODWN results are only in NL)\n",
    "- (7) background_info_bows.json -- a joint file with all bows per query term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Getting literals of related matches\n",
    "(Wikidata, AAT, PWN, ODWN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "rm_wikidata_en = wd.get_lit_related_matches_bow(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_wikidata_en.json', 'w') as jf:\n",
    "    json.dump(rm_wikidata_en, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "rm_wikidata_nl = wd.get_lit_related_matches_bow(\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_wikidata_nl.json', 'w') as jf:\n",
    "    json.dump(rm_wikidata_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN\n",
    "rm_aat_en = aat.get_lit_related_matches_bow(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_aat_en.json', 'w') as jf:\n",
    "    json.dump(rm_aat_en, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL\n",
    "rm_aat_nl = aat.get_lit_related_matches_bow(\"nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_aat_nl.json', 'w') as jf:\n",
    "    json.dump(rm_aat_nl, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_pwn = pwn31.get_lit_related_matches_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_pwn.json', 'w') as jf:\n",
    "    json.dump(rm_pwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_odwn = odwn.get_lit_related_matches_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('rm_bows_odwn.json', 'w') as jf:\n",
    "    json.dump(rm_odwn, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a common file with all related matches and Words Matter BoWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all files\n",
    "with open('rm_bows_wikidata_en.json','r') as jf:\n",
    "    rm_wikidata_en = json.load(jf)\n",
    "with open('rm_bows_wikidata_nl.json','r') as jf:\n",
    "    rm_wikidata_nl = json.load(jf)\n",
    "    \n",
    "with open('rm_bows_aat_en.json','r') as jf:\n",
    "    rm_aat_en = json.load(jf)\n",
    "with open('rm_bows_aat_nl.json','r') as jf:\n",
    "    rm_aat_nl = json.load(jf)\n",
    "    \n",
    "with open('rm_bows_pwn.json','r') as jf:\n",
    "    rm_pwn = json.load(jf)\n",
    "with open('rm_bows_odwn.json','r') as jf:\n",
    "    rm_odwn = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WM terms\n",
    "with open('en_wm_bows_tf_idf.json','r') as jf:\n",
    "    en_wm_bows = json.load(jf)\n",
    "    \n",
    "with open('nl_wm_bows_tf_idf.json','r') as jf:\n",
    "    nl_wm_bows = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing query terms\n",
    "with open('/LODlit/query_terms.json','r') as jf:\n",
    "    query_terms = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of terms EN\n",
    "\n",
    "query_terms_en = []\n",
    "for l in list(query_terms[\"en\"].values()):\n",
    "    query_terms_en.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of terms NL\n",
    "\n",
    "query_terms_nl = []\n",
    "for l in list(query_terms[\"nl\"].values()):\n",
    "    query_terms_nl.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaping a common file with backgroung info\n",
    "# {lang:{term:{\"wikidata\":[], \"aat\":[], \"pwn\":[], \"wm\":[]}}\n",
    "\n",
    "all_rm = {}\n",
    "all_rm[\"en\"] = {}\n",
    "all_rm[\"nl\"] = {}\n",
    "\n",
    "for term in query_terms_en:\n",
    "    \n",
    "    dict_per_term = {}\n",
    "    dict_per_term[term] = {}\n",
    "    \n",
    "    # Wikidata\n",
    "    if rm_wikidata_en.get(term) != None:\n",
    "        dict_per_term[term][\"wikidata\"] = rm_wikidata_en[term][\"bow\"]\n",
    "    \n",
    "    # AAT\n",
    "    if rm_aat_en.get(term) != None:\n",
    "        dict_per_term[term][\"aat\"] = rm_aat_en[term][\"bow\"]\n",
    "        \n",
    "    # PWN\n",
    "    if rm_pwn.get(term) != None:\n",
    "        dict_per_term[term][\"pwn\"] = rm_pwn[term]\n",
    "        \n",
    "    # WM bows    \n",
    "    for lemma, wordforms in query_terms[\"en\"].items():\n",
    "        if term in wordforms:\n",
    "            dict_per_term[term][\"wm\"] = en_wm_bows[lemma][\"bow_tf_idf\"]\n",
    "    \n",
    "    all_rm[\"en\"].update(dict_per_term)\n",
    "    \n",
    "for term in query_terms_nl:\n",
    "    \n",
    "    dict_per_term = {}\n",
    "    dict_per_term[term] = {}\n",
    "    \n",
    "    # Wikidata\n",
    "    if rm_wikidata_nl.get(term) != None:\n",
    "        dict_per_term[term][\"wikidata\"] = rm_wikidata_nl[term][\"bow\"]\n",
    "    \n",
    "    # AAT\n",
    "    if rm_aat_nl.get(term) != None:\n",
    "        dict_per_term[term][\"aat\"] = rm_aat_nl[term][\"bow\"]\n",
    "    \n",
    "    # ODWN\n",
    "    if rm_odwn.get(term) != None:\n",
    "        dict_per_term[term][\"odwn\"] = rm_odwn[term]\n",
    "    \n",
    "    # WM bows    \n",
    "    for lemma, wordforms in query_terms[\"nl\"].items():\n",
    "        if term in wordforms:\n",
    "            dict_per_term[term][\"wm\"] = nl_wm_bows[lemma][\"bow_tf_idf\"]\n",
    "            \n",
    "    all_rm[\"nl\"].update(dict_per_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "with open('background_info_bows.json', 'w') as jf:\n",
    "    json.dump(all_rm, jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how many terms have background info from at least one dataset besides the Words Matter text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file generated above\n",
    "with open(\"background_info_bows.json\",\"r\") as jf:\n",
    "    bg_info = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_term_only_wm = 0\n",
    "has_rm = 0\n",
    "for term, bg in bg_info[\"nl\"].items():\n",
    "    if len(bg) == 1 and \"wm\" in bg:\n",
    "        n_term_only_wm += 1\n",
    "    else:\n",
    "        has_rm += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EN total terms: {len(bg_info['en'].keys())}, has rm: {has_rm}, has wm only: {n_term_only_wm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NL total terms: {len(bg_info['nl'].keys())}, has rm: {has_rm}, has wm only: {n_term_only_wm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
