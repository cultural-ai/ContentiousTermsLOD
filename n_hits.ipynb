{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting N hits in resources' properties grouped by query terms and lemmas\n",
    "This notebook generates 36 csv files (6 datasets, 2 types of grouping, 3 dataset subsets) in the 'n_hits' directory:\n",
    "- related matches (Set 3) (12) \n",
    "- subset of relevant entities (Set 2) (12)\n",
    "- all search results (Set 1) (12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma_by_term(query_term:str, lang:str) -> str:\n",
    "    '''\n",
    "    Getting a lemma of a query term\n",
    "    lang: str, 'en' or 'nl'\n",
    "    Returns str, 'not found' if lemma was not found\n",
    "    '''\n",
    "    \n",
    "    return_lemma = 'not found'\n",
    "    \n",
    "    # importing query terms with lemmas\n",
    "    # change path to GitHub\n",
    "    \n",
    "    with open('/query_terms.json','r') as jf:\n",
    "        query_terms = json.load(jf)\n",
    "        \n",
    "    for lemma, qt in query_terms[lang].items():\n",
    "        if query_term in qt:\n",
    "            return_lemma = lemma\n",
    "            \n",
    "    return return_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_hits(path_to_dataset:str,resource:str,lang:str,groupby_lemma=False):\n",
    "    '''\n",
    "    Getting N of hits of query terms by properties in resources\n",
    "    with optional grouping by lemmas\n",
    "    path_to_dataset: str, path to a json file with results (related matches, subset, all results)\n",
    "    resource: str, \"wikidata\", \"aat\", \"pwn\", \"odwn\"\n",
    "    lang: str, language of results, \"en\" or \"nl\"\n",
    "    group_by_lemma: bool, if group hits by lemma, default False (count by query term)\n",
    "    Uses the function 'get_lemma_by_term';\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    # import a dataset\n",
    "    with open(path_to_dataset,'r') as jf:\n",
    "        dataset = json.load(jf)\n",
    "\n",
    "    # check resource\n",
    "    if resource == \"wikidata\":\n",
    "        df_per_resource = pd.DataFrame(columns=[\"query_term\",\"lang\",\"wd_pref\",\"wd_aliases\",\"wd_descr\",\"wd_total\"])\n",
    "\n",
    "        for query_term in dataset.keys():\n",
    "\n",
    "            wd_hits = Counter([hit[\"found_in\"] for hit in dataset[query_term]])\n",
    "            wd_pref = wd_hits.get('prefLabel')\n",
    "            wd_aliases = wd_hits.get('aliases')\n",
    "            wd_descr = wd_hits.get('description')\n",
    "            wd_total = sum(Counter(wd_hits).values())\n",
    "\n",
    "            data = [query_term,lang,wd_pref,wd_aliases,wd_descr,wd_total]\n",
    "            # replace None values\n",
    "            data = [0 if value is None else value for value in data]\n",
    "            # add a row\n",
    "            df_per_resource.loc[len(df_per_resource)] = data\n",
    "\n",
    "    if resource == \"aat\":\n",
    "        df_per_resource = pd.DataFrame(columns=[\"query_term\",\"lang\",\"aat_pref\",\"aat_alt\",\"aat_scopeNote\",\\\n",
    "                                                \"aat_pref_comment\",\"aat_alt_comment\",\"aat_total\"])\n",
    "\n",
    "        for query_term in dataset.keys():\n",
    "\n",
    "            aat_hits = Counter([hit[\"found_in\"] for hit in dataset[query_term]])\n",
    "            aat_pref = aat_hits.get('prefLabel')\n",
    "            aat_alt = aat_hits.get('altLabel')\n",
    "            aat_scopeNote = aat_hits.get('scopeNote')\n",
    "            aat_pref_comment = aat_hits.get('prefLabel_comment')\n",
    "            aat_alt_comment = aat_hits.get('altLabel_comment')\n",
    "            aat_total = sum(Counter(aat_hits).values())\n",
    "\n",
    "            data = [query_term,lang,aat_pref,aat_alt,aat_scopeNote,aat_pref_comment,aat_alt_comment,aat_total]\n",
    "            # replace None values\n",
    "            data = [0 if value is None else value for value in data]\n",
    "            # add a row\n",
    "            df_per_resource.loc[len(df_per_resource)] = data\n",
    "\n",
    "    if resource == \"pwn\":\n",
    "        df_per_resource = pd.DataFrame(columns=[\"query_term\",\"lang\",\"pwn_le\",\"pwn_def\",\"pwn_ex\",\"pwn_total\"])\n",
    "\n",
    "        for query_term in dataset.keys():\n",
    "\n",
    "            pwn_hits = Counter([hit[\"found_in\"] for hit in dataset[query_term]])\n",
    "            pwn_le = pwn_hits.get('lemmata')\n",
    "            pwn_def = pwn_hits.get('definition')\n",
    "            pwn_examples = pwn_hits.get('examples')\n",
    "            pwn_total = sum(Counter(pwn_hits).values())\n",
    "\n",
    "            data = [query_term,lang,pwn_le,pwn_def,pwn_examples,pwn_total]\n",
    "            # replace None values\n",
    "            data = [0 if value is None else value for value in data]\n",
    "            # add a row\n",
    "            df_per_resource.loc[len(df_per_resource)] = data\n",
    "\n",
    "    if resource == \"odwn\":\n",
    "        df_per_resource = pd.DataFrame(columns=[\"query_term\",\"lang\",\"odwn_le\",\"odwn_sense_def\",\\\n",
    "                                                    \"odwn_synset_def\",\"odwn_sense_ex\",\"odwn_total\"])\n",
    "\n",
    "        for query_term in dataset.keys():\n",
    "\n",
    "            odwn_hits = Counter([hit[\"found_in\"] for hit in dataset[query_term]])\n",
    "            odwn_le = odwn_hits.get('le')\n",
    "            odwn_sense_ex = odwn_hits.get('sense_examples')\n",
    "            odwn_sense_def = odwn_hits.get('sense_definition')\n",
    "            odwn_synset_def = odwn_hits.get('synset_definitions')\n",
    "            odwn_total = sum(Counter(odwn_hits).values())\n",
    "\n",
    "            data = [query_term,lang,odwn_le,odwn_sense_def,odwn_synset_def,odwn_sense_ex,odwn_total]\n",
    "            # replace None values\n",
    "            data = [0 if value is None else value for value in data]\n",
    "            # add a row\n",
    "            df_per_resource.loc[len(df_per_resource)] = data\n",
    "\n",
    "    # check if group by lemma\n",
    "    if groupby_lemma:\n",
    "        # add lemma column to the df\n",
    "        lemmas = [get_lemma_by_term(query_term,lang) for query_term in list(df_per_resource[\"query_term\"])]\n",
    "        df_per_resource.insert(0,\"lemma\",lemmas)\n",
    "        # create a new df; copy colums \n",
    "        new_colums = [\"lemma\"]\n",
    "        new_colums.extend(list(df_per_resource.columns[2:]))\n",
    "        df_per_resource_lemmas = pd.DataFrame(columns=new_colums)\n",
    "\n",
    "        # grouping by lemma\n",
    "        for lemma_group in df_per_resource.groupby(\"lemma\"):\n",
    "            row = [lemma_group[0],lang]\n",
    "            # count n hits by properties\n",
    "            for col in new_colums[2:]:\n",
    "                row.append(sum(lemma_group[1][col]))\n",
    "\n",
    "            df_per_resource_lemmas.loc[len(df_per_resource_lemmas)] = row\n",
    "        \n",
    "        return df_per_resource_lemmas\n",
    "    \n",
    "    else:\n",
    "        return df_per_resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related matches (Set 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata EN\n",
    "# terms\n",
    "rm_wd_en_terms = get_n_hits('/rm/rm_wd_en.json','wikidata','en')\n",
    "rm_wd_en_terms.to_csv('/n_hits/rm_wd_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_wd_en_lemmas = get_n_hits('/rm/rm_wd_en.json','wikidata','en',True)\n",
    "rm_wd_en_lemmas.to_csv('/n_hits/rm_wd_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata NL\n",
    "# terms\n",
    "rm_wd_nl_terms = get_n_hits('/rm/rm_wd_nl.json','wikidata','nl')\n",
    "rm_wd_nl_terms.to_csv('/n_hits/rm_wd_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_wd_nl_lemmas = get_n_hits('/rm/rm_wd_nl.json','wikidata','nl',True)\n",
    "rm_wd_nl_lemmas.to_csv('/n_hits/rm_wd_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT EN\n",
    "# terms\n",
    "rm_aat_en_terms = get_n_hits('/rm/rm_aat_en.json','aat','en')\n",
    "rm_aat_en_terms.to_csv('/n_hits/rm_aat_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_aat_en_lemmas = get_n_hits('/rm/rm_aat_en.json','aat','en',True)\n",
    "rm_aat_en_lemmas.to_csv('/n_hits/rm_aat_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT NL\n",
    "# terms\n",
    "rm_aat_nl_terms = get_n_hits('/rm/rm_aat_nl.json','aat','nl')\n",
    "rm_aat_nl_terms.to_csv('/n_hits/rm_aat_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_aat_nl_lemmas = get_n_hits('/rm/rm_aat_nl.json','aat','nl',True)\n",
    "rm_aat_nl_lemmas.to_csv('/n_hits/rm_aat_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWN\n",
    "# terms\n",
    "rm_pwn_terms = get_n_hits('/rm/rm_pwn.json','pwn','en')\n",
    "rm_pwn_terms.to_csv('/n_hits/rm_pwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_pwn_lemmas = get_n_hits('/rm/rm_pwn.json','pwn','en',True)\n",
    "rm_pwn_lemmas.to_csv('/n_hits/rm_pwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODWN\n",
    "# terms\n",
    "rm_odwn_terms = get_n_hits('/rm/rm_odwn.json','odwn','nl')\n",
    "rm_odwn_terms.to_csv('/n_hits/rm_odwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "rm_odwn_lemmas = get_n_hits('/rm/rm_odwn.json','odwn','nl',True)\n",
    "rm_odwn_lemmas.to_csv('/n_hits/rm_odwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset (Set 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata EN\n",
    "# terms\n",
    "subset_wd_en_terms = get_n_hits('/Wikidata/wd_en_subset.json','wikidata','en')\n",
    "subset_wd_en_terms.to_csv('/n_hits/subset_wd_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_wd_en_lemmas = get_n_hits('/Wikidata/wd_en_subset.json','wikidata','en',True)\n",
    "subset_wd_en_lemmas.to_csv('/n_hits/subset_wd_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata NL\n",
    "# terms\n",
    "subset_wd_nl_terms = get_n_hits('/Wikidata/wd_nl_subset.json','wikidata','nl')\n",
    "subset_wd_nl_terms.to_csv('/n_hits/subset_wd_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_wd_nl_lemmas = get_n_hits('/Wikidata/wd_nl_subset.json','wikidata','nl',True)\n",
    "subset_wd_nl_lemmas.to_csv('/n_hits/subset_wd_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT EN\n",
    "# terms\n",
    "subset_aat_en_terms = get_n_hits('/AAT/aat_en_subset.json','aat','en')\n",
    "subset_aat_en_terms.to_csv('/n_hits/subset_aat_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_aat_en_lemmas = get_n_hits('/AAT/aat_en_subset.json','aat','en',True)\n",
    "subset_aat_en_lemmas.to_csv('/n_hits/subset_aat_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT NL\n",
    "# terms\n",
    "subset_aat_nl_terms = get_n_hits('/AAT/aat_nl_subset.json','aat','nl')\n",
    "subset_aat_nl_terms.to_csv('/n_hits/subset_aat_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_aat_nl_lemmas = get_n_hits('/AAT/aat_nl_subset.json','aat','nl',True)\n",
    "subset_aat_nl_lemmas.to_csv('/n_hits/subset_aat_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWN\n",
    "# terms\n",
    "subset_pwn_terms = get_n_hits('/PWN/pwn_subset.json','pwn','en')\n",
    "subset_pwn_terms.to_csv('/n_hits/subset_pwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_pwn_lemmas = get_n_hits('/PWN/pwn_subset.json','pwn','en',True)\n",
    "subset_pwn_lemmas.to_csv('/n_hits/subset_pwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODWN\n",
    "# terms\n",
    "subset_odwn_terms = get_n_hits('/ODWN/odwn_subset.json','odwn','nl')\n",
    "subset_odwn_terms.to_csv('/n_hits/subset_odwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "subset_odwn_lemmas = get_n_hits('/ODWN/odwn_subset.json','odwn','nl',True)\n",
    "subset_odwn_lemmas.to_csv('/n_hits/subset_odwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All search results (Set 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata EN\n",
    "# terms\n",
    "all_wd_en_terms = get_n_hits('/Wikidata/results_clean_en.json','wikidata','en')\n",
    "all_wd_en_terms.to_csv('/n_hits/all_wd_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_wd_en_lemmas = get_n_hits('/Wikidata/results_clean_en.json','wikidata','en',True)\n",
    "all_wd_en_lemmas.to_csv('/n_hits/all_wd_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikidata NL\n",
    "# terms\n",
    "all_wd_nl_terms = get_n_hits('/Wikidata/results_clean_nl.json','wikidata','nl')\n",
    "all_wd_nl_terms.to_csv('/n_hits/all_wd_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_wd_nl_lemmas = get_n_hits('/Wikidata/results_clean_nl.json','wikidata','nl',True)\n",
    "all_wd_nl_lemmas.to_csv('/n_hits/all_wd_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT EN\n",
    "# terms\n",
    "all_aat_en_terms = get_n_hits('/AAT/aat_query_results_en.json','aat','en')\n",
    "all_aat_en_terms.to_csv('/n_hits/all_aat_en_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_aat_en_lemmas = get_n_hits('/AAT/aat_query_results_en.json','aat','en',True)\n",
    "all_aat_en_lemmas.to_csv('/n_hits/all_aat_en_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAT NL\n",
    "# terms\n",
    "all_aat_nl_terms = get_n_hits('/AAT/aat_query_results_nl.json','aat','nl')\n",
    "all_aat_nl_terms.to_csv('/n_hits/all_aat_nl_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_aat_nl_lemmas = get_n_hits('/AAT/aat_query_results_nl.json','aat','nl',True)\n",
    "all_aat_nl_lemmas.to_csv('/n_hits/all_aat_nl_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWN\n",
    "# terms\n",
    "all_pwn_terms = get_n_hits('/PWN/pwn31_query_results.json','pwn','en')\n",
    "all_pwn_terms.to_csv('/n_hits/all_pwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_pwn_lemmas = get_n_hits('/PWN/pwn31_query_results.json','pwn','en',True)\n",
    "all_pwn_lemmas.to_csv('/n_hits/all_pwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODWN\n",
    "# terms\n",
    "all_odwn_terms = get_n_hits('/ODWN/odwn_query_results.json','odwn','nl')\n",
    "all_odwn_terms.to_csv('/n_hits/all_odwn_terms.csv')\n",
    "\n",
    "# lemmas\n",
    "all_odwn_lemmas = get_n_hits('/ODWN/odwn_query_results.json','odwn','nl',True)\n",
    "all_odwn_lemmas.to_csv('/n_hits/all_odwn_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
